% !TeX spellcheck = russian-aot

\documentclass[12pt,a4paper]{article}
\usepackage{cmap}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsthm,amsmath,amssymb}
\usepackage{xspace}
\usepackage[a4paper,left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{todonotes}
\usepackage{enumitem}
\usepackage{microtype}

%% CALCULATOR
\usepackage{calc}
%% STYLE
\usepackage[dotinlabels]{titletoc}
\usepackage[small]{titlesec}
%% TITLESEC BUG WORKAROUND %%
\usepackage{etoolbox}
\makeatletter
\patchcmd{\ttlh@hang}{\parindent\z@}{\parindent\z@\leavevmode}{}{}
\patchcmd{\ttlh@hang}{\noindent}{}{}{}
\makeatother
%% END %%
\titlelabel{\thetitle.\quad}
%% Puts "." instead of ":" in captions
\usepackage{ccaption}
\captiondelim{. }

%\usepackage{indentfirst}
%% OTHER

\usepackage[bookmarks=false, colorlinks, unicode, pdfstartview=FitH, pdftex]{hyperref}
\hypersetup{ 
 plainpages=true,
 linkcolor=blue,
 citecolor=red,
 menucolor=blue,
 pdfnewwindow=true
}

\usepackage{tikz}
\usetikzlibrary{positioning,calc}

\newcommand{\bits}{\{0,1\}}
\newcommand{\bitstr}{\bits^*}
\newcommand{\sshalf}{{\textstyle\frac12}}
\newcommand{\seqn}[2]{{#1}_1,{#1}_2,\dotsc,{#1}_{#2}}
\newcommand{\seqin}[3]{{#1}_{{#2}_1},{#1}_{{#2}_2},\dotsc,{#1}_{{#2}_{#3}}}
\newcommand{\IC}{\mathrm{IC}}
\newcommand{\poly}{\mathrm{poly}}
\newcommand{\Nat}{\mathbb{N}}

\DeclareMathOperator{\dom}{dom}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator*{\maj}{maj}
\DeclareMathOperator{\rng}{rng}
\DeclareMathOperator{\out}{out}

\theoremstyle{definition}
\newtheorem{definition}{Определение}[section]

\theoremstyle{plain}
\newtheorem{theorem}{Теорема}[section]
\newtheorem{lemma}{Лемма}[section]
\newtheorem{statement}{Утверждение}[section]
\newtheorem{corollary}{Следствие}[section]

\theoremstyle{remark}
\newtheorem{example}{Пример}[section]
\newtheorem{exercise}{Упражнение}[section]
\newtheorem{remark}{Замечание}[section]
\newtheorem{problem}{Задача}[section]

\newenvironment{tasks}{\paragraph{Задачи.}\begin{enumerate}}{\end{enumerate}}

%opening
\title{,,Теоретико-сложностные основы криптографии``. Заметки к курсу в СПбАУ}
\author{А.В. Смаль}

\begin{document}

\maketitle

\begin{abstract}
Курс посвящён изучению теоретических оснований, на которых строится
надёжность криптографических протоколов.
\end{abstract}

%\newpage
\tableofcontents
\newpage


\section*{Введение}
Мы будем предполагать, что алгоритмы шифрования/дешифрования всем известны (т.е. no security by obscurity).

\section{Совершенная надёжность}
\begin{definition}
\emph{Система шифрования с закрытым ключом}~--- это пара
алгоритмов $E(k, m)$ и $D(k, c)$, такая, что
для любых $k$ и $m$ выполняется $D(k, E(k, m)) = m$. Система называется \emph{совершенно надёжной}, если для любых двух сообщений $m_1$ и $m_2$ случайные величины $E(k, m_1)$ и $E(k, m_2)$ при $k\gets \mathcal U(K)$ распределены одинаково ($\mathcal K$~--- пространство ключей).
\end{definition}
\begin{remark}
Система шифрования с одноразовым шифроблокнотом является совершенно надёжной.
\end{remark}

\begin{remark}
Для совершенной надёжности необходимо, чтобы длина ключа была не менее длины сообщения.
\end{remark}

\begin{theorem}
Пусть $P=NP$. Тогда для любой системы шифрования с закрытым ключом $(E,D)$ 
с полиномиальным алгоритмом $E$, в которой $|m|>|k|$, существуют сообщения 
$m_0$ и $m_1$ и полиномиальный алгоритм $A$, для которого
$$\Bigl|\Pr_k[A(E(k,m_0)) = 1]-\Pr_k[A(E(k,m_1)) = 1]\Bigr|\ge\frac12.$$
\end{theorem}
\begin{proof}
Не уменьшая общности предположим, что $\mathcal K = \bits^{n-1}$. 
Возьмём в качестве $m_0 = 0^n$. 
Пусть $S = \{E(k, 0^n)\mid k\in\mathcal K\}$. Легко видеть, что $S\in NP$ и $|S|\le 2^{n-1}$. Возьмём в качестве алгоритма $A$ полиномиальный разрешающий алгоритм для $S$, т.е. $A(y) := [y\in S]$ (он существует по предположению $P=NP$).

Для каждого сообщения $m$ рассмотрим $t_m = \bigl|\{k\mid E(k, m) \in S\}\bigr|$. 
Если существует сообщение $m^*$, для которого $t_{m^*} \le 2^{n-1}$, то $m_1 = m^*$ удовлетворяет требованиям. 

Предположим теперь, что $t_m > 2^{n-2}$ для любого $m$. Это значит, что существуют более $2^{n-2}\cdot 2^n = 2^{2n - 2}$ пар ключ-сообщение $(k,m)$, для которых 
$E(k,m)\in S$. Следовательно, для некоторого $y\in S$ существует более $2^{2n - 2} / |S| \ge 2^{n-1}$ пар $(k,m): E(k,m) = y$, т.е. существуют ключ $k$ и два различных сообщения $m'$ и $m''$: $E(k,m') = E(k,m'')$. Это противоречит корректности системы шифрования.
\end{proof}

\section{Односторонние функции}
Доказывать надёжность криптографических протоколов без каких-либо предположений, к сожалению, не получается~--- из такого доказательства следовало бы $P\neq NP$.
Было бы здорово показать, что криптография возможна, если $P\neq NP$, но это тоже не получается сделать. Поэтому в дальнейшем мы
будем отталкиваться от более сильного предположение~--- предположения о существовании \emph{односторонней функции}.

В дальнейшем мы будем рассматривать семейства функций $f_n: \bits^{k(n)} \to \bits^{l(n)}$, где $k(n)$ и $l(n)$ будут некоторыми полиномами. Кроме того, нас почти всегда будут интересовать
функции, которые можно вычислить за полиномиальное время.

\begin{definition}
    Семейство функций $f_n: \bits^{k(n)} \to \bits^{l(n)}$ называется 
    \emph{полиномиально вычислимым}, если имеется алгоритм, который получая на вход 
    число $n$ и $x$ длины $k(n)$ вычисляет $f_n(x)$ за полиномиальное от $n$ время.
\end{definition}

\subsection{Односторонние функции с худшем случае}
\begin{definition}
Полиномиально вычислимое семейство функций $f_n:\bits^{k(n)}\to \bits^{l(n)}$ называется 
\emph{односторонним в худшем случае}, если не существует полиномиально вычислимой функции 
$g_n$, что для любого $x\in\bits^{k(n)}$ верно $f_n(g_n(f_n(x))) = f_n(x)$.
\end{definition}

\begin{theorem}\label{th:weak-owf-p-np}
Односторонние функции с худшем случае существуют $\iff$ $P\neq NP$.
\end{theorem}
\begin{proof}\mbox{}
\begin{itemize}
\item[$\Rightarrow$] Пусть $P=NP$.
Определим язык $L = \{(1^n, y, z) \mid \exists x, |x| = k(n), z \sqsubset x, f_n(x) = y\}$, $L\in NP$. По предположению для $L$ существует полиномиальный разрешающий алгоритм. 
Для нахождения прообраза $y$ запустим этот алгоритм сначала на 
слове $(1^n, y, \lambda)$, где $\lambda$~--- пустая строка. 
Если это слово не принадлежит $L$, то $y$ не имеет прообраза.
В~противном случае восстановим прообраз $y$ по битам: сначала запустим алгоритм для слова $(1^n, y, 0)$ и проверим, есть ли у $y$ прообраз начинающийся с нуля. Далее аналогично восстановим второй и все последующие биты. Нам потребуется $k(n) + 1$ запуск полиномиального алгоритма, т.е. прообраз можно найти алгоритмически за полиномиальное время.

\item[$\Leftarrow$] Если $P\neq NP$, то можно построить одностороннюю в худшем на основе любой $NP$-трудной задачи.
Пусть $R(x,y)$~--- это отношение, задающее $NP$-трудную задачу $S$
(например, для $S = SAT$: $R(\phi, a) = 1 \iff \phi(a) = 1$). Пусть $f_n(x, y) = (x, R(x,y))$. 
Если $f_n^{-1}$ вычисляется за полиномиальное время, то и задачу $S$ можно решить за полиномиальное время,
вычислив $f^{-1}(x, 1)$.
\end{itemize}
\end{proof}


\subsection{Односторонние функции для алгоритмов}
Мы будем определять \emph{односторонние функции} (one-way function, owf) для противника, который является 
вероятностным полиномиальным алгоритмом, т.е. для \emph{равномерного противника}.
\begin{definition}
    Полиномиально вычислимое семейство $f_n$ называется
    \emph{слабо односторонним для равномерного противника}, 
    если \textbf{существует} такой полином $p$, что 
    для любого полиномиального вероятностного алгоритма $R$ 
    при всех достаточно больших $n$
    $$\Pr_{x,R}[f_n(R(1^n, f_n(x))) = f_n(x)] < 1 - \frac{1}{p(n)}.$$

\end{definition}

\begin{definition}
    Полиномиально вычислимое семейство $f_n$ называется 
    \emph{сильно односторонним для равномерного противника}, 
    если \textbf{для любого} полинома $q$, что
    для любого полиномиального вероятностного алгоритма $R$ 
    при всех достаточно больших $n$
    $$\Pr_{x,R}[f_n(R(1^n, f_n(x))) = f_n(x)] < \frac{1}{q(n)}.$$
\end{definition}

\subsection{Односторонние функции для неравномерного противника}
Аналогичным образом можно определить односторонние функции для противника, 
являющегося последовательностью схем, т.е. для \emph{неравномерного противника}.
\begin{definition}
    Полиномиально вычислимое семейство $f_n$ называется
    \emph{слабо односторонним для неравномерного противника}, 
    если \textbf{существует} такой полином $p$, 
    что для любой последовательности схем $C_n$ полиномиального размера
    при всех достаточно больших $n$
        $$\Pr_{x}[f_n(x) = f_n(C_n(f_n(x)))] < 1 - \frac{1}{p(n)}.$$
\end{definition}

\begin{definition}
    Полиномиально вычислимое семейство $f_n$ называется
    \emph{сильно односторонним для неравномерного противника}, 
    если \textbf{для любого} полинома $q$, 
    что для любой последовательности схем $C_n$ полиномиального размера
    при всех достаточно больших $n$
        $$\Pr_{x}[f_n(x) = f_n(C_n(f_n(x)))] < \frac{1}{q(n)}.$$
\end{definition}

\begin{remark}
Односторонние функции для неравномерного противника можно было бы 
определять для \emph{вероятностных} схем, т.е. для схем, которым на вход
подают не только $f_n(x)$, но и некоторую строку со случайными битами $r$.
Однако, легко показать, что от случайных битов в таких определениях
можно избавиться: для этого нужно для каждого $n$ выбрать одну ``самую лучшую''
строку $r_n$, на которой достигается максимальная вероятность обращения $f_n$
и ``зашить'' её в схему. Нетрудно увидеть, что вероятность обращения при 
$r = r_n$ будет не меньше, чем по всем $r$ в среднем.
\end{remark}

В дальнейшем мы часто будем говорить про односторонние \emph{функции}, 
подразумевая под этим \emph{семейства} односторонних функций. 
Когда говорят про \emph{одностороннюю функцию}, то имеется 
в виду сильно односторонняя функция.

\begin{definition}
Если в определении односторонней функции убрать требование полиномиальной вычислимости,
то получится определение \emph{необратимой} функции.
\end{definition}

\subsection{Примеры односторонних функций}

Неизвестно, существуют ли односторонние или хотя бы слабо односторонние функции 
(даже для равномерного противника). Доказательство их существования повлечёт
за собой $P \neq NP$.

\begin{theorem}
Если $P=NP$, то любое полиномиально вычислимое семейство функций $f_n$ не является
слабо необратимым даже для равномерного противника. Более того, 
существует детерминированный алгоритм, который для всех $x$ по $n$ и 
$f_n(x)$ за полиномиальное от $n$ время находит некоторый прообраз 
$f_n(x)$ длины $k(n)$.
\end{theorem}
\begin{proof}
См. пункт ``$\Rightarrow$'' доказательства теоремы~\ref{th:weak-owf-p-np}.
\end{proof}
\begin{example}[произведение натуральных чисел]
Семейство $f_n$ устроено следующим образом: $k(n) = l(n) = 2n$, вход $x$ делится пополам, каждая половинка представляет собой $n$-битовое число, результат $f_n$~--- произведение этих чисел (получится не более чем $2n$-битовое число).
\end{example}
\begin{example}[SUBSET-SUM]
Семейство $f_n$ для SUBSET-SUM устроено следующим образом: 
$k(n) = n^2 + n$, $l(n) = n^2 + 2n + \lceil\log n\rceil$,
вход $x$ разбивается на $n+1$ блок длины $n$, 
первые $n$ блоков интерпретируются как $n$-битовые числа $x_1, \dotsc, x_n$, 
а последний блок интерпретируется как подмножество $[n]$. Тогда
$f_n(x) = \bigl\langle x_1, x_2, \dotsc, x_n, \sum_{i\in I} x_i \bigr\rangle$.
\end{example}

\subsection{Построение сильно односторонних функций из слабо односторонних}
\begin{theorem}
Если существуют слабо односторонние функции, то существуют и сильно односторонние функции (это верно для любых противников).
\end{theorem}
\begin{proof}
Будем доказывать для равномерного противника~--- для неравномерного доказательство будет аналогичным. 
Пусть $f$~--- слабо односторонняя функция, т.е.
существует такой полином $p$, что для любого полиномиального вероятностного алгоритма $R$
при всех достаточно больших $n$
$$\Pr_{x,r}[f_n(x) = f_n(R(1^n, f_n(x), r))] < 1 - \frac{1}{p(n)}.$$

Определим функцию $F$, которая определяется следующим соотношением:
$$F_n(x_1,x_2,\dotsc,x_N) = \langle f_n(x_1), f_n(x_2), \dotsc, f_n(x_N) \rangle,$$
т.е. $F_n : \bits^{N\cdot k(n)} \to \bits^{N\cdot l(n)}$. Для того, чтобы обратить $F_n$ нам нужно $N$ раз обратить функцию $f_n$. В каждом случае вероятность ошибки не меньше $1/p(n)$, поэтому общая вероятность успеха не более $\bigl(1-1/p(n)\bigr)^N$.
Для $N = n\cdot p(n)$ эта вероятность близка к $e^{-n}$, что убывает быстрее любого обратного полинома.
Таким образом функция $F$~--- сильно односторонняя.

В предыдущем рассуждении кроется ошибка. Дело в том, что мы предполагаем, что обращающий
алгоритм будет обязательно устроен следующим образом: он будет пытаться $N$ раз обратить
$f_n$, т.е. найти прообразы для $f_n(x_1),f_n(x_2),\dotsc,f_n(x_N)$. 
Это не обязательно так~--- мы не можем предполагать, что этот алгоритм будет
устроен каким-то конкретным образом. Поэтому предыдущее доказательство ошибочное, 
хотя получившаяся функция $F$ действительно сильно односторонняя.

Корректное доказательство этого факта будет устроено другим образом. Мы предположим, что
функция $F$ не является сильно односторонней и из этого покажем, что в свою
очередь функция $f$ не является слабо односторонней. Для этого мы воспользуемся
алгоритмом, который обращает $F$, для построения алгоритма обращения $f$. 
Предположим, что алгоритм $R_F$ умеет обращать $F$ с вероятностью успеха 
более $1/q(n)$ для некоторого полинома $q$. Тогда мы покажем, что 
существует алгоритм $R_f$, который обращает $f$ с вероятностью успеха более
$1 - 1/p(n)$.

Алгоритм $R_f$ мог бы быть устроен так: для обращения $y$ мы выберем 
случайные $x_2, x_3,\dotsc,x_N$ и запустим алгоритм $R_F$ на входе
$\langle y, f_n(x_2), f_n(x_3),\dotsc,f_n(x_N)\rangle$. Действительно,
если $R_F$ найдёт прообраз для этого входа, то он в т.ч. найдёт
и прообраз для $y$. Вероятность успеха $R_F$ на таком входе 
для случайного $y$ не менее вероятности успеха $R_F$ для случайных
$x_1,\dotsc,x_N$. Однако нам этого недостаточно~--- мы хотели бы получить
вероятность успеха близкую к единице. 

Для этого будем использовать два дополнительных приёма:
\begin{itemize}
\item будем пытаться подставить $y$ не только на место $f_n(x_1)$, а 
для каждого $i$ будем запускать алгоритм $R_F$ на входе
$\langle f_n(x_1),\dotsc, f_n(x_{i-1}), y,  f_n(x_{i+1}),\dotsc,f_n(x_N)\rangle$ для случайных
$x_1,\dotsc, x_{i-1}, x_{i+1},\dotsc,x_N$;\footnote{Этот приём необходим, т.к. в противном случае
у нас не получится увеличивать вероятность успеха. Действительно, если представить, что алгоритм 
$R_F$ не работает на строках, у которых первый бит нулевой, то вероятность успеха такого алгоритма
вполне может быть $1/2$. Но тогда и вероятность успеха $R_f$ не может быть выше $1/2$.}
\item будем повторять каждую итерацию $M$ раз для различных случайных независимых наборов $x_1,\dotsc, x_{i-1},x_{i+1},\dotsc,x_N$.
\end{itemize}

Давайте выделим один \emph{раунд} алгоритма $R_f$: для каждого $i$ выбирается 
независимый случайный набор входов $x_1,\dotsc, x_{i-1},x_{i+1},\dotsc,x_N$
и вызывается алгоритм $R_F$ на входе 
$\langle f_n(x_1),\dotsc, f_n(x_{i-1}), y,  f_n(x_{i+1}),\dotsc,f_n(x_N)\rangle$.
Этот этап будет повторён $M$ раз. Значение $M$ мы выберем позже, это будут некоторый полином от $n$. 

Через $s_i(x)$ мы будем обозначать вероятность того, что алгоритм $R_F$ найдёт прообраз
$\langle f_n(x_1),\dotsc, f_n(x_{i-1}), f_n(x),  f_n(x_{i+1}),\dotsc,f_n(x_N)\rangle$
для случайных $x_1,\dotsc, x_{i-1},x_{i+1},\dotsc,x_N$. Через $\hat s(x)$ обозначим
вероятность успеха одного раунда алгоритма $R_f$. Эта вероятность заведомо не меньше
максимальной вероятности среди всех $s_i(x)$, т.е. $\hat s(x) \ge \max_i s_i(x)$. 

Рассмотрим отдельно входы $x$, которые наш алгоритм $R_f$ обращает с маленькой
вероятностью, т.е. это ``трудные'' для обращения входы. Будем говорить, что $x$~--- трудный, 
если $\hat s(x) < \epsilon$ для некоторого обратного полинома $\epsilon$,
который мы выберем дальше. 
Долю трудных ``трудных'' слов среди всех слов длины $n$ мы обозначим через $\delta$,
т.е. $\delta = \Pr_{x\gets U_n}[\hat s(x) < \epsilon]$. 

Дальнейшее доказательство будет построено так: мы предположим, что получившийся алгоритм $R_f$ 
не обращает функцию $f$ с нужной вероятностью, т.е. вероятность его ошибки большее $1/p(n)$.
Из этого будет следовать, что доля трудных слов $\delta$ довольно большая 
(больше некоторого обратного полинома). А раз трудных слов много, то и вероятность успеха 
$R_F$ не может быть больше $1/q(n)$. Таким образом мы придём к противоречию.
Для реализации этого плана потребуется следующие две леммы.
\begin{lemma}\label{lm:owf:rf}
Вероятность ошибки $R_f$ при обращении слова $f_n(x)$ 
для случайного $x$ не больше $\delta + (1 - \epsilon)^M.$
\end{lemma}
\begin{proof}
По формуле полной вероятности вероятность ошибки $R_f$ 
при обращении слова $f_n(x)$ для случайного $x$ можно расписать
как вероятность ошибки на ``трудных'' входах и на простых входах.
$$\begin{aligned}
\Pr_{x,r}[\text{ошибка $R_f$}] 
&= \Pr_r[\text{ошибка $R_f$}\mid \hat s(x) <   \epsilon] \cdot \Pr_x[\hat s(x) <   \epsilon]\\ 
&+ \Pr_r[\text{ошибка $R_f$}\mid \hat s(x) \ge \epsilon] \cdot \Pr_x[\hat s(x) \ge \epsilon]\\
&\le 1 \cdot \delta + (1 - \epsilon)^M \cdot 1.
\end{aligned}
$$
\end{proof}

\begin{lemma}\label{lm:owf:rfn}
Вероятность успеха алгоритма $R_F$ при обращении слова $F(\bar x)$ 
для случайного $\bar x = x_1,\dotsc,x_N$ не больше $N\delta\epsilon + (1 - \delta)^N$.
\end{lemma}
\begin{proof}
Оценим вероятность успеха сверху по формуле полной вероятности:
$$\begin{aligned}
\Pr_{\bar x,r}[\text{успех $R_F$}] 
&= \Pr_r[\text{успех $R_F$}\mid \exists i, \hat s(x_i) <   \epsilon] \cdot \Pr_{\bar x}[\exists i, \hat s(x_i) < \epsilon]\\
&+ \Pr_r[\text{успех $R_F$}\mid \forall i, \hat s(x_i) \ge \epsilon] \cdot \Pr_{\bar x}[\forall i, \hat s(x_i) \ge \epsilon]\\
&\le \epsilon \cdot N\delta + 1 \cdot (1 - \delta)^N.
\end{aligned}
$$
\end{proof}

Предположим теперь, что у получившегося алгоритма $R_f$ вероятность ошибки больше, чем $1/p(n)$, 
т.е. $R_f$ обращает $f$ с вероятностью успеха меньше $1-\frac{1}{p(n)}$. Положим $M = n / \epsilon$. 
Тогда второе слагаемое в лемме~\ref{lm:owf:rf} будет порядка $e^{-n}$, что при
при достаточно больших $n$ меньше, чем $\frac{1}{2p(n)}$.  Таким образом
$\delta > \frac{1}{2p(n)}$.

Теперь мы хотим определить $N$ и $\epsilon$ так, чтобы вероятность успеха $R_F$ оказалась
меньше, чем $1/q(n)$. Выберем $N = n\cdot p(n)$, тогда при $\delta > \frac{1}{2p(n)}$ мы получаем, 
что второе слагаемое в лемме~\ref{lm:owf:rfn} будет порядка $e^{-n/2}$:
$$(1 - \delta)^N < \Bigl (1 - \frac{1}{2p(n)}  \Bigr)^{n\cdot p(n)} 
= \Biggl[\Bigl(1 - \frac{1}{2p(n)}  \Bigr)^{2p(n)}\Biggr]^{n/2} \approx e^{-n/2}.$$
При достаточно больших $n$ это меньше, чем $\frac{1}{2q(n)}$.
Осталось определить $\epsilon$ так, чтобы и первое слагаемое лемме~\ref{lm:owf:rfn}
было меньше $\frac{1}{2q(n)}$. Например, это достигается при
$$\epsilon = \frac{1}{2N\cdot q(n)} = \frac{1}{2n\cdot p(n)\cdot q(n)}.$$
При таким $M$, $N$ и $\epsilon$ получается, что алгоритм $R_f$ вызовет
полиномиальный алгоритм $R_F$ не более $M\cdot N = 2n^3\cdot p^2(n)\cdot q(n)$ раз,
т.е. $R_f$ сам по себе будет полиномиальным.

\end{proof}


\subsection{Частичные односторонние функции}
Односторонние функции, которые мы определили выше, определены
для всех слов длины $k(n)$. Можно обобщить это определение на
случай частичных функций, которые определены на некотором 
$D_n\subset\bits^{k(n)}$. Для того, чтобы такие функции можно 
было применять для построения криптографических протоколов,
мы дополнительно потребуем возможности
генерировать \emph{почти} равномерное распределение на $D_n$.

\begin{definition}
Последовательность распределений вероятностей $\mu_n$ 
на множестве двоичных слов называется \emph{полиномиально 
моделируемой}, если существует полиномиальный вероятностный
алгоритм $K$, такой, что для всех $x\in\bitstr$
$$\Pr_r[K(1^n, r) = x] = \mu_n(x).$$
\end{definition}

\begin{definition}
\emph{Статистическим расстоянием} между распределениями
вероятностей $\mu$ и $\nu$ называется
$$\delta(\mu,\nu) = \max_{A\subset\bitstr}|\mu(A) - \nu(A)|.$$
Не сложно показать, что максимум достигается при $A$ равном 
$\{x \mid \mu(x) > \nu(x)\}$ и его дополнению.
Таким образом 
$$\delta(\mu,\nu) = \frac12\sum_{x} |\mu(x) - \nu(x)|.$$
\end{definition}

\begin{definition}
Последовательности распределений $\mu_n$ и $\nu_n$ называются
\emph{статистически неотличимыми}, если статистическое расстояние
между ними стремится к нулю быстрее любого обратного полинома от $n$
при $n\to\infty$. 
\end{definition}

\begin{definition}
Случайные величины $\alpha_n$ и $\beta_n$ называются \emph{статистически
неотличимыми}, если их распределения $\mu_n(x) = \Pr[\alpha_n = x]$
и $\nu_n(x) = \Pr[\beta_n = x]$ статистически неотличимы.
\end{definition}

\begin{definition}
Распределение $\mu_n$ называется \emph{доступным}, если оно статистически
неотличимо от некоторого полиномиально моделируемого распределения $\nu_n$.
\end{definition}

\begin{definition}
Семейство частичных функций $f_n$ с областями определения $D_n$ называется 
\emph{сильно односторонним}, если $f_n$ полиномиально вычислимо, равномерное
распределение на $D_n$ доступно, и для любого полинома $q$ и для любого
полиномиального вероятностного алгоритма $R$,
$$\Pr_{x\gets D_n,r}[f_n(x) = f_n(R(1^n, f_n(x), r))] < \frac{1}{q(n)}$$
при всех достаточно больших $n$. Сильно одностороннее семейство частичных функций
$f_n$ называется \emph{сильно односторонней перестановкой} (one-way permutation, owp), 
если для всех $n$ оно является перестановкой своей области определения $D_n$.
\end{definition}
Аналогичным образом определяются \emph{слабо односторонние} функции и
\emph{односторонние функции} для неравномерного противника.

\begin{example}[Предположительно сильно односторонние частичные функции]
\mbox{}
\begin{enumerate}
\item \emph{Функция Рабина.} Функция $f_n$ определена на словах вида $xy$
длины $4n$, где $|x| = |y| = 2n$. При этом $x$ и $y$ интерпретируются как 
$2n$-битовые числа, удовлетворяющих следующим требованиям:
\begin{enumerate}
\item $y = p\cdot q$, где $p$ и $q$ простые $n$-битовые числа вида $4k+3$;
\item $x = z^2 \bmod y$ для некоторого $z$, взаимно простого с $y$.
\end{enumerate}
Значение функции на $xy$ равно конкатенации слов $x^2 \bmod y$ и $y$.

\item \emph{Функция RSA.} Функция RSA является обобщением функции Рабина.
Она определена на словах вида $xyz$, где $x$, $y$ и $z$ имеют длину $2n$
и интерпретируются как двоичные записи чисел, удовлетворяющие следующим
требованиям:
\begin{enumerate}
\item $y = p\cdot q$, где $p$ и $q$ простые $n$-битовые числа;
\item $x \in [1, pq - 1]$ и взаимно просто с $y$;
\item $z$ взаимно просто $\phi(pq) = (p-1)\cdot(q-1)$.
\end{enumerate}
Значение функции на $xyz$ равно конкатенации слов ($x^z \bmod y$), $y$ и $z$.
\item \emph{Дискретная экспонента.} Функция определена на словах вида $xyz$, где $x$, $y$ и $z$ имеют длину $n$ и соответствующие числа удовлетворяют следующим требованиям:
\begin{enumerate}
\item $y$~--- $n$-битовое простое число,
\item $x\in [2,y-1]$, порождает всю мультипликативную группу вычетов
по модулю $y$ (т.е. любой ненулевой вычет является степенью $x$),
\item $z\in [1,y-1]$.
\end{enumerate}
Значение функции на $xyz$ равно конкатенации слов $x$, $y$ и $(x^z\bmod y)$.
Обращение этой функции~--- является дискретным логарифмированием.
\end{enumerate}
Более подробно об этих примерах см. \cite{veresch17}.
\end{example}

\begin{definition}
Частичная функция $f_n: D_n \to \{0,1\}^*$ называется
\emph{проверяемой}, если по $n$, любому слову $x$ длины $k(n)$
и любому слову $y$ из множества значений $f_n$ можно 
за полиномиальное время проверить, верно ли, что $f_n$
определена на $x$ и её значение на $x$ равно $y$.
\end{definition}
\begin{remark}
Неизвестно, является ли функция Рабина проверяемой, т.к. неясно, как за полиномиальное время проверить, является
ли данное число квадратичным вычетом по составному модулю.
\end{remark}


\section{Генераторы псевдослучайных чисел}
\subsection{Вычислительно неотличимые случайные величины}
\begin{definition}[Для неравномерного противника]
Случайные величины $\alpha_n$ и $\beta_n$, зависящие
от натурального параметра $n$, со значениями в множестве
слов некоторой длины $l(n)$ называются \emph{вычислительно
неотличимыми}, если для любой последовательности схем
$C_0,C_1,\dotsc, C_n,\dotsc$ размера $\poly(n)$
(с $l(n)$ входами и одним выходом) вероятность событий
$C_n(\alpha_n) = 1$ и $C_n(\beta_n) = 1$ отличаются на 
пренебрежимо малую величину, т.е. 
$$\bigl|\Pr[C_n(\alpha_n) = 1] - \Pr[C_n(\beta_n) = 1]\bigr|<\epsilon_n,$$
где $\epsilon_n$ убывает быстрее любого обратного полинома.
Схема $C_n$ в этом контексте
называется \emph{тестом} и мы говорим, что случайная величина
$\alpha_n$ проходит тест $C_n$, если $C_n(\alpha_n)= 1$.
Таким образом, мы требуем, чтобы $\alpha_n$ и $\beta_n$
проходили любые тесты полиномиального размера с приблизительно
равной вероятностью.
\end{definition}

\begin{definition}[Для равномерного противника]
Случайные величины $\alpha_n$ и $\beta_n$, зависящие
от натурального параметра $n$, со значениями в множестве
слов некоторой длины $l(n)$ называются \emph{вычислительно
неотличимыми}, если для любого вероятностного 
полиномиального алгоритма $T$ вероятность событий
$T(1^n, \alpha_n) = 1$ и $T(1^n, \beta_n) = 1$ отличаются на 
пренебрежимо малую величину, соответственно
$$\bigl|\Pr[T(1^n, \alpha_n) = 1] - \Pr[T(1^n, \beta_n) = 1]\bigr|<\epsilon_n,$$
где $\epsilon_n$ убывает быстрее любого обратного полинома.
Алгоритм $T$ в этом контексте
называется \emph{тестом} и мы говорим, что случайная величина
$\alpha_n$ проходит тест $T$, если $T(1^n, \alpha_n)= 1$.
\end{definition}

\begin{remark}
Если $\alpha_n$ и $\beta_n$ статистически неотличимы,
то они и вычислительно неотличимы (например, для неравномерного
противника), поскольку разность вероятностей $\alpha_n$
и $\beta_n$ в множество $\{x\mid C_n(x)\}$, задаваемое
тестом $C_n$, не превосходит статистического расстояния
между $\alpha_n$ и $\beta_n$.
\end{remark}

\begin{lemma}[Свойства вычислительной неотличимости]
\mbox{}
\begin{enumerate}
\item Отношение вычислительной неотличимости рефлексивно, симметрично и транзитивно.

\item Для неравномерного противника: вычислительно неотличимые
последовательности случайных величин $\alpha_n$ и $\beta_n$
вычислительно неотличимы и вероятностными тестами 
полиномиального размера. Это означает, что для любой последовательности
$T_n$ вероятностных схем полиномиального от $n$ размера с $l(n)$
входами, вероятности событий $T_n(\alpha_n) = 1$ и $T_n(\beta_n) = 1$
приблизительно равны.

\item Если $\alpha_n$ и $\beta_n$ вычислительно неотличимы,
а $C_n$~--- последовательность вероятностных схем полиномиального размера с $l(n)$ входами, то и случайные
величины $C_n(\alpha_n)$ и $C_n(\beta_n)$ вычислительно
неотличимы. Аналогично для равномерного противника.

\item Пусть случайные величины $\alpha_n$, $\beta_n$
и $\gamma_n$ имеют совместное распределение. И пусть
для любой последовательности значений $c_n$ случайной
величины $\gamma_n$ случайные величины 
$(\alpha_n\mid\gamma_n = c_n)$ и 
$(\beta_n\mid\gamma_n = c_n)$ вычислительно неотличимы.
Тогда и $\alpha_n\gamma_n$ и $\beta_n\gamma_n$ вычислительно
неотличимы.

Для равномерного противника это свойство справедливо только
для независимых случайных величин $\alpha_n$, $\gamma_n$,
причём случайная величина $\gamma_n$ должна быть полиномиально моделируемой.
\end{enumerate}
\end{lemma}
\begin{proof}\mbox{}
\begin{enumerate}
\item[1-2.] Очевидно.
\item[3.] Пусть дана последовательность тестов $T_n$
позволяет отличать $C_n(\alpha_n)$ и $C_n(\beta_n)$.
Тогда последовательность схем $D_n(x) = T_n(C_n(x))$
будет вероятностным тестом полиномального размера 
для случайных величин $\alpha_n$ и $\beta_n$.

\item[4.]
Допустим, что существует последовательность 
схем-тестов $T_n$ полиномиального размера такая, что
вероятность $T_n(\alpha_n\gamma_n) = 1$
$T_n(\beta_n\gamma_n) = 1$ отличается $\epsilon = 1/\poly(n)$
для бесконечно многих $n$. Разность вероятностей
событий $T_n(\alpha_n\gamma_n) = 1$ и
$T_n(\beta_n\gamma_n) = 1$ равна среднему значению разности
вероятностей
$$
\Pr[T_n(\alpha_n c) \mid \gamma_n = c] - 
\Pr[T_n(\beta _n c) \mid \gamma_n = c]
$$
по случайно выбранному $c$ (в соответствии с распределением
случайной величины $\gamma_n$). Поэтому для бесконечно
многих $n$ найдётся $c=c_n$ в множестве значений $\gamma_n$,
для которой разность вероятности не меньше $\epsilon$.
Если ``зашить'' $c_n$ в схему $T_n$, то получится полиномиальный тест, различающий 
$(\alpha_n\mid\gamma_n = c_n)$ и 
$(\beta_n\mid\gamma_n = c_n)$.
\end{enumerate}
\end{proof}

\subsection{Генераторы псевдослучайных чисел}
\begin{definition}
Пусть даны многочлены $k(n)$ и $l(n)$ такие, что
$l(n) > k(n)$ для всех $n$. \emph{Генератором
псевдослучайных чисел типа $k(n)\to l(n)$} будем
называть семейство функций $G_n : \bits^{k(n)}\to \bits^{l(n)}$, удовлетворяющее следующим условиям.
\begin{enumerate}
\item Семейство $G_n$ вычислимо за полиномиальное от $n$ время.
\item (Надежность генератора ПСЧ.) Случайная величина $G_n(s)$ для равномерного случайного $s$ вычислительно неотличима от случайной величины равномерно распределенной
на всех словах длины $l(n)$.
\end{enumerate}
\end{definition}

\begin{definition}
\emph{Генератор псевдослучайных чисел типа $k(n)\to\infty$} будем
называть семейство отображений $G_n: \bits^{k(n)}\to\bitstr$,
удовлетворяющее следующим требованиям.
\begin{enumerate}
\item Существует алгоритм, который по слову $s$ и натуральному числу $l$
вычисляет элемент последовательности $G_n(s)$ с номером $l$ за время, полиномиальное
от $|s| + l$.

\item Случайная величина $G_n(s)$ вычислительно неотличима от равномерно
распределённой бесконечной последовательности нулей и единиц.
(Это означает, что для любого полинома $p(n)$ первые $p(n)$ битов
$G_n(s)$ вычислительно неотличимы от случайной величины равномерно
распределённой на всех словах длины $p(n)$.)
\end{enumerate}
\end{definition}
 
\begin{remark}
По генератору ПСЧ типа $k(n)\to\infty$ можно построить генератор ПСЧ
типа $k(n)\to l(n)$ для любого полинома $l(n)$ (нужно взять первый $l(n)$ битов).
\end{remark}

\begin{theorem}
Если существует генератор ПСЧ $G_n$ типа $k(n)\to l(n)$,
то существуют и односторонние функции.
\end{theorem}
\begin{proof}
Действительно, можно рассмотреть сам генератор $G_n$ как слабо одностороннюю функцию.
Давайте покажем, что никакая последовательность схем полиномиального размера 
$C_n$ не обращает $G_n$ с вероятностью успеха более $3/4$ для бесконечно многих $n$.
Предположим, что такая последовательность существует. Тогда можно рассмотреть
следующий полиномиальный тест для последовательностей длины $l(n)$: для входа $y$ проверяем, что $G_n(C_n(y)) = y$. Если это верно (т.е. обращение произошло удачно), 
то выдаём $1$, а иначе $0$. Вероятность того, что $G_n$ пройдёт такой тест 
не менее $3/4$. При этом равномерно распределённая на $l(n)$ случайная 
величина пройдёт этот тест с вероятностью не более $1/2$ (т.к. размер 
образа $G_n$ не более $1/2$). 
\end{proof}
Обратное утверждение тоже верно. 
\begin{theorem}[\cite{hill}]
Если существует односторонняя функция, то существует
и генератор псевдослучайных чисел типа $n\to\infty$.
\end{theorem}
Мы же докажем более простое утверждение.
\begin{theorem}
Если существует односторонняя перестановка, то существует
и генератор псевдослучайных чисел типа $n\to\infty$.
\end{theorem}

В дальнейшем мы будем говорить про \emph{полиномиального противника}
подразумевая под этим две возможных формулировки: полиномиальный
вероятностный алгоритм и семейство схем полиномиального размера.

\subsection{Трудный бит}
\begin{definition}
Для пары совместно распределённых случайных величин $(\beta_n,\gamma_n)$, где $\beta_n$ распределена на
$\bits$ будем говорить, что $\beta_n$ является \emph{вычислительно трудной} относительно $\gamma_n$, 
если для любого полиномиального противника $B$
$$\left|\Pr[B(\gamma_n) = \beta_n] - \tfrac12\right| < \frac{1}{p(n)}$$
для любого полинома $p$ для достаточно больших $n$.
\end{definition}

\begin{theorem}\label{thm:hard-random-value}
Случайная величина $\beta_n$ вычислительно трудна относительно $\gamma_n$ тогда и только тогда,
когда случайная величина $\beta_n\gamma_n$ вычислительно неотличима от $r_n\gamma_n$, 
где $r_n$~--- это равномерно распределённая на $\bits$ случайная величина.
\end{theorem}
\begin{proof}\mbox{}
\begin{itemize}
\item[$\Leftarrow$] Пусть существует противник $B$, который для бесконечного числа $n$
предсказывает $\beta_n$ по $\gamma_n$ с хорошей вероятностью, т.е.
$$\Pr[B(\gamma_n) = \beta_n]\ge \tfrac12 + \epsilon_n,$$
где $\epsilon_n$~--- обратный полином.
Используя противника $B$ построим противника $A$, который различает $\beta_n\gamma_n$ и $r_n\gamma_n$.
$$A(x,y) = 
\begin{cases}
1, & B(y) = x,\\
0, & B(y) \neq x.
\end{cases}
$$
Тогда $\Pr[A(\beta_n\gamma_n) = 1]\ge\frac12 + \epsilon_n$, а $\Pr[A(r_n\gamma_n) = 1] = \frac12$.

\item[$\Rightarrow$] Пусть существует противник $A$, который для бесконечного числа $n$ 
различает $\beta_n\gamma_n$ и $r_n\gamma_n$ с хорошей вероятностью, т.е.
$$\Pr[A(\beta_n\gamma_n) = 1] - \Pr[A(r_n\gamma_n) = 1]\ge\epsilon_n,$$
где $\epsilon_n$~--- обратный полином.  Построим противника $B$, который предсказывает $\beta_n$ по $\gamma_n$.
$$B(x) = 
\begin{cases}
r, & A(0x) = 0,\ A(1x) = 0,\\
1, & A(0x) = 0,\ A(1x) = 1,\\
0, & A(0x) = 1,\ A(1x) = 0,\\
r, & A(0x) = 1,\ A(1x) = 1,\\
\end{cases}
$$
где $r$ означает случайный бит.

Покажем, что 
$$\Pr[B(\gamma_n) = \beta_n] = \frac12 + \Pr[A(\beta_n\gamma_n) = 1] - \Pr[A(r_n\gamma_n) = 1] \ge \frac12 + \epsilon_n.$$
Давайте докажем это равенство для фиксированного $\gamma_n = x$:
$$\Pr[B(\gamma_n) = \beta_n\mid \gamma_n = x] = 
  \frac12 + \Pr[A(\beta_n\gamma_n) = 1\mid \gamma_n = x] - \Pr[A(r_n\gamma_n) = 1\mid \gamma_n = x].$$
Отсюда по формуле полной вероятности получается требуемое равенство. Для того, чтобы убедиться,
что это равенство верно, нужно подставить все четыре возможные варианта из определения $B$
и проверить, что равенство выполняется. Например, в первом случае вероятность слева будет равна $1/2$,
т.к. $B$ возвращает случайный бит, а справа обе вероятности равны нулю. Для второго случай вероятность
слева будет равна первой вероятности справа, а последняя $=1/2$.

\begin{remark}
В случае неравномерного противника данная конструкция даёт вероятностную схему, 
которую, как описано выше можно переделать в детерминированную. В случае равномерного
противника нам потребовалось бы также фиксировать внутренние биты вероятностного алгоритма.
\end{remark}
\end{itemize}
\end{proof}

\begin{definition}
Для односторонней перестановки $f_n: D_n\to D_n$, где $D_n\subset\bits^{k(n)}$,
будем называть \emph{трудным битом} такую полиномиально вычислимую функцию $h_n: D_n\to\bits$,
для которой случайная величина
$h_n(U(D_n))$ трудна для $f_n(U(D_n))$. 
\end{definition}

\begin{statement}\label{st:hard-bit}
Пусть $f_n:D_n\to D_n$~--- односторонняя перестановка с трудным битом $h_n: D_n\to\bits$.
Тогда случайная величина $h_n(x)f_n(x)$ вычислительно неотличима от $r x$, где $x\gets U(D_n)$,
а $r\gets U_1$.
\end{statement}
\begin{proof}
Заметим, что $f_n(x)$ распределено так же, как $x$ (важно, что $f_n$~--- перестановка). Поэтому
$r f_n(x)$ распределено так же, как $r x$. Осталось применить теорему~\ref{thm:hard-random-value}
для $r f_n(x)$ и $h_n(x)f_n(x)$.
\end{proof}

Это конструкцию можно итерировать. Например, $h_n(x) h_n(f_n(x)) f_n(f_n(x))$ позволяет получить 
два бита. Заметим, что если случайная величина $h_n(x) h_n(f_n(x)) f_n(f_n(x))$ отличима 
от $r h_n(f_n(x)) f_n(f_n(x))$, то отличимы $h_n(x) f_n(x)$ и $r f_n(x)$ (первые можно получить из вторых).
Продолжая рассуждение получаем, что $h_n(x) h_n(f_n(x)) f_n(f_n(x))$ неотличима от $rr'x$, где $r,r'\gets U_1$.

\begin{theorem}
Пусть $f_n:D_n\to D_n$~--- односторонняя перестановка с трудным битом $h_n: D_n\to\bits$.
Тогда случайная величина 
$$h_n(x)h_n(f_n(x))\dotsc h_n(f^{(p(n))})f_n^{(p(n) + 1)}(x)$$
вычислительно неотличима от случайной величины 
$$r_1r_2\dotsc r_{p(n)}x,$$
где $r_1,\dotsc,r_{p(n)}\gets U_1$, $x\gets U(D_n)$.
\end{theorem}
\begin{corollary}
$G_n(x) = h_n(x)h_n(f_n(x))\dotsb h_n(f^{(p(n))})f_n^{(p(n) + 1)}(x)$ является надёжным генератором псевдослучайных чисел.
\end{corollary}
\begin{proof}
Доказательство ,,гибридным`` методом.
$$
\begin{array}{llllll}
T_0 = & h_n(x)&h_n(f_n(x))&\dotsc  &h_n(f^{(p(n)-1)})  &f_n^{(p(n))}(x)\\
T_1 = &r_1   &h_n(x)     &\dotsc  &h_n(f^{(p(n)-2)})&f_n^{(p(n)-1)}(x)\\
T_2 = &r_1   &r_2        &\dotsc  &h_n(f^{(p(n)-3)})&f_n^{(p(n)-2)}(x)\\
\vdots   &\vdots&\vdots     &\dotsc  &\vdots			 &\vdots\\
T_{p(n)}= &r_1   &r_2        &\dotsc  &r_{p(n)}		 &x\\
\end{array}
$$
Пусть взломщик $B$ отличает $T_0$ от $T_{p(n)}$, т.е. $\Pr[B(T_0) = 1] - \Pr[B(T_0) = 1]\ge\epsilon_n$
для бесконечного числа $n$ и обратного полинома $\epsilon_n$. Тогда существует такое $i$, что
$$\Pr[B(T_i) = 1] - \Pr[B(T_{i+1}) = 1]\ge\epsilon_n/p(n).$$ Т.е. мы научились отличать
$$
\begin{array}{llllllll}
r_1   &\dotsc & r_i & h_n(x)  & h_n(f_n(x)) &\dotsc& h_n(f^{(p(n)-i - 1)})    &f_n^{(p(n) - i)}(x)\\
r_1   &\dotsc & r_i & r_{i+1} & h_n(x)      &\dotsc& h_n(f^{(p(n)-i - 2)})&f_n^{(p(n) - i - 1)}(x)\\
\end{array}
$$
%Можно воспользоваться тем, что $x$ распределён также как $f_n(x)$ и переписать $T_{i+1}$
%$$
%\begin{array}{llllllll}
%r_1   &\dotsc & r_i & h_n(x)  & h_n(f_n(x)) &\dotsc& h_n(f^{(p(n)-i-1)}) &f_n^{(p(n) - i)}(x)\\
%r_1   &\dotsc & r_i & r_{i+1} & h_n(f_n(x)) &\dotsc& h_n(f^{(p(n)-i-1)}) &f_n^{(p(n) - i)}(x)\\
%\end{array}
%$$
Используя противника, который отличает эти две случайные величины мы можем отличать $h_n(x)f_n(x)$ от $r x$~---
по этим случайным величинам можно детерминированным алгоритмом построить соответствующие значения $T_{i}$ и $T_{i+1}$, что противоречит утверждению \ref{st:hard-bit}.

\begin{remark}
В этом доказательстве мы воспользовались тем, что наш у нас неравномерный противник, т.е. для схема,
т.к. мы в эту схему зашили число $i$. В случае с алгоритмами можно взять случайное $i$ и доказать, 
что с хорошей вероятностью оно подойдёт.
\end{remark}
\end{proof}

\begin{theorem}[Голдрейх, Левин]
Пусть $f_n:D_n\to D_n$~--- односторонняя перестановка, $D_n\subseteq \bits^{k(n)}$.
Рассмотрим две функции: $g_n: D_n\times \bits^{k(n)}\to D_n\times \bits^{k(n)}$ и $h_n: D_n\times \bits^{k(n)}\to \bits$, такие что
$$g_n(xy)= f_n(x)y,\quad h_n(x,y) = x\odot y = \bigoplus_{i=1}^{k(n)} x_iy_i = \sum_{i=1}^{k(n)} x_iy_i\mod2.$$ 
Тогда $g_n$~--- односторонняя перестановка
с трудным битом $h_n$.
\end{theorem}

\begin{definition}
\emph{Код Уолша-Адамара}~--- это код исправляющий ошибки $WH: \bits^k\to\bits^{2^k}$,
определяющий следующим соотношением $WH(x)=(x\odot y)_{y\in\bits^{k}}$.
\end{definition}
Код Уолша-Адамара не очень удобен в практических применениях, 
т.к. он удлиняет строки в экспоненту раз.
Однако он обладает одним очень хорошим свойством.
\begin{statement}
Код Уолша-Адамара имеет расстояние $2^{k-1}$.
\end{statement}
\begin{proof}
Пусть $x_i\neq y_i$. Рассмотрим $r$ и $r^{\oplus i}$, где $r,r^{\oplus i}\in\bits^{k}$ и отличаются только в бите $i$.
Тогда либо $x\odot r$ отличается от $x\odot r^{\oplus i}$, либо $y\odot r$ отличается от $y\odot r^{\oplus i}$.
Т.е. все $\bits^k$ можно разбить на пары, различающиеся в одном бите, то все пары строк имеют коды, отличающиеся
ровно в половине всех битов.
\end{proof}

\begin{lemma}\label{lm:WH-list-decoding}
Пусть $s\in\bits^{2^m}$ и $\Pr_i[s_i \neq WH(x)] \le 1/2 - \epsilon$ (в терминах расстояния Хеммнига $\Delta(WH(x), s) \le (1/2 - \epsilon)2^m$). Существует вероятностный алгоритм $A^s$ со временем работы $\poly(m, \frac{1}{\epsilon})$, который выдаёт
список $L$ слов длины $m$ такой, что $x\in L$ с вероятностью не менее $1/2$ (алгоритм получает оракульный доступ к строке $s$).
\end{lemma}

\begin{proof}[Доказательство теоремы Голдрейха-Левина]
Функция $g_n$ является перестановкой. Легко показать, что если противник взламывает
$g_n$, то он взламывает и $f_n$, т.е. $g_n$ является односторонней перестановкой.

Теперь нужно показать, что $h_n$ является трудным битом $g_n$. 
Пусть существует неравномерный противник $B$ (в дальнейшем будем предполагать, 
что противник~--- это всегда семейство схем), который предсказывает $h_n$, т.е. 
$$\Pr_{\substack{x\gets U(D_n), y\gets U_{k(n)}}} [B(f(x)y) = x\odot y] \ge 1/2 + \epsilon_n$$
для бесконечного числа $n$ и обратного полинома $\epsilon_n$. Построим противника $C$,
который обращает $f_n$, т.е.
$$\Pr_{x\gets U(D_n)}[C(f_n(x)) = x]\ge \epsilon_n/4.$$
Противник $C$ будет использовать алгоритм декодирования списком кода Уолша-Адамара из леммы~\ref{lm:WH-list-decoding}
и при обращении к биту $y$ выдаём значение $B(f(x)y)$.
В списке $L$, который возвращает алгоритм $A$ ищем $z$ такое, что $f_n(z) = f_n(x)$. Если такое $z$ нашлось, то выдаём его, 
иначе выдаём любую строку.

Пусть $M\subseteq D_n$ и $x\in M\iff \Pr_{y\gets U_{k(n)}}[B(f_n(x)y) = x\odot y]\ge 1/2 + \epsilon_n/2.$
Давайте покажем, что $\Pr_{x\gets U(D_n)} [x\in M]\ge \epsilon_n/2$. Пусть это не так, тогда
$$
\begin{aligned}
\Pr_{x,y}[B(f_n(x)y) = x\odot y] &= 
    \Pr_{x,y}[B(f_n(x)y) = x\odot y \mid x    \in M] \cdot \Pr_x[x    \in M]\\ 
&+  \Pr_{x,y}[B(f_n(x)y) = x\odot y \mid x\not\in M] \cdot \Pr_x[x\not\in M]\\
&< 1 \cdot \epsilon_n/2 + (1/2 + \epsilon_n/2) \cdot 1 < 1/2 + \epsilon_n.
\end{aligned}
$$

Заметим, что $\Pr_{x}[C(f_n(x)) = x\mid x\in M]\ge 1/2,$ т.к. с вероятность не менее $1/2$ в списке будет искомый элемент.
Поэтому получаем
$$
\Pr_{x} [C(f_n(x)) = x]\ge \Pr_{x} [C(f_n(x)) = x\mid x\in M]\cdot \Pr_x[x    \in M]
\ge \frac12 \cdot \frac{\epsilon_2}{2} = \frac{\epsilon_n}{4}.
$$
\end{proof}
\begin{proof}[Доказательство леммы~\ref*{lm:WH-list-decoding}]
Будем рассматривать код Уолша-Адамара как таблицу истинности некоторой функции $f:\{0,1\}^m\to 1$.
Пусть $WH(x)$ соответствует $f$, а кодовое слово $s$~--- некоторой функции $\tilde{f}$. Таким 
образом для восстановления $x$ нам нужно вычислить $f$ на входах $100\dotsb0$, $010\dotsb0$, $001\dotsb0$,\ldots
Действительно, 
$$
\begin{aligned}
&x_1 = f(100\dotsb0)\\
&x_2 = f(010\dotsb0)\\
&\vdots\\
&x_n = f(000\dotsb 1)
\end{aligned}
$$
Используя линейность $f$ мы можем вычислять $f(z)$ следующим образом: 
выберем случайный $r$ и вычислим $f(z) = f(r) \oplus f(z \oplus r)$. Проблема в том,
что доступа к $f$ у нас нет, а есть доступ к $\tilde{f}$, про которую известно
$\Pr_y[f(y) \neq \tilde{f}(y)]\le 1/2 - \epsilon.$
Используя идею с линейностью мы можем попробовать вычислять 
$f(z) = \tilde{f}(r) \oplus \tilde{f}(z \oplus r)$ (добавление $r$ позволяет вычислять
$\tilde{f}$ в \emph{случайной} точке, в то время как значение $\tilde{f}$
на строках вида $00\cdots010\cdots00$ может быть неправильным).
Если бы ошибка в $\tilde{f}$ случалась с вероятностью менее $1/4-\epsilon$,
то суммарная ошибка при таком вычислении $f(z)$ была бы не более $1/2 - 2\epsilon$.
Тогда мы могли бы её амплифицировать и получить $f(z)$ с хорошей вероятностью.
Однако, ошибка в $f$ случается с большей вероятностью.

\paragraph{Идея.} Если бы у нас был доступ к истинному значению, то тогда бы тоже всё сработало
$f(z) = f(r) \oplus \tilde{f}(z \oplus r)$. Предположим, 
что мы всё же умеем вычислять $f(r)$ вместо $\tilde{f}(r)$. Тогда мы можем вычислить $f(z)$ 
следующим образом: выберем случайные $r_1,r_2,\dotsc,r_N$ 
и вычислим $\maj_i\{f(r_i) \oplus \tilde{f}(z \oplus r_i)\}$.
С хорошей вероятностью полученное значение будет совпадать с $f(z)$. Чтобы оценить это давайте вспомним следующий
факт из теории вероятностей.

\begin{remark}{Неравенство Чебышёва (закон больших чисел для 2-независимых случайных величин).}
Пусть $X_1,X_2,\dotsc,X_N$~--- одинаково распределённые попарно-независимые 
Бернулиевские случайные величины, $\forall i, \Pr[X_i = 1] = p$, тогда
$$\Pr\Biggl[ \biggl|\frac{\sum_i X_i}{N} - p\biggr| \ge \delta \Biggr]\le \frac{1}{\delta^2 N}.$$
\end{remark}

Для применения этого неравенства нам нужны попарно независимые случайные величины. Пусть $N=2^k - 1$, конкретное значение для $N$ мы определим позже. 
Выберем $t_1,t_2,\dotsc,t_k\gets U_m$~--- независимые случайные строки.
Из этих случайных строк можно сгенерировать $N$ попарно независимых следующим образом:
$$\forall J\subseteq \{1,\dotsc,k\},\ J\neq\emptyset,\ r_J = \bigoplus_{i\in J} t_i.$$

\begin{statement}
Если $J_1 \neq J_2$, то $r_{J_1}$ и $r_{J_2}$ будут независимыми.
\end{statement}
\begin{corollary}
$\{r_J\}_J$~--- 2-независимые случайные величины.
\end{corollary}

Теперь опишем алгоритм декодирования кода Уолша-Адамара используя нашу идею с
вычисление $f(r)$. Сгененируем независимые $t_1,t_2,\dotsc,t_k\gets U_m$ и
по ним определим $r_J = \bigoplus_{i\in J} t_i$, $J\subset [n], J\neq\emptyset$.
Так как доступа к $f$ у нас нет, то вычислить $f(r)$ мы не можем. Вместо этого
мы переберём все значения для $f(r)$. Если бы все $r$ были независимы, то нам
пришлось бы перебрать $2^N$ различных значений. Однако, наши $r$ получаются
из $k$ строк $t_i$. Поэтому достаточно перебрать значения $f$ на $t_i$.
Пусть $\forall i, a_i = f(t_i)$, тогда 
$$f(r^{J}) = f\Bigl(\bigoplus_{j\in J} t_j\Bigr) = \bigoplus_{j\in J} f(t_j) = \bigoplus_{j\in J} a_j.$$
Таким образом, алгоритм декодирования для всех возможных $a_1, \dotsc, a_k\in \{0,1\}$ добавит 
в список $L$ строку $x_1,\dotsc,x_m$, полученную по следующей процедуре: 
$$x_i = \maj_J\Bigl\{\bigoplus_{j\in J} a_j \oplus \tilde{f}\bigl((0\dotsb\underset{i}{1}\dotsb 0) \oplus r^J\bigr)\Bigr\},$$

Для успеха $x_i$ должен быть верен с вероятностью не менее $1 - \frac{1}{10m}$
(тогда весь $x$ мы угадаем с вероятностью $\ge9/10$).
Определим случайные величины $\{X^J_i\}$ такие, что 
$$X^J_i = 1\iff \tilde{f}\bigl((0\dotsb\underset{i}{1}\dotsb 0) \oplus r^J\bigr) 
= f\bigl((0\dotsb\underset{i}{1}\dotsb 0) \oplus r^J\bigr).$$
Пусть $p = \Pr[X^J_i = 1] \ge 1/2 + \epsilon.$ По закону больших чисел вероятность того, что при вычислении $\maj$ мы получим более половины неправильных
значений $\tilde{f}$ не более $\frac{1}{\epsilon^2 N}$. 

\begin{align*}
\Pr[\text{$x_i$ ошибочный}] 
&= \Pr\Biggl[\sum_J \frac{X^{J}_i}{N} \le \frac{1}{2}\Biggr]\\
&= \Pr\Biggl[\sum_J \frac{X^{J}_i}{N} - \biggl(\frac{1}{2} + \epsilon\biggr) \le -\epsilon\Biggr]\\
&\le \Pr\Biggl[\Biggl|\sum_J \frac{X^{J}_i}{N} - \biggl(\frac{1}{2} + \epsilon\biggr)\Biggr| \ge \epsilon\Biggr]\\
&\le \Pr\Biggl[\Biggl|\sum_J \frac{X^{J}_i}{N} - p\Biggr| \ge \epsilon\Biggr] \le \frac{1}{\epsilon^2 N}.
\end{align*}
Таким образом, мы требуем, чтобы $\frac{1}{\epsilon^2 N} \le \frac{1}{10m}$,
следовательно $N\ge\frac{10m}{\epsilon^2}.$
\end{proof}

\section{Протоколы шифрования с секретным ключом}
\begin{definition}
Пусть дана доступная случайная величина $d_n$. \emph{Одноразовый протокол с секретным ключом} задаётся двумя вероятностными полиномиальными алгоритмами
$E(d,x)$ и $D(d, m)$, такими, что $D(d, E(d, x)) = x$.
Будем говорить, что этот протокол \emph{надёжный}, если для некоторого полинома $l$ и любых последовательный строк $x_n$ и $y_n$ длины $l(n)$ случайные величины $E(d_n, x_n)$ и $E(d_n, y_n)$ вычислительно неотличимы.
\end{definition}

Такой протокол мы уже можем построить. Возьмём генератор псевдослучайных чисел $G: \bits^n\to\bits^{l(n)}$.
Возьмём $d_n = U_n$ и для $x\in\bits^{l(n)}$ определим 
$$
\begin{aligned}
E(d, x) &= G(d) \oplus x,\\ D(d, m) &= G(d) \oplus m.
\end{aligned}
$$
Если бы противник научился отличать случайные величины $E(d_n, x_n)$ и $E(d_n, y_n)$, то 
он также научился бы отличать одну из этих случайных величин от равномерного распределения
$U_{l(n)}$. Пусть он умеет отличать $E(d_n, x_n)$ от $U_{l(n)}$. Тогда мы можем зашить $x_n$ в схему 
и таким образом научиться отличать образ $G(d_n)$ от $U_{l(n)}$.

\begin{definition}
Пусть $S_n \subseteq\bits^{l(n)}$ и для любого $s\in S_n$ определена функция $f^s_n: \bits^n\to\bits^n$.
Множество функций $\{f^s_n\}_{s\in S_n}$ называется \emph{семейством псевдослучайных функций}, если 
выполняются следующие свойства.
\begin{enumerate}
\item Существует полиномиальный алгоритм, который по $(s, x)$ вычисляет $f^s_n(x)$.
\item Распределение $U(S_n)$ доступно.
\item (\emph{слабая надёжность}) Для любого полинома $p$ и для любого набора различных 
строк $t_1,\dotsc, t_{p(n)}\in \bits^n$ случайная величина $f^s_n(t_1)f^s_n(t_2)\dotsb f^s_n(t_{p(n)})$ 
вычислительно неотличима от $U_{np(n)}$, где $s\gets U(S_n)$.
\item[$3'$.] (\emph{сильная надёжность}) Для любого полинома $p$, любого семейства схем полиномиального размера
$\{C_i\}_{i=1}^{p(n) - 1}$ и любого $t_1\in\{0,1\}^n$ определим случайные величины 
$\{y_i\}_{i=1}^{p(n)}$ следующим образом:
$$
\begin{aligned}
s   &\gets U(S_n),\\
y_1 &= f^s_n(t_1),\\
t_2 &= C_1(t_1, y_1),\\
y_2 &= f^s_n(t_2),\\
t_3 &= C_2(t_1, y_1, y_2),\\
y_3 &= f^s_n(t_3),\\
&\vdots
\end{aligned}
$$
Тогда случайная величина $y_1y_2\dotsb y_{p(n)}$ вычислительно неотличима от $U_{np(n)}$ (при условии, что все $t_i$ различны).
\end{enumerate}
\end{definition}

\begin{theorem}
Если существует генератор псевдослучайных чисел, то существует и семейство псевдослучайных функций.
\end{theorem}
\begin{proof}
Пусть $G_n:\bits^n\to\bits^{2n}$. Мы построим семейство псевдослучайных функций $\{f^s_n\}_{s\in S_n}$, где $S_n = \bits^n$, $f^s_n: \{0,1\}^n\to\{0,1\}^n$. Для этого определим функции $G_n^{(0)},G_n^{(1)}: \bits^n\to\bits^n$ исходя из следующего соотношения:  
$$G_n(r) = G_n^{(0)}(r)\; G_n^{(1)}(r).$$ Тогда  
$$f^s_n(x) = G_n^{(x_n)}(\dotsb G_n^{(x_2)}(G_n^{(x_1)}(s))  \dotsb).$$
Можно представить вычисление $f^s_n$ на всевозможных $x$ в виде бинарного дерева: 
в корне записано число $s$; если в вершине записано число $z$, то в его наследниках будут записаны $G^{(0)}(z)$ 
и $G^{(1)}(z)$; в листьях дерева будут все возможные $f^s_n(x)$.

% Set the overall layout of the tree
\tikzstyle{level 1}=[level distance=0.5cm, sibling distance=5.5cm]
\tikzstyle{level 2}=[level distance=1cm, sibling distance=2.7cm]
\tikzstyle{level 3}=[level distance=1.5cm, sibling distance=1.3 cm]

% Define styles for bags and leafs
\tikzstyle{bag} = []
\tikzstyle{end} = [circle, minimum width=3pt,fill, inner sep=0pt]

% The sloped option gives rotated edge labels. Personally
% I find sloped labels a bit difficult to read. Remove the sloped options
% to get horizontal labels. 
\begin{center}
\begin{tikzpicture}[grow=down, sloped]
\node[bag] {$s$}
    child {
        node[end] {}        
            child {
                node[end] {}
	            child {
	                node[end, label={below:$f^s_n(000)$}] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end, label={below:$f^s_n(001)$}] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent
                node[above] {$G^{(0)}$}
            }
            child {
                node[end] {}
	            child {
	                node[end, label={below:$f^s_n(010)$}] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end, label={below:$f^s_n(011)$}] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent
                node[above] {$G^{(1)}$}
            }
            edge from parent 
            node[above] {$G^{(0)}$}
    }
    child {
        node[end] {}        
            child {
                node[end] {}
	            child {
	                node[end, label={below:$f^s_n(100)$}] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end, label={below:$f^s_n(101)$}] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent
                node[above] {$G^{(0)}$}
            }
            child {
                node[end] {}            
	            child {
	                node[end, label={below:$f^s_n(110)$}] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end, label={below:$f^s_n(111)$}] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent
                node[above] {$G^{(1)}$}
            }
        edge from parent 
        node[above] {$G^{(1)}$}
    };
\end{tikzpicture}
\end{center}
Будем доказывать гибридным методом. Для этого нам нужно построить последовательность распределений,
которые постепенно сходятся к равномерному. Изначальное распределение задаёт дерево $T_0$, в корне которого
выбирается $s$, а дальше вычисление происходит детерминировано.
Каждое $t_i$ задаёт некоторый путь от корня к листьям. Мы будем модифицировать исходное дерево следующим образом: для каждой вершины на пути соответствующему $t_1$ мы будем удалять эту вершину из дерева
и заменять её сыновей на случайные строки из $U(S_n)$.

\begin{center}
\begin{tikzpicture}[grow=down, sloped]
\node[bag] {$s$}
    child {
        node[end] {}        
            child {
                node[end] {}
	            child {
	                node[end, label={below:$f^s_n(000)$}] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end, label={below:$f^s_n(001)$}] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[thin]
                node[above] {$G^{(0)}$}
            }
            child {
                node[end] {}
	            child {
	                node[end, label={below:$f^s_n(\mathbf{010})$}] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end, label={below:$f^s_n(011)$}] {}
	                edge from parent[thin]
	                node[above] {$G^{(1)}$}
	            }
                edge from parent
                node[above] {$G^{(1)}$}
            }
            edge from parent[thick]
            node[above] {$G^{(0)}$}
    }
    child {
        node[end] {}        
            child {
                node[end] {}
	            child {
	                node[end, label={below:$f^s_n(100)$}] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end, label={below:$f^s_n(101)$}] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent
                node[above] {$G^{(0)}$}
            }
            child {
                node[end] {}            
	            child {
	                node[end, label={below:$f^s_n(110)$}] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end, label={below:$f^s_n(111)$}] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent
                node[above] {$G^{(1)}$}
            }
        edge from parent 
        node[above] {$G^{(1)}$}
    };
\end{tikzpicture}

Для примера $t_1=010$.
\end{center}

\begin{center}
\begin{tikzpicture}[grow=down, sloped]
\node[bag] {}
    child {
        node[bag] {$s_1$}
            child {
                node[end] {}
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[thin,solid]
                node[above] {$G^{(0)}$}
            }
            child {
                node[end] {}
	            child {
	                node[end] {}
	                edge from parent[thick]
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent[thin]
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[thick,solid]
                node[above] {$G^{(1)}$}
            }
            edge from parent[dashed]
    }
    child {
        node[bag] {$s_2$}        
            child {
                node[end] {}
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[solid]
                node[above] {$G^{(0)}$}
            }
            child {
                node[end] {}            
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[solid]
                node[above] {$G^{(1)}$}
            }
        edge from parent[dashed]
    };
\end{tikzpicture}

Удаляем корневую вершину и заменяем её сыновей на $s_1,s_2\gets U(S_n)$
\end{center}

\begin{center}
\begin{tikzpicture}[grow=down, sloped]
\node[bag] {}
    child {
        node {}
            child {
                node {$s_1$}
	            child {
	                node[end] {}
	                edge from parent[solid]
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent[solid]
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[dashed]
            }
            child {
                node {$s_2$}
	            child {
	                node[end] {}
	                edge from parent[solid,thick]
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent[solid,thin]
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[dashed]
            }
            edge from parent[dashed]
    }
    child {
        node {$s_3$}        
            child {
                node[end] {}
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[solid]
                node[above] {$G^{(0)}$}
            }
            child {
                node[end] {}            
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[solid]
                node[above] {$G^{(1)}$}
            }
        edge from parent[dashed]
    };
\end{tikzpicture}

Удаляем следующую вершину и заменяем сыновей на случайные элементы из $U(S_n)$.
\end{center}

\begin{center}
\begin{tikzpicture}[grow=down, sloped]
\node[bag] {}
    child {
        node[bag] {}
            child {
                node {$s_1$}
	            child {
	                node[end] {}
	                edge from parent[solid]
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent[solid]
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[dashed]
            }
            child {
                node {}
	            child {
	                node {$s_2$}
	                edge from parent
	            }
	            child {
	                node {$s_3$}
	                edge from parent
	            }
                edge from parent[dashed]
            }
            edge from parent[dashed]
    }
    child {
        node[bag] {$s_4$}        
            child {
                node[end] {}
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[solid]
                node[above] {$G^{(0)}$}
            }
            child {
                node[end] {}            
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[solid]
                node[above] {$G^{(1)}$}
            }
        edge from parent[dashed]
    };
\end{tikzpicture}

Удаляем последнюю вершину и заменяем сыновей на случайные элементы из $U(S_n)$.
\end{center}
В конце этого процесса в вершине, которая раньше соответствовала $t_1$,
будет некоторый $s_j\gets U(S_n)$.
Мы повторим этот процесс для всех $t_i$. Таким образом получится последовательность из $n\cdot p(n) + 1$ дерева, которые задают распределения
$\{T_i\}_{i=0}^{np(n)}$. В последнем распределении $T_{n p(n)}$
значение для каждого $f^s_n(t_i)$ выбирается из $U(S_n)$, т.е. это соответствует равномерному распределению.
 
Если существует противник, который отличает первое распределение от последнего,
то существуют и два последовательных распределения, которые этот противник различает с хорошей вероятностью:
$$
\Pr_{z\gets T_0}[B(z) = 1] - \Pr_{z\gets T_{np(n)}}[B(z) = 1] \ge \epsilon_n \implies
\exists i: \Pr_{z\gets T_i}[B(z) = 1] - \Pr_{z\gets T_{i+1}}[B(z) = 1] \ge \frac{\epsilon_n}{np(n)}.
$$
Дерево распределения $T_{i+1}$ отличается от $T_i$ в трёх вершинах:
\begin{center}
\tikzstyle{level 1}=[level distance=1.5cm, sibling distance=1.5cm]
\begin{tikzpicture}[grow=down, sloped]
\node[bag] {$s_v$}
    child {
        node[end, label={below:$G^{(0)}(s_v)$}] {}
        edge from parent[solid]
    }
    child {
        node[end, label={below:$G^{(1)}(s_v)$}] {}        
        edge from parent[solid]
    };
    \node at (0,-3) {$T_i$};
\end{tikzpicture}\hspace{1cm}
\begin{tikzpicture}[grow=down, sloped]
\node[bag] {\vphantom{$s_v$}}
    child {
        node[end, label={below:$s_u$\vphantom{$G^{(1)}()$}}] {}
        edge from parent[dashed]
    }
    child {
        node[end, label={below:$s_w$\vphantom{$G^{(1)}()$}}] {}        
        edge from parent[dashed]
    };
    \node at (0,-3) {$T_{i+1}$};
\end{tikzpicture}
\end{center}
Таким образом противник может отличить образ генератора $G(s_v) = G^{(0)}(s_v)G^{(1)}(s_v)$ от полностью случайной строки $s_us_w$
с вероятностью больше $\epsilon_n/(n\cdot p(n))$.
\end{proof}
\begin{remark}
Это было доказательство надёжности в смысле п.3. 
То же самое доказательство работает и для п.$3'$. 
\end{remark}

\begin{definition}
Пусть $d_n$~--- доступная случайная величина $d_n\in\bits^{k(n)}$.
\emph{Многоразовый протокол с секретным ключом}~--- это пара
полиномиальных вероятностных алгоритмов $E(d, x)$ и 
$D(d, m)$ таких, что $D(d, E(d, x)) = x$, и выполняются
следующее условие надёжности.
\begin{enumerate}[label=\alph*)]
\item (\emph{слабая надёжность}) Для любых полиномов $p$ и $q$ и для любого набора сообщений $x_1,\dotsc,x_{p(n)}\in\bits^{q(n)}$ при $d\gets d_n$
случайные величины $E(d,x_1)\dotsb E(d,x_{p(n)})$ и
$E(d,0^{q(n)})\dotsb E(d,0^{q(n)})$ вычислительно неотличимы.
\item (\emph{сильная надёжность})
 Для любых полиномов $p$ и $q$, любого $x_1\in\bits^{q(n)}$
 и семейства полиномиальных схем $\{C_i\}_{i=1}^{p(n) - 1}$
 определим $\{x_i\}_{i=2}^{p(n)}$ следующим образом:
 $$
 \begin{aligned}
 d&\gets d_n,\\
 c_1 &= E(d, x_1),\\
 x_2 &= C_1(x_1, c_1),\\
 c_2 &= E(d, x_1),\\
 x_3 &= C_2(x_1, c_1,c_2),\\
 c_3 &= E(d, x_2),\\
 x_4 &= C_3(x_1, c_1, c_2, c_3),\\
 &\ \;\vdots\\ 
 x_{p(n)} &= C_{p(n)-1}(x_1, c_1,\dotsc,c_{p(n) - 1}),\\
 c_{p(n)} &= E(d, x_{p(n)}).\\
 \end{aligned}
 $$
Тогда получившаяся случайная величина $c_1,\dotsc,c_{p(n)}$ вычислительно неотличима от случайной величины
$E(d,0^{q(n)})\dotsb E(d,0^{q(n)})$.
\end{enumerate}
\end{definition}

\begin{theorem}
Если существует семейство псевдослучайных функций, то существует и многоразовый протокол с секретным ключом.
\end{theorem}
\begin{proof}
Докажем для сообщения из одного бита. Из этого будет следовать, что есть протокол для сообщения любой длины.
Пусть $f_s:\bits^n\to\bits$~--- семейство псевдослучайных функций, $s\in\bits^n$. Тогда $d_n = U_n$.  Алгоритм шифрования $E(d,m)$ для ключа $d\gets d_n$ и бита $m\in\bits$ выбирает $z\gets U_n$ и выдаёт $(m\oplus f_{d}(z),z)$. Алгоритм дешифровки $D(d, y)$, где $y\in\bits^{n+1}$, $y=bz$, выдаёт $b\oplus f_{d}(z)$. Корректность
протокола очевидна. Нужно доказать многоразовую надёжность.

Пусть коды сообщений $m_1,\dotsc,m_{p(n)}$ соответственно
$$(f_{d}(z_1)\oplus m_1,z_1),(f_{d}(z_2)\oplus m_2,z_2),\dotsc,(f_{d}(z_{p(n)})\oplus m_{p(n)},z_{p(n)}).$$
Нужно показать, что такая случайная величина вычислительно неотличима
от строки из $U_{(n+1)\cdot p(n)}$. Если это не так, то 
мы могли бы отличить псевдослучайные функции от равномерного распределения (см. соответствующее определение надёжности
псевдослучайных функций).
\end{proof}
\begin{remark}
У этой схемы есть существенный недостаток: длина шифра в $n+1$ раз
длиннее самого сообщения.
\end{remark}
\subsection{Эффективная схема шифрования с закрытым ключом}
Для шифрования сообщений $m\in\bits^{k(n)}$ возьмём семейство псевдослучайных
функций $f^{s}: \bits^n\to\bits^{n}$, где $s\in S_n = \bits^n$, и генератор псевдослучайных чисел $G:\bits^n\to\bits^{k(n)}$. 
Тогда алгоритм шифрования
может быть устроен так: выберем случайное $z\gets U_{n}$ и 
определим $E(d, m) = (G(f^{d}(z))\oplus m, z)$,
$D(d, (c,z)) = G(f^{d}(z))\oplus c$.
\begin{statement}
Описанная схема шифрования надёжна.
\end{statement}
\begin{proof}[Схема доказательства]
Доказываем гибридным методом в два этапа. 
Сначала заменяем функции $f^s$ на случайные строки длины $n$ (за один шаг), а потом заменяем применения генераторов на случайные строки длины $k(n)$ (за $p(n)$ шагов). 
\end{proof}

\section{Протоколы шифрования с открытым ключом}
\begin{definition}
Пусть $(e_n, d_n)$~--- доступные случайные величины. Пара вероятностных 
полиномиальных алгоритмов $(E,D)$ называется 
\emph{системой шифрования с отрытым ключом}, если 
алгоритмы шифрования и дешифрования, $E(e,m)$ и $D(e,d,c)$, связанны
следующим соотношением (корректность):
$D(e, d, E(e, m)) = m$.
\emph{Надёжность} протокола определяется следующим
образом: для любого полинома $p$
и любых сообщений
$x,y\in\bits^{p(n)}$ случайные величины $\langle e, E(e, x)\rangle$ и $\langle e,E(e, y)\rangle$
вычислительно неотличимы для $e\gets e_n$.
\end{definition}

\begin{remark}
В такой системе шифрования значение $e$ сообщается всем (\emph{публичный ключ}), 
а $d$~--- никому (\emph{секретный ключ}). 
\end{remark}

\begin{remark}
Шифрование с закрытым ключом называют \emph{симметричным} (для шифрования и дешифрования используется один и тот же ключ), а шифрование с открытым ключом~--- \emph{асимметричным} (ключи разные). 
\end{remark}

\begin{remark}
Для протоколов с открытым ключом из одноразовой надежности следует многоразовая надежность.
\end{remark}

\begin{definition}[trapdoor permutation family]
Пусть задан полиномиальный вероятностный алгоритм $K$,
который получив на вход $1^n$ генерирует пару слов 
$\langle e, d \rangle$ или выдаёт $\perp$ (символ неудачи),
причём последнее происходит с пренебрежимо малой вероятностью.
%Будем называть \emph{необратимой перестановкой с секретом} семейство 
%перестановок $f_n^e: D_n^e\to D_n^e$ такое,
%что функция $\langle e,x\rangle\to\langle e, f_n^e(x)\rangle$~--- 
%односторонняя.
Слова $e$ и $d$ называются соответственно \emph{открытым и закрытым ключами}. 
Будем через $A_n$ обозначать первые компоненты
всех возможных пар $\langle e,d\rangle$, генерируемых
алгоритмом $K$ на входе $1^n$. Пусть для каждого $e\in A_n$
задана перестановка $f_n^e$ некоторого множества слов $D_n^e$
длины $l(n)$. Последовательность пар 
$\{(\langle e_n, d_n\rangle, f_n^e )\}$
будем называть \emph{семейством односторонних перестановкой с секретом},
если выполнены следующие условия.
\begin{enumerate}
\item (Доступность равномерного распределения на области определения).
Существует вероятностный полиномиальный алгоритм $B$,
который по $1^n$ и любому $e\in A_n$ генерирует случайную
величину, статистически неотличимую от равномерно 
распределённой на $D_n^e$ случайной величины при известном $e_n$.
(Т.е. пара, состоящая из $e$ и выхода алгоритма $B$
статистически неотличима от пары, состоящей из $e$ и 
случайной строки $D_n^e$.)

Из этого условия следует доступность случайной величины $\langle e, U(D_n^e) \rangle.$

\item (Полиномиальная вычислимость.) Функция 
$\langle 1^n, e,x \rangle\to f_n^e(x)$ вычислима
за полиномиальное от $n$ время.

\item (Необратимость.) Для любой последовательности
схем $C_n$ полиномиального размера вероятность того,
что $C_n$ по $\langle e,f_n^e(x) \rangle$ найдёт $x$,
стремится к нулю быстрее любого обратного полинома от $n$
($e$ выбирается случайно из $A_n$, 
$x$ выбирается случайно из $D^e_n$).

\item (Возможность обращения при известном закрытом ключе.)
Существует полиномиальный вероятностный алгоритм, который
по тройке $\langle 1^n, d, f_n^e(x) \rangle$ с вероятностью
близкой к $1$ вычисляет $x$. Здесь пара
$\langle e,d \rangle$ выбирается генератором случайной
величины $\langle e_n,d_n \rangle$, а $x$ выбирается
равномерно в $D_n^e$.
\end{enumerate}
\end{definition}

\begin{remark}
Предположение о существовании односторонних перестановок
с секретом сильнее, чем существование односторонних
функций. Если функция Рабина или RSA является односторонней,
то существуют односторонние перестановки с секретом.
\begin{itemize}
\item В случае RSA открытым ключом будет $\langle p\cdot q,z\rangle$, а закрытым $z^{-1}\bmod \phi(p\cdot q)$.
\item В  функции Рабина открытым ключом будет $p\cdot q$, а секретным ключом будет $\langle p, q \rangle$.
\end{itemize}
\end{remark}

\begin{definition}
Для односторонней перестановки с секретом $f_n^e: D_n\to D_n$, где $D_n\subset\bits^{k(n)}$,
будем называть \emph{трудным битом} такую полиномиально вычислимую функцию $h_n: D_n\to\bits$,
для которой случайная величина
$h_n(U(D_n))$ трудна для $\langle e, f_n^e(U(D_n))\rangle$. 
\end{definition}


\begin{theorem}
Если существует семейство перестановок с секретом, то существует протокол с открытым ключом.
\end{theorem}
\begin{proof}
Заметим, что если есть многоразовая надёжность, то достаточно научиться шифровать сообщения из
одного бита (будем пересылать сообщение зашифрованное побитово). 
Воспользуемся теоремой Голдрейха-Левина и по перестановке с секретом $f^e_n$ построим
перестановку с секретом $g^e_n$ c трудным битом $h^e_n$:
$$g^e_n(x,r) = f^e_n(x)r, \quad h^e_n(x,r) = x\odot r.$$
\begin{statement}
Величина $h^e_n(x, r)$ является трудной для $\langle e, g^e_n(x,r)\rangle$.
\end{statement}
\begin{proof}
Аналогично доказательству теоремы Голдрейха-Левина.
\end{proof}
Теперь построим протокол для кодирования одного бита. Для ключей $\langle e,d \rangle\gets K$:
\begin{itemize}
\item алгоритм $E(e, m)$, где $m \in\bits$, выбирает случайный элемент $x\gets U(D_n)$, случайные биты $r\gets U_{l(n)}$ и выдаёт $\langle m\oplus h^e_n(x,r), g_n^e(x,r)\rangle$;

\item алгоритм $D(e, d, \sigma y r)$ вычисляет $x = (f^e_n)^{-1}(y)$ и возвращает $\sigma\oplus h^e_n(x,r)$.
\end{itemize}
Давайте докажем, что при известном $e$ для любых последовательностей битов $y_n,z_n$ случайные величины $\langle y_n\oplus h^e_n(x,r), g^e_n(x,r), e \rangle$ и $\langle z_n\oplus h^e_n(x,r), g^e_n(x,r), e \rangle$ будут вычислительно неотличимы. Обе эти случайные величины неотличимы от 
$\langle U_1, U(D_n), e\rangle$ по соответствующей теореме о трудном бите.
\end{proof}
\begin{remark}
Можно научиться посылать несколько длинные сообщения, если воспользоваться конструкцией,
которую мы использовали для псевдослучайного генератора (т.е. получится последовательность случайных битов).
\end{remark}

\section{Протокол привязки (схема обязательства, commitment protocol)}
Один участник хочет послать другому участнику некоторый зашифрованный секрет таким образом,
что 
\begin{itemize}
\item без знания ключа секрет невозможно расшифровать,
\item не существует другого ключа, который расшифровывал код, в другой секрет.
\end{itemize}

\subsection{Неинтерактивный протокол привязки к строке}
\begin{definition}
\emph{Неинтерактивный протокол привязки к строке}~--- это пара полиномиальных алгоритмов $S$ и $R$:
\begin{itemize}
\item вероятностный алгоритм $S(x, 1^n) = (c, k)$ шифрует секрет, где $x$~--- это секрет (строка), 
$c(x)$~--- шифр секрета, а $k(x)$~--- ключ,
\item детерминированный алгоритм $R(c, k) \in \{x,\perp\}$ по зашифрованному секрету и ключу либо восстанавливает 
\emph{исходный} секрет, либо сообщает, что ключ не подходит.
\end{itemize}
При этом выполняются следующие условия.
\begin{enumerate}
\item (Полнота) Если $S(x, 1^n) = (c, k)$, то $R(c, k) = x$ с вероятностью близкой к 1.
\item (Неразглашение) Для любого полинома $p$ и любых последовательностей строк $x_n$, $y_n$,
$|x_n|=|y_n|=p(n)$, если $c_n$~--- привязка $x_n$, $d_n$~--- привязка $y_n$,
то случайный величины $c_n$ и $d_n$ вычислительно неотличимы.
\item (Недвусмысленность) Ни для какого $n$ не существует таких $c, k_1, k_2$, что одновременно $R(c, k_1)\neq \perp$, $R(c, k_2)\neq \perp$
и $R(c, k_1)\neq R(c, k_2)$.
\end{enumerate}
\end{definition}

\begin{remark}
Достаточно научиться привязывать к биту (т.е. достаточно построить конструкцию для $p(n) = 1$).
\end{remark}

\begin{definition}
Будем называть одностороннюю перестановку $f_n : D_n\to D_n$ \emph{правильной},
если равномерное распределение на $D_n\cup \{\perp\}$ полиномиально моделируемо (т.е., если не
получилось сгенерировать элемент из $D_n$, то выдаётся особый символ $\perp\not\in D_n$).
\end{definition}

\begin{theorem}
Если существует правильная односторонняя перестановка, то существует и 
неинтерактивный протокол привязки к биту.
\end{theorem}
\begin{proof}
Пусть $f_n : D_n\to D_n$~--- односторонняя перестановка с трудным битом $h_n$.
Будем привязывать бит $\sigma\in\bits$. Выберем строку $x$ из распределения 
на $D_n$, которое вычислительно неотличимо от равномерного (есть по свойству доступности).
Тогда $S(\sigma, 1^n) = (\underbrace{\strut\langle h_n(x)\oplus \sigma, f_n(x)\rangle}_{c}, \underbrace{\strut r_n}_{k})$, где $r_n$~--- это случайные биты, которые использовались для генерации $x$.\footnote{Нельзя в качестве ключа выбрать $x$, т.к. тогда нужно было бы уметь проверять, что $x\in D_n$.} Соответственно, $R(c, k)$ генерирует $x$ используя в качестве случайных битов $k$ и проверяет, что $f_n(x)$ совпадает с соответствующими битами $c$. Если это так, то бит $\sigma$ восстанавливается по первому биту $c$. Несложно увидеть, что свойство 1 выполняется по построению, свойство 2 следует из определения трудного бита, а свойство 3 из того, что $K$ возвращает только элементы из $D_n$.
\end{proof}

\section{Интерактивные протоколы}
\begin{definition}
\emph{Интерактивный протокол}~--- это пара вероятностных алгоритмов $A(1^n, x, h)$ и $B(1^n, y, h)$,
которые ,,общаются между собой'', передавая сообщения друг другу.
Интерактивный протокол состоящий из $t$ раундов устроен так:
\begin{align*}
s_1&\gets A(1^n, x, \lambda),\\
s_2&\gets B(1^n, y, s_1),\\
s_3&\gets A(1^n, x, \langle s_1, s_2\rangle),\\
s_4&\gets B(1^n, y, \langle s_1, s_2, s_3\rangle),\\
&\vdots\\
s_{t-1}&\gets A(1^n, x, \langle s_1, s_2,\dotsc,s_{t-2}\rangle),\\
s_{t}  &\gets B(1^n, y, \langle s_1, s_2,\dotsc,s_{t-1}\rangle).
\end{align*}
В последнем сообщении $s_t$ содержится некоторый признак (например, специальный символ),
который сигнализирует об окончании общения.
Алгоритмы такого вида будем называть \emph{интерактивными алгоритмами}.
Через $\pi_{A(x),B(y)}$ будем обозначать историю взаимодействия алгоритмов $A$ и $B$
на входах $x$ и $y$ соответственно. Для $t$-раундового протокола $\pi_{A(x),B(y)} = \langle s_1, s_2,\dotsc,s_{t}\rangle$. После завершения общения алгоритмы $A$ и $B$ ещё раз запускаются 
на полученной истории и печатают результат, т.е. на стороне алгоритма $A$ результатом будет
$A(1^n, x, \pi_{A(x),B(y)})$, а на стороне алгоритма $B$~--- $B(1^n, y, \pi_{A(x),B(y)})$. 
Аналогичное определение можно дать и для схем, нужно только позаботиться о том, чтобы аккуратно
закодировать неполную историю (можно, например, использовать алфавит с дополнительными символами).
\end{definition}
\subsection{Интерактивные протоколы привязки к строке}
Для неинтерактивного протокола привязки нам потребовалось предположить
существование правильных односторонних перестановок. Оказывается,
что если добавить интерактивность, то можно построить протокол привязки
при более слабом предположении.
\begin{definition}
\emph{Интерактивный протокол привязки к строке}~--- полиномиальный (по суммарному времени,
а следовательно и по количеству раундов) интерактивный протокол, заданный
полиномиальными вероятностными алгоритмами $S(1^n, \sigma, h)$ и $T(1^n, h)$, 
и детерминированный полиномиальный алгоритм $R(1^n, c,k)$,
где $S$~--- алгоритм стороны, которая осуществляет привязку, 
$T$~--- алгоритм стороны, которая получает привязку, а $R$~--- алгоритм
проверяющий, что привязка действительно соответствует исходной строке.
Привязкой строки $\sigma$ в этом интерактивном алгоритме будет $c(\sigma) = \pi_{S(\sigma), T}$. 
После окончания взаимодействия алгоритм $S$ выдаёт ключ $k(\sigma)$, 
соответствующий этой привязке.
Алгоритм $R(c,k)$ выдаёт либо строку $\sigma$, по которой была построена привязка,
либо один из специальных символов $\perp_S$ и $\perp_T$, которые ,,обвиняют'' соответственно,
протокол $S$ и $T$ в жульничестве. Кроме того, должны выполняться следующие свойства.
\begin{enumerate}
\item (Корректность) $R(\pi_{S(\sigma), T}, k_{n,\sigma}) = \sigma$ с вероятностью 1.
\item (Полнота) Для любого (схемного) противника $T^*$
$$R(\pi_{S(\sigma), T^*}, k_{n,\sigma}) \in \{\sigma, \perp_T\}$$
с вероятностью пренебрежимо отличающейся от 1.
\item (Неразглашение) Для любого противника $T^*$, полинома $p(n)$ и любых последовательностей строк $x_n$, $y_n$,
$|x_n|=|y_n|=p(n)$, случайные величины $\pi_{S(x_n), T^*}$ и $\pi_{S(y_n), T^*}$
вычислительно неотличимы.
\item (Недвусмысленность привязки) Для любого противника $S^*$ вероятность
$$\Pr\bigl[\exists k_1, k_2 \mid 
R(\pi_{S^*, T}, k_1)\neq \perp_S, 
R(\pi_{S^*, T}, k_2)\neq \perp_S, 
R(\pi_{S^*, T}, k_1)\neq R(\pi_{S^*, T}, k_2)
\bigr]$$
пренебрежимо мала.
\item Вероятность $\Pr[\exists k \mid R(\pi_{S^*,T}, k) = \perp_T]$ пренебрежимо мала.
\end{enumerate}
\end{definition}
\begin{theorem}
Если существует генератор псевдослучайных чисел, то существует интерактивный протокол привязки к биту.
\end{theorem}
\begin{proof}
Определим протокол привязки для бита $\sigma\in\bits$. Возьмём генератор псевдослучайных чисел $G_n:\bits^n\to\bits^{3n}$. Алгоритм $T(1^n)$ генерирует случайную строку $r\gets U_{3n}$ и посылает её $S$.
Алгоритм $S(1^n, \sigma)$ ожидает получения строки $r\in\bits^{3n}$, генерирует строку $s\gets U_n$
и посылает сообщение 
$$t = 
\begin{cases} 
G(s)\oplus r, & \sigma = 1,\\ 
G(s),         & \sigma = 0.
\end{cases}
$$ 
Ключом для этой привязки будет $k = \sigma s$.

Алгоритм $R(1^n, (r,t), k)$ проверяет, что все длины строк в привязке соответствуют ожидаемым: $|r|=|t|=3n$, $|k|=n+1$. Если длины неправильные, то $R$ обвиняет соответствующую сторону. 
После этого алгоритм $R$ по $k=\sigma s$ вычисляет $t\oplus G(s)$:
\begin{itemize}
\item если получилось $0^{3n}$, то проверяет, что $\sigma=0$, и выдаётся $0$;
\item если получилось $r$,      то проверяет, что $\sigma=1$, и выдаётся $1$;
\item если получилось что-то ещё, то выдаёт $\perp_S$.
\end{itemize}

Свойства 1, 2 и 5 выполняются по построению.
Свойство 3 означает, что следующие случайные величины $\langle r,G_n(s)\rangle$ и 
$\langle r,G_n(s)\oplus r\rangle$
должны быть вычислительно неотличимы. Если мы умеем их различать, то умеем одну из
них отличать от $\langle r,U_{3n}\rangle$, а это позволяет взломать генератор $G_n$. Осталось проверить свойство 4.
Давайте оценим 
$$\Pr\bigl[\exists s_0, s_1 \mid G_n(s_0) \oplus t = 0^{3n}, G_n(s_1) \oplus t = r \bigr] =
\Pr\bigl[\exists s_0, s_1 \mid G_n(s_0) \oplus G_n(s_1) = r \bigr] \le \frac{2^{2n}}{2^{3n}} = 2^{-n}.$$
\end{proof}

\subsection{Протокол подбрасывания монетки}
\begin{definition}
\emph{Интерактивный протокол подбрасывания монетки}~--- это полиномиальный 
(по суммарному времени и по количеству раундов)
интерактивный протокол, заданный полиномиальными вероятностными алгоритмами 
$A(1^n, h)$ и $B(1^n, h)$, и детерминированный полиномиальный алгоритм $D(1^n, h)$,
где $A$ и $B$~--- это алгоритмы сторон, а $D$~--- алгоритм, 
позволяющий по истории общения получить результат подбрасывания монетки.
Стороны запускают $D$ после завершения протокола и определяют результат.
Для стороны $A$ и любого противника $B^*$ должны выполняться следующие свойства (интересы стороны $A$):
\begin{enumerate}
\item вероятность $\Pr[D(\pi_{A, B^*}) = \perp_A]$ пренебрежимо мала,
\item для любого $\sigma\in\bits$ $\Pr\bigl[D(\pi_{A, B^*}) = \sigma]\le\frac12 + \alpha_n$, где $\alpha_n$~--- пренебрежимо мала.
\end{enumerate}
Такие же свойства должны выполняться и для стороны $B$ и любого противника $A^*$.
\end{definition}
\begin{theorem}
Если существует интерактивный протокол привязки к биту, 
то существует и интерактивный протокол подбрасывания монетки.
\end{theorem}
\begin{proof}
Пусть $(S,T,R)$~--- интерактивный протокол привязки.
Сторона $A$ генерирует бит $\sigma$ и запускает алгоритм привязки $S(\sigma)$,
сторона $B$ запускает алгоритм $T$; в конце протокола обе стороны знают привязку $c(\sigma)$,
а сторона $A$ ещё дополнительно знает ключ $k(\sigma)$. 
Потом сторона $B$ генерирует бит $\tau$ и посылает его алгоритму $A$, а сторона $A$ в ответ посылает
ключ $k(\sigma)$.

Алгоритм $D(c(\sigma), \tau, k(\sigma))$ запускает алгоритм $R(c(\sigma), k(\sigma))$ 
для проверки для привязки.
Если алгоритм проверки привязки обвиняет какую-то сторону, то $D$ обвиняет соответствующую сторону.
В противном случае $D$ выдаёт $\sigma\oplus\tau$.

Давайте проверим, что интересы стороны $A$ соблюдаются. Свойство $1$ следует из протокола привязки
(т.к. обвинение стороны возможно только в протоколе привязки). 
Предположим, что второе свойство нарушается. Тогда $B^*$ может подбирать бит $\tau$ так,
чтобы угадывать $\sigma$ с нетривиальной вероятностью, а значит $B^*$ можно использовать 
для взлома протокола привязки.

Интересы стороны $B$ соблюдаются из-за недвусмысленности протокола привязки,
поэтому вероятность того, что $A$ сможет подменить ключ пренебрежимо мала.
\end{proof}

\section{Протоколы с нулевым разглашением}
Пусть алгоритм $A(1^n, x, e)$, где $x\in D_n$, $e\gets\nu_n$, 
общается с некоторой полиномиальной схемой $C_n$,
которая уже имеет некоторую информацию о $x$ и $e$, а именно $C_n$ знает
значение функции $g(1^n,x,e)$. Пусть имеется ещё одна функция $f(1^n,x,e)$.
Давайте определим, что значит, алгоритм $A$ \emph{разглашает} информацию $f(1^n,x,e)$,
если противнику уже известна информация $g(1^n,x,e)$ о входах $x,e$ 
(для краткости будем опускать параметр $1^n$).
\begin{definition}
Будем говорить, что алгоритм $A$ \emph{разглашает только $f$ при известном $g$ на области $D_n$},
если существует полиномиальный вероятностный алгоритм $M$, который для любой последовательности 
слов $\{x_n\in D_n\}$ и любой последовательности полиномиальных схем $C_n$
получая на вход $f(x_n,e)$ и схему $C_n$ в качестве чёрного ящика
(т.е. как оракул) генерирует случайную величину $\alpha_n(x_n, e)$,
вычислительно неотличимую от протокола общения $\beta_n(x_n, e)$ между алгоритмом $A(x_n, e)$
и схемой $C_n(g(x_n,e), \cdot)$ при известном $g(x_n,e)$ (т.е. случайные величины 
$g(x_n,e)\alpha_n(x_n, e)$ и $g(x_n,e)\beta_n(x_n, e)$ вычислительно неотличимы). Вероятность
берётся по выбору $e\gets\nu_n$ и случайным битам алгоритмов $A(x_n,e)$ и $M$.
Множество $D_n$ называется \emph{областью неразглашения алгоритма}, а алгоритм $M$~--- \emph{симулятором}.

%Если условие для $M$ выполняется с вероятностью близкой к $1$ по случайному выбору $x$,
%то мы будем говорить, что \emph{$A$ разглашает только $f$ при известном $g$ в слабом смысле}.
\end{definition}
\begin{example}
Пусть $e\gets U_n$, а $A$ посылает $x\oplus e$. 
Этот алгоритм имеет нулевое разглашение. 
Симулятору достаточно выдать случайную строку из $U_n$.
\end{example}
\begin{example}
Пусть дана схема шифрования $K,E,D$ с открытым ключом. 
Для открытого ключа $e$ алгоритм шифрования $E(e,x)$ разглашает
пару $(|x|, e)$ при известном $e$. Действительно, $E(e,x)$
вычислительно неотличима от $E(e,0^{|x|})$. 
Симулятор $M$ выдаёт $E(e,0^{|x|})$.
\end{example}
\begin{example}
Пусть дан интерактивный протокол привязки $S,T,R$ для бита.
Алгоритм $S$ имеет нулевое разглашение.
Симулятор по схеме $C$ моделирует общение алгоритма $S(0)$
и схемы $C$ и выдаёт протокол общения.
\end{example}

\begin{lemma}
Выполняются следующие свойства разглашения.
\begin{enumerate}
\item Для любых функций $f,g,h$, если $A$ разглашает только $f$ при известном $g$,
то $A$ разглашает только пару $f,h$ при известном $g$.

\item Для любых функций $f,g,h$, если $A$ разглашает только $f$ при известной паре $g,h$,
то $A$ разглашает только $f$ при известном $g$.
\end{enumerate}
\end{lemma}

\begin{definition}
Если $A$ разглашает только $g$ при известном $g$, то мы будем говорить,
что $A$ имеет \emph{нулевое разглашение при известном $g$}. Если $g$
является константной функцией, то мы говорим, что $A$ \emph{разглашает только $f$}.
Если при этом ещё и $f$ является константной функцией, то мы говорим, что $A$ имеет
\emph{нулевое разглашение}.
\end{definition}

\begin{definition}
Пусть $A$ и $B$ вероятностные полиномиальные интерактивные алгоритмы. Выполним сначала $A$ на паре входов
$x$ и $e$, а потом $B$ на паре входов $(x,c)$ и $e$, где $c$~--- протокол общения,
полученный в ходе выполнения $A$. Полученный алгоритм будем обозначать как $(A,B)$.
\end{definition}

\begin{theorem}[о неразглашении при последовательном выполнении]
\label{thm:repetition-knowledge}
Пусть $g(x,e) = (e, k(x,e))$, где $k$~--- произвольная функция.
Допустим, что алгоритм $A(x,e)$ разглашает только $f(x,e)$ при
известном $g(x,e)$ на области $D_n$, а алгоритм $B(x,e)$ разглашает
только $h(x,e)$ при известном $g(x,e)$ на той же области $D_n$.
Пусть также хотя бы одна из функция $f(x,e)$ или $h(x,e)$ полиномиально
вычислима. Тогда алгоритм $(A,B)$ разглашает только пару $(f(x,e),h(x,e))$
при известном $g(x,e)$ на области $D_n$.
%То же самое верно и для слабого разглашения (для любого распределения на входах $x$).
\end{theorem}
\begin{proof}
Пусть $M$ и $N$~--- симуляторы для $A$ и $B$ соответственно. Построим симулятор для $(A,B)$.
Алгоритмы $A$ и $B$ получают на вход некоторое неизвестное $x$ и случайное $e$  и после 
этого по очереди беседуют с некоторой схемой $C$, которой известно $g(x,e)$. В результате
получается протокол беседы $\pi_{(A,B)(x,e),C(g(x,e))}$, который является случайной величиной
с параметром $x$.

Симулятор для $(A,B)$ должен по схеме $C$ и подсказке о $x$ и $e$ в виде пары $f(x,e), g(x,e)$
сгенерировать случайную величину, вычислительно неотличимую от случайной величины 
$\pi_{(A,B)(x,e),C(g(x,e))}$ при известном $g(x,e)$.

В дальнейшем совместно распределённые случайные величины $f(x,e), g(x,e)$ и $h(x,e)$
будем для краткости обозначать $f,g$ и $h$ соответственно. 
Через $C^w$ мы будем обозначать схему $C$, в которую подставили
(зашили) слово $w$ (т.е. первые $|w|+1$ символ входа равны слову $w\$$, 
а остальные входы свободны).

Общение алгоритма $(A,B)(x,e)$ со схемой $C$ устроено так: схема $C$ читает $g$
и превращается в $C^g$, затем беседует с $A(x,e)$, в результате чего получается
некоторый протокол общения $u$, потом алгоритм $B(x,e)$ общается уже со схемой 
$C^{gu}$. Давайте обозначим протокол общения $B$ и $C^{gu}$ через $\mathcal B(C^{gu})$.
Тогда весь протокол общения $(A,B)(x,e)$ со схемой $C$~--- это конкатенация
случайных величин $u$ и $\mathcal B(C^{gu})$.

Симулятор для $(A,B)$ должен по $f,h$ и $C$ сгенерировать некоторую случайную
величину, вычислительно неотличимую от $u\mathcal B(C^{gu})$ при известном $g$. Для
этого он сначала запускает симулятор $M$ на $f$ и $C$ (значение $g$ известно), в результате
чего получается протокол общения $\tilde{u}$. После этого он запускает $N$ на входе
$h$ и $C^{\square\tilde{u}}$, в результате чего получается последовательность сообщений
$\mathcal N(C^{g\tilde{u}})$. В результате симулятор выдаёт $\tilde{u}\mathcal N(C^{g\tilde{u}})$.

Отметим, что по свойству симулятора $N$ известно, что $\mathcal N(C^{g\tilde{u}})$ вычислительно
неотличима от протокола общения $B(x,e)$ и $C^{g\tilde{u}}$.

Зафиксируем произвольную последовательность строк $x_n$ полиномиальной длины.
Нам нужно показать, что случайные величины 
$$\alpha=\tilde{u}\mathcal N(C^{g\tilde{u}})\text{\quad и\quad}\gamma=u\mathcal B(C^{gu})$$
вычислительно неотличимы при известном $g$. Докажем, что эти две случайные
величины неотличимы от какой-нибудь третьей случайной величины и потом воспользуемся
транзитивностью. Рассмотрим два случая.
\begin{enumerate}
\item Пусть $h$ является полиномиально вычислимой. Рассмотрим случайную величину
$$\beta=u\mathcal N(C^{gu}).$$ 
Покажем сначала, что $\beta$ вычислительно неотличима от $\alpha$.
Так как мы зафиксировали $x_n$, $e$ является частью $g$, 
а функция $h$ полиномиально вычислима, то следующее преобразование можно вычислить 
схемой полиномиального размера:
$$gv\to gv\mathcal N(C^{gv}).$$ Применяя это преобразование к $gu$ мы получим $g\beta$,
а применяя его к $g\tilde{u}$ получим $g\alpha$. Исходные $gu$ и $g\tilde{u}$
вычислительно неотличимы, значит неотличимы и $g\alpha$ и $g\beta$.

Покажем теперь неотличимость $\gamma$ и $\beta$. Если мы зафиксируем случайные биты $A$,
то $u$ будет функцией от $g$ ($e$ входит в состав $g$), которую можно вычислить схемой
полиномиального размера. Поэтому нам достаточно показать вычислительную неотличимость
$$
g\mathcal B(C^{gu})\text{\quad и\quad }g\mathcal N(C^{gu}).
$$
,,Зашьём`` схему для $u$ в схему $C^{gu}$, в результате получится семейство схем $H^{g}$:
$$H^{g}\equiv C^{gu}.$$
По свойству симулятора $N$ случайные величины $g\mathcal B(H^g)$ и $g\mathcal N(H^g)$ вычислительно неотличимы,
следовательно неотличимы и $g\mathcal B(C^{gu})$ и $g\mathcal N(C^{gu})$ 
(эти величины имеют такие же распределения, т.к. симулятор общается со схемой как с чёрным ящиком,
и поэтому не видит разницы между $H^{g}$ и $C^{gu}$). Из этого, как мы уже заметили, следует вычислительная неотличимость и $\gamma$ и $\beta$.


\item Пусть $f$ является полиномиально вычислимой.
Рассмотрим случайную величину
$$\beta=\tilde{u}\mathcal N(C^{gu}).$$ 
Доказательство устроено аналогично. Для неотличимости $\alpha$ и $\beta$
при известном $g$ нам нужно, чтобы $f$ была полиномиально вычислимой
функцией от $g,x$~--- это позволяет вычислить $\tilde{u}$
по $g$ и случайным битам $M$ схемой полиномиального размера.
А для отличимости $\alpha$ и $\beta$ при известном $g$ нам опять нужно,
чтобы $e$ было полиномиально вычислимой функцией от $g,x$,
что позволяет вычислить $\mathcal B(C^{gu})$ по $g$ и $u$ вероятностной 
схемой полиномиального размера.
\end{enumerate}
\end{proof}

\begin{remark}
Теорема о неразглашении при повторении выполняется и в ситуации, когда
алгоритму $B$ дополнительно на вход подаётся протокол $u$ общения $A$ и $C_n$,
а так же использованные при этом случайные биты $A$.
\end{remark}
\begin{theorem}[о неразглашении при последовательном выполнении, улучшенная]
Пусть $g(x,e) = (e, k(x,e))$, где $k$~--- произвольная функция.
Допустим, что алгоритм $A(x,e)$ разглашает только $f(x,e)$ при
известном $g(x,e)$ на области $D_n$, а алгоритм $B(u, r, x,e)$ разглашает
только $h(x,e)$ при известном $g(x,e)$ на области $E_n$.
Пусть также хотя бы одна из функция $f(x,e)$ или $h(x,e)$ полиномиально
вычислима. Пусть наконец, для всех $x\in D_n$ для протокола общения
$u$ алгоритма $A$ с любой схемой $C_n$ полиномиального размера и его случайных битов $r$
с почти единичной вероятностью $(u,r,x)\in E_n$. 
Тогда алгоритм $(A,B)$ разглашает только пару $(f(x,e),h(x,e))$
при известном $g(x,e)$ на области $D_n$.
\end{theorem}
%\begin{proof} См. доказательство теоремы~\ref{thm:repetition-knowledge}.
%\end{proof}

\begin{definition}
Для интерактивного алгоритма $A$ через $A^{k}$ будем обозначать 
последовательное выполнение $A$ на входах $(x,1,e),(x,2,e),\dotsc,(x,k,e)$.
\end{definition}

\begin{theorem}[о неразглашении при последовательном применении полиномиального числа алгоритмов]
\label{thm:knowledge-poly-repetition}
Пусть $g(x,e) = (e, h(x,e))$, где $h$~--- произвольная функция, а $f(x,e)$ некоторая полиномиально
вычислимая функция. Если алгоритм $A$ разглашает только $f(x,e)$ при известном $g(x,e)$,
то алгоритм $A^{k(n)}$ для некоторого полинома $k$ разглашает только $f(x,e)$ при известном $g(x,e)$.
\end{theorem}
\begin{proof}
Обозначим через $M$ симулятор для алгоритма $A$ и построим симулятор $M^k$ для алгоритма $A^k$. Такой симулятор должен по входам $f$ и $C$ породить случайную величину, вычислительно неотличимую от протокола общение $A^k(x,e)$ и $C^g$.

Обозначим через $\mathcal{A}_i(C,e)$ протокол общения алгоритма $A(x,i,e)$ 
со схемой $C^g$, а через $\mathcal{M}_i(C,e)$, соответственно, 
результат работы симулятора $M$ на входах $f$ и $C$.

Зафиксируем произвольную полиномиальную схему $C$. Протокол общения $\gamma$ алгоритмов
$A^k(x,e)$ и $C^g$ можно получить последовательным применением к пустой строке для 
$j=1,\dotsc,k$ вероятностных операторов 
$$
R^A_i: u\to u\mathcal A_j(C^{gu}, e).
$$
Если применять ,,близкие`` операторы
$$
R^M_i: u\to u\mathcal M_j(C^{gu}, e),
$$
то получится некоторая случайная величина $\alpha$. Покажем, что $\alpha$
вычислительно неотличима от $\gamma$ при известном $g$.

Зафиксируем произвольную последовательность $x_n$ слов 
полиномиальной длины для алгоритма $A^k$.
Рассмотрим гибридные случайные величины $\beta_0,\beta_1,\dotsc,\beta_k$, которые
получаются смешиванием этих двух вероятностных операторов: для получения случайной величины 
$\beta_i$ мы сначала последовательно применяем $R^A_1, \dotsc, R^A_i$, а потом 
$R^M_{i+1}, \dotsc, R^M_k$.
Покажем, что две последовательные случайные величины $\beta_{i-1}$ и $\beta_{i}$
неотличимы при известном $g$ (из этого будет следовать неотличимость $\gamma=\beta_0$ и $\alpha=\beta_k$).

Обозначим через $\delta$ случайную величину, полученную применение к пустой 
строке операторов $R^A_1, \dotsc, R^A_i$, т.е. это протокол первых $i-1$ запуска $A$.
Через $F(u,e)$ обозначим случайную 
величину, полученную из строки $u$ путём последовательного применения 
$R^M_{i+1}, \dotsc, R^M_k$. В этих обозначениях
$$\beta_i     = F(\delta \mathcal A_i(C^{g\delta},e),e), \quad 
  \beta_{i-1} = F(\delta \mathcal M_i(C^{g\delta},e),e).$$
Поскольку оператор $F(u,e)$ можно вычислить вероятностной схемой 
полиномиального размера по $x_n, e$ и $u$ ($f$ полиномиально вычислимо), 
нам достаточно доказать неотличимость $\delta \mathcal A_i(C^{g\delta},e)$ и 
$\delta \mathcal M_i(C^{g\delta},e)$ при известном $g$. Слово $\delta$ зависит 
от $e$ и случайных битов, использованных $A$ в первых $i-1$ запусках. 
Давайте зафиксируем эти биты. Теперь $\delta$ становится
функцией от $e$ ($x_n$ мы тоже зафиксировали), а следовательно вычислима схемой полиномиального размера.
Поэтому достаточно доказать неотличимость $\mathcal A_i(C^{g\delta},e)$ и $\mathcal M_i(C^{g\delta},e)$ при известном $g$. Теперь ,,зашьём`` вычисление $\delta$ в схему. Получится схема $H^g \equiv C^{g\delta}$.
Тогда $$\mathcal A_i(C^{g\delta}, e) = \mathcal A_i(H^{g},e),\quad \mathcal M_i(C^{g\delta}, e) = \mathcal M_i(H^{g},e).$$
По определению симулятора $\mathcal A_i(H^{g},e)$ и $\mathcal M_i(H^{g},e)$ вычислительно неотличимы при известном $g$.
Это наблюдение завершает доказательство.
\end{proof}

\subsection{Языки с нулевым разглашением}

\begin{definition}
Для языка $L$ мы будем говорить, что он обладает \emph{доказательством с нулевым разглашением},
если существуют такие полиномиальные вероятностные интерактивные алгоритмы $P$ и $V$:
\begin{enumerate}
\item если $x\in L$, то существует $y$, $|y|\le p(x)$: $\Pr[\out_{P(x, y), V(x) = 1}]\ge 1-\alpha_n$,
\item если $x\not\in L$, то для любой функции $P^*$: $\Pr[\out_{P^*, V(x) = 1}] < \alpha_n$,
\item $P(x, y)$ разглашает только $(x, L(x))$,
\end{enumerate}
где $\alpha_n$ пренебрежимо мала.
\end{definition}

\begin{definition}
$ZKP$~--- это класс языков, для которые обладают доказательством с нулевым разглашением.
\end{definition}

\begin{remark}
$GI$ обладает протоколом со статистически неотличимым нулевым разглашением
(т.е. в определении нулевого разглашения можно заменить вычислительную неотличимость на статистическую).
\end{remark}

\begin{definition}
Язык изоморфизма графов $GI$~--- это язык пар графов $(G_0, G_1)$ таких, что $G_1$ изоморфен $G_0$.
\end{definition}

\begin{lemma}
$GI\in ZKP$.
\end{lemma}
\begin{proof}
Алгоритм $P$ на своей стороне получает $G_0, G_1$ и перестановку вершин $\tau\in S_n$: $\tau(G_0) = G_1$
($n$ обозначает число вершин). Алгоритм $P$ выбирает случайную перестановку $\pi\gets U(S_n)$ и посылает
$H = \pi(G_0)$ алгоритму $V$. Алгоритм $V$ в ответ посылает случайный бит $\alpha\in\{0,1\}$.
В ответ алгоритм $P$ вычисляет $\sigma = \pi\circ\tau^{-\alpha}$ (т.е. такую перестановку, что $\sigma(G_\alpha) = \pi(G_0)$). Алгоритм $V$ на своей стороне проверяет, что $\sigma(G_0) = H$ и принимает, если это так. Этот протокол нужно повторить полиномиальное число раз для уменьшения ошибки.

Условие 1 выполняется по построению. Условие 2 выполняется, т.к. на каждой итерации алгоритм $V$
ловит алгоритм $P^*$ с вероятностью $\frac{1}{2}$. Остаётся проверить условие 3 и тут нам потребует теорема~\ref{thm:knowledge-poly-repetition}.

Пусть $F$~--- это схема, с которой общается (честный) алгоритм $P$.
Будем рассматривать поведение только на входе из языка, т.е. на
паре изоморфных графов.
Давайте считать, что $F$~--- детерминирована и не нарушает протокол,
т.е. $F(H)$~--- это один бит (который выбирается детерминировано).
Тогда протокол задаётся следующей тройкой из множества  
$$\{(H,\alpha,\sigma): \alpha\in\bits, \sigma\in S_n, F(H)=\alpha, \sigma(G_\alpha)= H\}.$$ Будем называть это множество \emph{множеством хороших троек}.

Давайте покажем, что протокол (как случайная величина) равномерно распределен на множестве хороших троек. Рассмотрим такую хорошую тройку $(H,\alpha,\sigma)$. Так как $\sigma = \pi\circ\tau^{-\alpha}$,
то по $\sigma,$ $\alpha$ и $\tau$ можно однозначно 
восстановить $\pi$, а по $\pi$ однозначно получается $H$. Обратно по $\pi$ можно восстановить хорошую тройку ($\alpha= F(\pi(G_0))$). Таким образом хороших троек столько же, сколько различных перестановок $\pi$, а именно $n!$. 

Теперь нам нужно научиться генерировать
равномерное распределение на хороших тройках. Будем генерировать
следующим образом: $\alpha\gets U_1,$ $\sigma\gets U(S_n),$ $H=\sigma(G_\alpha)$, если теперь $F(H)=\alpha$, то вернём $(H,\alpha,\sigma)$, иначе вернём $\perp$. Заметим, что
$$\Pr[F(\sigma(G_\alpha)) = \alpha] = 
\frac12\Pr[F(\sigma(G_0)) = 0] +
\frac12\Pr[F(\sigma(G_1)) = 1].
$$
Так как $\sigma$ выбирается случайно, а $G_0\simeq G_1$, то это то же самое, что 
$$\Pr[F(\sigma(G_\alpha)) = \alpha] = 
\frac12\Pr[F(\sigma(G_0)) = 0] +
\frac12\Pr[F(\sigma(G_0)) = 1] = \frac12.
$$
Теперь этот алгоритм можно повторить $n$ раз и получить распределение, неотличимое от равномерного.

Если $F$ выдаст не один бит, а некоторую строку $\beta$, то симулятор должен выдать ,,оборванный протокол`` $(H,\beta)$.

Мы доказали эту теорему для детерминированного $F$. 
Если $F$ использует случайные биты, для каждых фиксированных
значений этих битов теорема верна, значит и для случайного выбора
случайных битов тоже.
\end{proof}

Покажем, что если существуют односторонние функции, то $NP\subseteq ZKP$.

\begin{theorem}
Если существуют односторонние функции, тогда для любого $L\in NP$ существует 
вероятностный полиномиальные интерактивные
алгоритмы $P$ и $V$:
\begin{enumerate}
\item если $x\in L$, то любой подсказки $y$ для $x$, $|y|\le p(x)$: $\Pr[\out_{P(x, y), V(x) = 1}]\ge 1-\alpha_n$,
\item если $x\not\in L$, то для любой функции $P^*$: $\Pr[\out_{P^*, V(x) = 1}] < \alpha_n$,
\item $P(x, y)$ разглашает только $(x, R(x,y))$, где $R$~--- предикат задающий $L$.
\end{enumerate}
\end{theorem}
\begin{proof}
Достаточно доказать для какого-либо $NP$-полного языка относительно сведений,
которые сохраняют подсказки. 
Пусть $L\in NP$ с предикатом $R$,
$L^*$~--- $NP$-полный с предикатом $R*$. Пусть существует полиномиально вычислимая функция $f:$
$x\in L \iff f(x)\in L^*$,
и существует полиномиально вычислимая функция $g:$
$R(x,y) = 1 \implies R(f(x), g(y))$.
Если мы докажем существование $P$ и $V$ для $L^*$, то из этого легко можно построить $P$ и $V$ для $L$ с необходимыми свойствами.

Будем доказывать для языка $3-COL$ неориентированных три-раскрашиваемых графов.

Будем доказывать с усиленным свойством 2.
{\em
\begin{itemize}
\item[2'.] Существует такой оракульный вероятностный полиномиальный по времени алгоритм $A$, что если для какой-то вероятностной функции $P^*$ и любого $x$
$$
\Pr[\out_{P^*,V(x)} = 1] = p,
$$
то $A^{P^*}$ выдаёт подсказку для $x$ 
с вероятностью не менее $p - \alpha(|x|)$,
где $\alpha(n)$ пренебрежимо мало.
\end{itemize}}
(Это свойство гарантирует, что если $p$ не пренебрежимо мало, то $x\in L$.)

\paragraph{Алгоритм.} $P$ на входе $(G,\sigma)$ выбирает случайную
перестановку $\pi\gets S_3$ и вычисляет
$\alpha = \pi\circ\sigma$. После этого
запускается интерактивный алгоритм привязки для цвета каждой вершины. Если
на этом этапе $V$ заблокировал, то протокол останавливается. 
$V$ выбирает случайное ребро $(u,v)$.
$P$ в ответ посылает привязки $k_u$ и
$k_v$ для вершин $u$ и $v$.
$V$ проверяет привязки. Если привязки корректны и цвета различные, то попытка успешна. В противном случае $V$ возвращает $0$. Нужно повторить этот алгоритм $2n|E|$ раз.

Можно считать, что $p\ge e^{-n}$ (иначе $p$ пренебрежимо мало). Определим вероятности $\seqn{p}{2n|E|}$, где $p_i = \Pr[\text{успех в раунде $i$}\mid \text{успех в предыдущих раундах}].$ Тогда $$p=\prod_{i=1}^{2n|E|} p_i.$$
Тогда по предположению существует $i$: $p_i> e^{-\frac1{2|E|}}\ge 1 - \frac1{2|E|}$.
Построим алгоритм для поиска раскраски $A$. Этот алгоритм будет общаться с $P*$:
в раунде $j$ алгоритм $A$ будет спрашивать $P^*$ про все рёбра (для этого мы будем
подсовывать ей историю предыдущих $j-1$ раундов без истории $j$-го раунда).
Если нам удалось найти раскраску, то возвращаем её. Если нет, то повторим этот раунд $n$ раз. Для выбранного $i$ вероятность $p_i$ большая~--- если мы спросим все рёбра, то вероятность успеха как минимум $\frac{1}{2}$. После $n$ повторений получается вероятность $1-2^{-n}$. Заметим, что построенный алгоритм найдёт раскраску только при условии, что в предыдущих раундах был успех, т.е. 
$$
\Pr[\text{найдёт раскарску в раунде $i$}\mid \text{успех в предыдущих раундах}] \approx 1.
$$
Отсюда следует, что 
\[
\Pr[\text{найдёт раскарску в раунде $i$}] \ge \Pr[\text{успех в предыдущих раундах}] \ge p.
\]


Осталось доказать нулевое разглашение. Алгоритм ведёт себя одинаково в каждом раунде, так
что достаточно доказать для одного раунда. Будем строить симулятор $M$.
Возьмём $\beta$~--- случайную раскраску в три цвета и запустим протокол привязки
для цвета каждой вершины, в результате чего получим историю $S_\beta$.
Запустим $V^*(\pi_{S_\beta, V^*})$ и получим ребро $(u,v)$.
Если $\beta(u)\neq \beta(v)$, то выдадим ключи $k_u$ и $k_v$.
Иначе повторим. Всего $n$ повторений. Если нам ни разу не повезло, то вернём пустую строку.

Давайте сначала покажем, что каждую попытку нам везёт с вероятностью $2/3$.
\begin{align*}
\Pr[V^*(\pi_{S_\beta, V^*}), \beta(u)\neq\beta(v)] &= 
\sum_{\substack{(u,v)\in E\\a,b\in\{1,2,3\}\\a\neq b}} 
\Pr[V^*(\pi_{S_{\beta|v\gets a, u\gets b}, V^*}) = (u,v), \beta(u) = a, \beta(v) = b]\\
&=\sum_{\substack{(u,v)\in E\\a,b\in\{1,2,3\}\\a\neq b}} 
\frac{1}{9}\Pr[V^*(\pi_{S_{\beta|v\gets a, u\gets b}, V^*}) = (u,v)].
\end{align*}
По свойствам привязки существует случайная величина $\Theta_{V^*}$,
вычислительно неотличимая от случайной величины $\pi_{S_{\beta|v\gets a, u\gets b}, V^*}$.
Тогда продолжая предыдущее рассуждение
$$\approx 
\sum_{\substack{(u,v)\in E\\a,b\in\{1,2,3\}\\a\neq b}} \frac{1}{9}\Pr[V^*(\Theta_{V^*}) = (u,v)] = 
\frac{6}{9}\sum_{(u,v)\in E}\Pr[V^*(\Theta_{V^*}) = (u,v)] = \frac{2}{3}.
$$

Осталось показать, что полученное распределение будет вычислительно неотличимо от настоящего.
Обозначим полученное распределение $\eta$.
\begin{equation}\label{eq:eta-def}
\Pr[\eta = d] = \Pr[\pi_{P_{\beta}, V^*} = d\mid 
\beta(u)\neq \beta(v)].
\end{equation}
Пусть $A$~--- схема полиномиального размера (различитель).
Мы хотим показать, что 
\begin{equation}\label{eq:eta-approx-real}
\Pr[A(\pi_{P_\alpha, V^*}) = 1] \approx \Pr[A(\eta) = 1]
\end{equation}
По определению условной вероятности из~\eqref{eq:eta-def} получаем
$$\Pr[A(\eta) = 1]\approx \frac32 \Pr[A(\pi_{P_{\beta}, V^*}) = 1, \beta(u)\neq \beta(v)].$$
С другой стороны
$$
\Pr[A(\pi_{P_\alpha, V^*}) = 1] = \sum_{(u,v)} \sum_{a\neq b} 
\Pr[A(\pi_{P_\alpha, V^*}) = 1, V^*(\pi_{S_\alpha, V^*}) = (u,v), \alpha(u) = a, \alpha(v) = b].
$$
Применим тот же трюк с избавлением зависимости от $a$ и $b$, получаем
\begin{align}\label{eq:adv-alpha}
&= \sum_{(u,v)} \sum_{a\neq b} 
\Pr[A(\pi_{P_{\alpha|u\gets a, v\gets b}, V^*}) = 1, V^*(\pi_{S_{\alpha|u\gets a, v\gets b}, V^*}) = (u,v), \alpha(u) = a, \alpha(v) = b] \notag\\ 
&= \frac{1}{6}\sum_{(u,v)} \sum_{a\neq b} 
\Pr[A(\pi_{P_{\alpha|u\gets a, v\gets b}, V^*}) = 1, V^*(\pi_{S_{\alpha|u\gets a, v\gets b}, V^*}) = (u,v)].
\end{align}
Раскладывая таким же образом $\Pr[A(\eta) = 1]$ получаем
\begin{align}\label{eq:adv-beta}
&\approx \frac{3}{2} \sum_{(u,v)} \sum_{a\neq b} 
\Pr[A(\pi_{P_{\beta|u\gets a, v\gets b}, V^*}) = 1,
 V^*(\pi_{S_{\beta|u\gets a, v\gets b}, V*}) = (u,v), \beta(u) = a, \beta(v) = b] \notag\\
&=\frac{1}{6} \sum_{(u,v)} \sum_{a\neq b} 
\Pr[A(\pi_{P_{\beta|u\gets a, v\gets b}, V^*}) = 1,
 V^*(\pi_{S_{\beta|u\gets a, v\gets b}, V*}) = (u,v)].
\end{align}
Мы хотим показать, что можно построить распределение, вычислительно неотличимое от 
$$\pi_{S_{\beta|u\gets a, v\gets b}, V*} = \pi_{P_{\beta|u\gets a, v\gets b}, V*}, (k_u, k_v)$$
для какой-то фиксированной раскраски $\beta$. Проблема только в генерации $k_u$ и $k_v$, т.к. мы не знаем, при помощи каких случайных битов они сгенерированы, но знаем $a$ и $b$. Поэтому можно сгенерировать $k_u$ и $k_v$ при помощи других случайных бит и воспользоваться свойством неразглашения протокола привязки. Получится некоторое распределение $\Theta_{u,v,a,b}$, которое ``не зависит'' от $\beta$ (тут мы пользуемся нулевым разглашением протокола привязки). Поэтому~\eqref{eq:adv-alpha} и
\eqref{eq:adv-beta} примерно равны, а следовательно соотношение~\eqref{eq:eta-approx-real} выполняется.
\end{proof}

\section{Протоколы цифровой подписи}
Цифровая подпись позволяет подписывать цифровые документы, при этом все могут эту подпись проверить,
но никто не может её подделать.

\begin{definition}
\emph{Протокол цифровой подписи}~--- это тройка полиномиальных
вероятностных алгоритмов $(G, S, V)$: алгоритм $G(1^n)$ генерирует пару ключей $(e_n, d_n)$, где $e_n$ известен всем, а $d_n$ только владельцу, алгоритм $S(e_n, d_n, m)$ создаёт 
подпись $c$ для документа $m$, алгоритм $V(e_n, m, c)$ проверяет
корректность подписи. Должны выполняться следующие свойства.
\begin{enumerate}
\item (Полнота) Вероятность того, что $V(e_n, m, S(e_n, d_n, m)) = 1$ отличается от $1$ на пренебрежимо малую величину.

\item (Надёжность) Для любого полинома $k(n)$ и любого полиномиального противника $C = \{C_i\}_{i=1}^{k(n)+1}$ 
определим $\{x_i\}$ и $\{c_i\}$ следующим образом
$$
 \begin{aligned}
 (e,d)&\gets G(1^n),\\
 x_1 &= C_1(e),\\
 c_1 &= S(e, d, x_1),\\ 
 x_2 &= C_2(e,c_1),\\
 c_2 &= S(e, d, x_2),\\  
 &\ \;\vdots\\ 
 x_{k(n)} &= C_{k(n)}(x_1, \seqn{c}{k(n) - 1}),\\
 c_{k(n)} &= S(e, d, x_{k(n)}),\\
 (x_{k+1}, c_{k+1}) &= C_{k(n)+1}(x_1, \seqn{c}{k(n)}).\\
 \end{aligned}
$$
Тогда 
$\Pr[x_{k(n)+1}\notin \{\seqn{x}{k(n)}\} \land 
V(e_n, x_{k(n)+1}, c_{k(n)+1}) = 1]$ пренебрежимо мала.
\end{enumerate}
\end{definition}
\begin{theorem}
Если существует односторонняя функция, то существует и протокол
цифровой подписи.
\end{theorem}
		
\subsection{Одноразовый протокол подписи одного бита}
Это частный случай протокола для $m\in\bits$, $k(n)=1$:
противник просит нас подписать бит $b$, а потом пробует
подписать $1-b$.

\begin{theorem}
Если существует сильная односторонняя функция, то существует
и одноразовый протокол подписи одного бита.
\end{theorem}
\begin{proof}
Пусть $f_n:\bits^{k(n)}\to\bits^{l(n)}$ сильно односторонняя.
Сгенерируем пару $x^0_n,x^1_n\gets U_{k(n)}$ и положим $e_n = (f(x^0_n), f(x^1_n))$, $d_n=(x^0_n,x^1_n)$. Тогда алгоритм $S(e_n,d_n, \sigma)$ выдаёт $x^\sigma_n$, а
алгоритм $V((e^0_n, e^1_n), c, \sigma)$ будет проверять, 
что $e^\sigma_n = f_n(c)$.

Полнота очевидна по построению. Давайте проверим надёжность.
Пусть 
$$
\begin{aligned}
\sigma &= C_1(e_n),\\
c &= S(e_n, d_n, \sigma),\\
(\bar \sigma, \bar c) &= C_2(e_n,c),
\end{aligned}
$$
где $\bar c$~--- корректная подпись для 
$\bar\sigma$ для бесконечного числа $n$ с вероятностью
не менее $\epsilon_n\ge 1/p(n)$ для некоторого полинома $p(n)$. Цель: научиться обращать $f_n$ с вероятностью
не менее $\epsilon_n/2$. Для бесконечного числа $n$ схема
$C_1$ в случае успеха возвращает $\sigma\in\bits$ с вероятностью
не менее $\epsilon_n/2$. Не умаляя общности будем считать,
что $\sigma = 0$. Тогда, если мы хотим обратить $f_n(x)$,
то пробуем запустить $C_1,C_2$ на ключе $(f_n(r),f_n(x))$ 
для случайного $r\gets U_{k(n)}$. Вероятность успеха $\epsilon_n/2$.
\end{proof}

\subsection{Одноразовый протокол подписи $p(n)$ битов}
\begin{theorem}
Если существует одноразовый протокол подписи одного бита,
то для любого полинома $p(n)$ существует одноразовый протокол подписи сообщений из $p(n)$ битов.
\end{theorem}

\subsection{Одноразовый протокол подписи полиномиального числа битов}
Нам потребуется дополнительный примитив.
\begin{definition}
\emph{Семейство хеш-функций с трудно обнаружимыми коллизиями}\break
(СТОК)~--- это последовательность полиномиально вычислимых функций $h^n:\bits^{l(n)}\times \bits^{*}\to\bits^{k(n)}$, где $l(n)$ и $k(n)$~--- некоторые полиномы. Кроме того задана
доступная случайная величина $\alpha_n$ на строках длины $l(n)$.
Будем обозначать $h^n_t(x) = h^n(t,x)$.  Для любого 
полиномиального противника $C$ вероятность
$\Pr_{t\gets\alpha_n}[C(t) = (x, y)\mid h^n_t(x) = h^n_t(y)]$
пренебрежимо мала.
\end{definition}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\begin{thebibliography}{9}
    
    \bibitem{veresch17} Н.К. Верещагин. 
        \emph{Курс лекций ``Теоретико-сложностные проблемы криптографии''},
        МГУ, \url{http://lpcs.math.msu.su/~ver/teaching/cryptography/index.html}.
    
    \bibitem{dmitrits} Д.М. Ицыксон. \emph{Курс ``Теоретико-сложностные основы криптографии''}, 
        CS центр, \url{https://compsciclub.ru/courses/cryptography-foundations/2016-spring/}.

    \bibitem{gold} O. Goldreich. \emph{Foundations of cryptography}.

    \bibitem{hill} J. H\aa{}stad, R. Impagliazzo, L.A. Levin, M. Luby. 
        \emph{A Pseudorandom Generator from any One-way Function}.  
        SIAM J. Comput. 28, 4 (March 1999), 1364-1396.\\ 
        DOI: \url{https://doi.org/10.1137/S0097539793244708}
            
    \bibitem{katz} J. Katz, Y. Lindell. \emph{Introduction to Modern Cryptography}.

\end{thebibliography}

\listoftodos

\end{document}
% vim: set tw=120:
