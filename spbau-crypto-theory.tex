% !TeX spellcheck = ru_RU

\documentclass[12pt]{article}
\usepackage{cmap}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsthm,amsmath,amssymb}
\usepackage{xspace}
\usepackage{fullpage}
\usepackage{todonotes}
\usepackage{enumitem}

%% CALCULATOR
\usepackage{calc}
%% STYLE
\usepackage[dotinlabels]{titletoc}
\usepackage[small]{titlesec}
%% TITLESEC BUG WORKAROUND %%
\usepackage{etoolbox}
\makeatletter
\patchcmd{\ttlh@hang}{\parindent\z@}{\parindent\z@\leavevmode}{}{}
\patchcmd{\ttlh@hang}{\noindent}{}{}{}
\makeatother
%% END %%
\titlelabel{\thetitle.\quad}
%% Puts "." instead of ":" in captions
\usepackage{ccaption}
\captiondelim{. }

%\usepackage{indentfirst}
%% OTHER

\usepackage[bookmarks=false, colorlinks, unicode, pdfstartview=FitH, pdftex]{hyperref}
\hypersetup{ 
 plainpages=true,
 linkcolor=blue,
 citecolor=red,
 menucolor=blue,
 pdfnewwindow=true
}

\usepackage{tikz}
\usetikzlibrary{positioning,calc}

\newcommand{\bits}{\{0,1\}}
\newcommand{\bitstr}{\bits^*}
\newcommand{\sshalf}{{\textstyle\frac12}}
\newcommand{\seqn}[2]{{#1}_1,{#1}_2,\dotsc,{#1}_{#2}}
\newcommand{\seqin}[3]{{#1}_{{#2}_1},{#1}_{{#2}_2},\dotsc,{#1}_{{#2}_{#3}}}
\newcommand{\IC}{\mathrm{IC}}
\newcommand{\poly}{\mathrm{poly}}
\newcommand{\Nat}{\mathbb{N}}

\DeclareMathOperator{\dom}{dom}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\maj}{Maj}
\DeclareMathOperator{\rng}{rng}

\theoremstyle{definition}
\newtheorem{definition}{Определение}[section]

\theoremstyle{plain}
\newtheorem{theorem}{Теорема}[section]
\newtheorem{lemma}{Лемма}[section]
\newtheorem{statement}{Утверждение}[section]
\newtheorem{corollary}{Следствие}[section]

\theoremstyle{remark}
\newtheorem{example}{Пример}[section]
\newtheorem{exercise}{Упражнение}[section]
\newtheorem{remark}{Замечание}[section]
\newtheorem{problem}{Задача}[section]

\newenvironment{tasks}{\paragraph{Задачи.}\begin{enumerate}}{\end{enumerate}}

%opening
\title{,,Теоретико-сложностные основы криптографии``. Заметки к курсу в СПбАУ}
\author{А.В. Смаль}

\begin{document}

\maketitle

\begin{abstract}
Курс посвящён изучению теоретических оснований, на которых строится
надёжность криптографических протоколов.
\end{abstract}

%\newpage
\tableofcontents
\newpage


\section*{Введение}
Мы будем предполагать, что алгоритмы шифрования/дешифрования всем известны (т.е. no security by obscurity).

\section{Совершенная надёжность}
\begin{definition}
\emph{Система шифрования с закрытым ключом}~--- это пара
алгоритмов $E(k, m)$ и $D(k, c)$, такая, что
для любых $k$ и $m$ выполняется $D(k, E(k, m)) = m$. Система называется \emph{совершенно надёжной}, если для любых двух сообщений $m_1$ и $m_2$ случайные величины $E(k, m_1)$ и $E(k, m_2)$ при $k\gets \mathcal U(K)$ распределены одинаково ($\mathcal K$~--- пространство ключей).
\end{definition}
\begin{remark}
Система шифрования с одноразовым шифроблокнотом является совершенно надёжной.
\end{remark}

\begin{remark}
Для совершенной надёжности необходимо, чтобы длина ключа была не менее длины сообщения.
\end{remark}

\begin{theorem}
Пусть $P=NP$. Тогда для любой системы шифрования с закрытым ключом $(E,D)$ 
с полиномиальным алгоритмом $E$, в которой $|m|>|k|$, существуют сообщения 
$m_0$ и $m_1$ и полиномиальный алгоритм $A$, для которого
$$\Bigl|\Pr_k[A(E(k,m_0)) = 1]-\Pr_k[A(E(k,m_1)) = 1]\Bigr|\ge\frac12.$$
\end{theorem}
\begin{proof}
Не уменьшая общности предположим, что $\mathcal K = \bits^{n-1}$. 
Возьмём в качестве $m_0 = 0^n$. 
Пусть $S = \{E(k, 0^n)\mid k\in\mathcal K\}$. Легко видеть, что $S\in NP$ и $|S|\le 2^{n-1}$. Возьмём в качестве алгоритма $A$ полиномиальный разрешающий алгоритм для $S$, т.е. $A(y) := [y\in S]$ (он существует по предположению $P=NP$).

Для каждого сообщения $m$ рассмотрим $t_m = \bigl|\{k\mid E(k, m) \in S\}\bigr|$. 
Если существует сообщение $m^*$, для которого $t_{m^*} \le 2^{n-1}$, то $m_1 = m^*$ удовлетворяет требованиям. 

Предположим теперь, что $t_m > 2^{n-2}$ для любого $m$. Это значит, что существуют более $2^{n-2}\cdot 2^n = 2^{2n - 2}$ пар ключ-сообщение $(k,m)$, для которых 
$E(k,m)\in S$. Следовательно, для некоторого $y\in S$ существует более $2^{2n - 2} / |S| \ge 2^{n-1}$ пар $(k,m): E(k,m) = y$, т.е. существуют ключ $k$ и два различных сообщения $m'$ и $m''$: $E(k,m') = E(k,m'')$. Это противоречит корректности системы шифрования.
\end{proof}

\section{Односторонние функции}
Доказывать надёжность криптографических протоколов без каких-либо предположений, к сожалению, не получается~--- из такого доказательства следовало бы $P\neq NP$.
Было бы здорово показать, что криптография возможна, если $P\neq NP$, но это тоже не получается сделать. Поэтому в дальнейшем мы
будем отталкиваться от более сильного предположение~--- предположения о существовании \emph{односторонней функции}.

В дальнейшем мы будем рассматривать семейства функций $f_n: \bits^{k(n)} \to \bits^{l(n)}$, где $k(n)$ и $l(n)$ будут некоторыми полиномами. Кроме того, нас почти всегда будут интересовать
функции, которые можно вычислить за полиномиальное время.

\begin{definition}
    Семейство функций $f_n: \bits^{k(n)} \to \bits^{l(n)}$ называется 
    \emph{полиномиально вычислимым}, если имеется алгоритм, который получая на вход 
    число $n$ и $x$ длины $k(n)$ вычисляет $f_n(x)$ за полиномиальное от $n$ время.
\end{definition}

\subsection{Односторонние функции с худшем случае}
\begin{definition}
Полиномиально вычислимое семейство функций $f_n:\bits^{k(n)}\to \bits^{l(n)}$ называется 
\emph{односторонним в худшем случае}, если не существует полиномиально вычислимой функции 
$g_n$, что для любого $x\in\bits^{k(n)}$ верно $f_n(g_n(f_n(x))) = f_n(x)$.
\end{definition}

\begin{theorem}\label{th:weak-owf-p-np}
Односторонние функции с худшем случае существуют $\iff$ $P\neq NP$.
\end{theorem}
\begin{proof}\mbox{}
\begin{itemize}
\item[$\Rightarrow$] Пусть $P=NP$.
Определим язык $L = \{(1^n, y, z) \mid \exists x, |x| = k(n), z \sqsubset x, f_n(x) = y\}$, $L\in NP$. По предположению для $L$ существует полиномиальный разрешающий алгоритм. 
Для нахождения прообраза $y$ запустим этот алгоритм сначала на 
слове $(1^n, y, \lambda)$, где $\lambda$~--- пустая строка. 
Если это слово не принадлежит $L$, то $y$ не имеет прообраза.
В~противном случае восстановим прообраз $y$ по битам: сначала запустим алгоритм для слова $(1^n, y, 0)$ и проверим, есть ли у $y$ прообраз начинающийся с нуля. Далее аналогично восстановим второй и все последующие биты. Нам потребуется $k(n) + 1$ запуск полиномиального алгоритма, т.е. прообраз можно найти алгоритмически за полиномиальное время.

\item[$\Leftarrow$] Если $P\neq NP$, то можно построить одностороннюю в худшем на основе любой $NP$-трудной задачи.
Пусть $R(x,y)$~--- это отношение, задающее $NP$-трудную задачу $S$
(например, для $S = SAT$: $R(\phi, a) = 1 \iff \phi(a) = 1$). Пусть $f_n(x, y) = (x, R(x,y))$. 
Если $f_n^{-1}$ вычисляется за полиномиальное время, то и задачу $S$ можно решить за полиномиальное время,
вычислив $f^{-1}(x, 1)$.

\end{itemize}
\end{proof}


\subsection{Односторонние функции для алгоритмов}
Мы будем определять \emph{односторонние функции} для противника, который является 
вероятностным полиномиальным алгоритмом, т.е. для \emph{равномерного противника}.
\begin{definition}
    Полиномиально вычислимое семейство $f_n$ называется
    \emph{слабо односторонним для равномерного противника}, 
    если существует такой полином $p$, что 
    для любого полиномиального вероятностного алгоритма $R$ 
    при всех достаточно больших $n$
            $$\Pr_{x,R}[f_n(R(1^n, f_n(x))) = f_n(x)] < 1 - \frac{1}{p(n)}.$$

\end{definition}

\begin{definition}
    Полиномиально вычислимое семейство $f_n$ называется 
    \emph{сильно односторонним для равномерного противника}, 
    если существует такой полином $q$, что
    для любого полиномиального вероятностного алгоритма $R$ 
    при всех достаточно больших $n$
    $$\Pr_{x,R}[f_n(R(1^n, f_n(x))) = f_n(x)] < \frac{1}{q(n)}.$$
\end{definition}

\subsection{Односторонние функции для неравномерного противника}
Аналогичным образом можно определить односторонние функции для противника, 
являющегося последовательностью схем, т.е. для \emph{неравномерного противника}.
\begin{definition}
    Полиномиально вычислимое семейство $f_n$ называется
    \emph{слабо односторонним для неравномерного противника}, 
    если существует такой полином $p$, 
    что для любой последовательности схем $C_n$ полиномиального размера
    при всех достаточно больших $n$
        $$\Pr_{x}[f_n(x) = f_n(C_n(f_n(x)))] < 1 - \frac{1}{p(n)}.$$
\end{definition}

\begin{definition}
    Полиномиально вычислимое семейство $f_n$ называется
    \emph{сильно односторонним для неравномерного противника}, 
    если существует такой полином $q$, 
    что для любой последовательности схем $C_n$ полиномиального размера
    при всех достаточно больших $n$
        $$\Pr_{x}[f_n(x) = f_n(C_n(f_n(x)))] < \frac{1}{q(n)}.$$
\end{definition}

\begin{remark}
Односторонние функции для неравномерного противника можно было бы 
определять для \emph{вероятностных} схем, т.е. для схем, которым на вход
подают не только $f_n(x)$, но и некоторую строку со случайными битами $r$.
Однако, легко показать, что от случайных битов в таких определениях
можно избавиться: для этого нужно для каждого $n$ выбрать одну ``самую лучшую''
строку $r_n$, на которой достигается максимальная вероятность обращения $f_n$
и ``зашить'' её в схему. Нетрудно увидеть, что вероятность обращения при 
$r = r_n$ будет не меньше, чем по всем $r$ в среднем.
\end{remark}

В дальнейшем мы часто будем говорить про односторонние \emph{функции}, 
подразумевая под этим \emph{семейства} односторонних функций. 
Когда говорят про \emph{одностороннюю функцию}, то имеется 
в виду сильно односторонняя функция.

\begin{definition}
Если в определении односторонней функции убрать требование полиномиальной вычислимости,
то получится определение \emph{необратимой} функции.
\end{definition}

\subsection{Примеры односторонних функций}

Неизвестно, существуют ли односторонние или хотя бы слабо односторонние функции 
(даже для равномерного противника). Доказательство их существования повлечёт
за собой $P \neq NP$.

\begin{theorem}
Если $P=NP$, то любое полиномиально вычислимое семейство функций $f_n$ не является
слабо необратимым даже для равномерного противника. Более того, 
существует детерминированный алгоритм, который для всех $x$ по $n$ и 
$f_n(x)$ за полиномиальное от $n$ время находит некоторый прообраз 
$f_n(x)$ длины $k(n)$.
\end{theorem}
\begin{proof}
См. пункт ``$\Rightarrow$'' доказательства теоремы~\ref{th:weak-owf-p-np}.
\end{proof}
\begin{example}[произведение натуральных чисел]
Семейство $f_n$ устроено следующим образом: $k(n) = l(n) = 2n$, вход $x$ делится пополам, каждая половинка представляет собой $n$-битовое число, результат $f_n$~--- произведение этих чисел (получится не более чем $2n$-битовое число).
\end{example}
\begin{example}[SUBSET-SUM]
Семейство $f_n$ для SUBSET-SUM устроено следующим образом: 
$k(n) = n^2 + n$, $l(n) = n^2 + 2n + \lceil\log n\rceil$,
вход $x$ разбивается на $n+1$ блок длины $n$, 
первые $n$ блоков интерпретируются как $n$-битовые числа $x_1, \dotsc, x_n$, 
а последний блок интерпретируется как подмножество $[n]$. Тогда
$f_n(x) = \bigl\langle x_1, x_2, \dotsc, x_n, \sum_{i\in I} x_i \bigr\rangle$.
\end{example}

\subsection{Построение сильно односторонних функций из слабо односторонних}
\begin{theorem}
Если существуют слабо односторонние функции, то существуют и сильно односторонние функции (это верно для любых противников).
\end{theorem}
\begin{proof}
Будем доказывать для равномерного противника~--- для неравномерного доказательство будет аналогичным. 
Пусть $f$~--- слабо односторонняя функция, т.е.
существует такой полином $p$, что для любого полиномиального вероятностного алгоритма $R$
при всех достаточно больших $n$
$$\Pr_{x,r}[f_n(x) = f_n(R(1^n, f_n(x), r))] < 1 - \frac{1}{p(n)}.$$

Определим функцию $F$, которая определяется следующим соотношением:
$$F_n(x_1,x_2,\dotsc,x_N) = \langle f_n(x_1), f_n(x_2), \dotsc, f_n(x_N) \rangle,$$
т.е. $F_n : \bits^{N\cdot k(n)} \to \bits^{N\cdot l(n)}$. Для того, чтобы обратить $F_n$ нам нужно $N$ раз обратить функцию $f_n$. В каждом случае вероятность ошибки не меньше $1/p(n)$, поэтому общая вероятность успеха не более $\bigl(1-1/p(n)\bigr)^N$.
Для $N = n\cdot p(n)$ эта вероятность близка к $e^{-n}$, что убывает быстрее любого обратного полинома.
Таким образом функция $F$~--- сильно односторонняя.

В предыдущем рассуждении кроется ошибка. Дело в том, что мы предполагаем, что обращающий
алгоритм будет обязательно устроен следующим образом: он будет пытаться $N$ раз обратить
$f_n$, т.е. найти прообразы для $f_n(x_1),f_n(x_2),\dotsc,f_n(x_N)$. 
Это не обязательно так~--- мы не можем предполагать, что этот алгоритм будет
устроен каким-то конкретным образом. Поэтому предыдущее доказательство ошибочное, 
хотя получившаяся функция $F$ действительно сильно односторонняя.

Корректное доказательство этого факта будет устроено другим образом. Мы предположим, что
функция $F$ не является сильно односторонней и из этого покажем, что в свою
очередь функция $f$ не является слабо односторонней. Для этого мы воспользуемся
алгоритмом, который обращает $F$, для построения алгоритма обращения $f$. 
Предположим, что алгоритм $R_F$ умеет обращать $F$ с вероятностью успеха 
более $1/q(n)$ для некоторого полинома $q$. Тогда мы покажем, что 
существует алгоритм $R_f$, который обращает $f$ с вероятностью успеха более
$1 - 1/p(n)$.

Алгоритм $R_f$ мог бы быть устроен так: для обращения $y$ мы выберем 
случайные $x_2, x_3,\dotsc,x_N$ и запустим алгоритм $R_F$ на входе
$\langle y, f_n(x_2), f_n(x_3),\dotsc,f_n(x_N)\rangle$. Действительно,
если $R_F$ найдёт прообраз для этого входа, то он в т.ч. найдёт
и прообраз для $y$. Вероятность успеха $R_F$ на таком входе 
для случайного $y$ не менее вероятности успеха $R_F$ для случайных
$x_1,\dotsc,x_N$. Однако нам этого недостаточно~--- мы хотели бы получить
вероятность успеха близкую к единице. 

Для этого будем использовать два дополнительных приёма:
\begin{itemize}
\item будем пытаться подставить $y$ не только на место $f_n(x_1)$, а 
для каждого $i$ будем запускать алгоритм $R_F$ на входе
$\langle f_n(x_1),\dotsc, f_n(x_{i-1}), y,  f_n(x_{i+1}),\dotsc,f_n(x_N)\rangle$ для случайных
$x_1,\dotsc, x_{i-1}, x_{i+1},\dotsc,x_N$;\footnote{Этот приём необходим, т.к. в противном случае
у нас не получится увеличивать вероятность успеха. Действительно, если представить, что алгоритм 
$R_F$ не работает на строках, у которых первый бит нулевой, то вероятность успеха такого алгоритма
вполне может быть $1/2$. Но тогда и вероятность успеха $R_f$ не может быть выше $1/2$.}
\item будем повторять каждую итерацию $M$ раз для различных случайных независимых наборов $x_1,\dotsc, x_{i-1},x_{i+1},\dotsc,x_N$.
\end{itemize}

Давайте выделим один \emph{раунд} алгоритма $R_f$: для каждого $i$ выбирается 
независимый случайный набор $x_1,\dotsc, x_{i-1},x_{i+1},\dotsc,x_N$
и вызывается алгоритм $R_F$ на входе 
$\langle f_n(x_1),\dotsc, f_n(x_{i-1}), y,  f_n(x_{i+1}),\dotsc,f_n(x_N)\rangle$.
Этот этап будет повторён $M$ раз. Значение $M$ мы выберем позже, это будут некоторый полином от $n$. 

Введём обозначение $s_i(x)$~--- вероятность того, что алгоритм $R_F$ найдёт прообраз 
$\langle f_n(x_1),\dotsc, f_n(x_{i-1}), f_n(x),  f_n(x_{i+1}),\dotsc,f_n(x_N)\rangle$
для случайных $x_1,\dotsc, x_{i-1},x_{i+1},\dotsc,x_N$. Через $\hat s(x)$ обозначим
вероятность успеха одного раунда алгоритма $R_f$. Эта вероятность заведомо не меньше
максимальной вероятности среди всех $s_i(x)$, т.е. $\hat s(x) \ge \max_i s_i(x)$. 

Рассмотрим отдельно входы $x$, которые наш алгоритм $R_f$ обращает с маленькой
вероятностью, т.е. это ``трудные'' для обращения входы. Будем говорить, что $x$~--- трудный, 
если $\hat s(x) < \epsilon$ для некоторого обратного полинома $\epsilon$,
который мы выберем дальше. 
Долю трудных ``трудных'' слов среди всех слов длины $n$ мы обозначим через $\delta$,
т.е. $\delta = \Pr_{x\gets U_n}[\hat s(x) < \epsilon]$. 

Дальнейшее доказательство будет построено так: мы предположим, что получившийся алгоритм $R_f$ 
не обращает функцию $f$ с нужной вероятностью, т.е. вероятность его ошибки большее $1/p(n)$.
Из этого будет следовать, что доля трудных слов $\delta$ довольно большая 
(больше некоторого обратного полинома). А раз трудных слов много, то и вероятность успеха 
$R_F$ не может быть больше $1/q(n)$. Таким образом мы придём к противоречию.
Для реализации этого плана потребуется следующие две леммы.
\begin{lemma}\label{lm:owf:rf}
Вероятность ошибки $R_f$ при обращении слова $f_n(x)$ 
для случайного $x$ не больше $\delta + (1 - \epsilon)^M.$
\end{lemma}
\begin{proof}
По формуле полной вероятности вероятность ошибки $R_f$ 
при обращении слова $f_n(x)$ для случайного $x$ можно расписать
как вероятность ошибки на ``трудных'' входах и на простых входах.
$$\begin{aligned}
\Pr_{x,r}[\text{ошибка $R_f$}] 
&= \Pr_r[\text{ошибка $R_f$}\mid \hat s(x) <   \epsilon] \cdot \Pr_x[\hat s(x) <   \epsilon]\\ 
&+ \Pr_r[\text{ошибка $R_f$}\mid \hat s(x) \ge \epsilon] \cdot \Pr_x[\hat s(x) \ge \epsilon]\\
&\le 1 \cdot \delta + (1 - \epsilon)^M \cdot 1.
\end{aligned}
$$
\end{proof}

\begin{lemma}\label{lm:owf:rfn}
Вероятность успеха алгоритма $R_F$ при обращении слова $F(\bar x)$ 
для случайного $\bar x = x_1,\dotsc,x_N$ не больше $N\delta\epsilon + (1 - \delta)^N$.
\end{lemma}
\begin{proof}
Оценим вероятность успеха сверху по формуле полной вероятности:
$$\begin{aligned}
\Pr_{\bar x,r}[\text{успех $R_F$}] 
&= \Pr_r[\text{успех $R_F$}\mid \exists i, \hat s(x_i) <   \epsilon] \cdot \Pr_{\bar x}[\exists i, \hat s(x_i) < \epsilon]\\
&+ \Pr_r[\text{успех $R_F$}\mid \forall i, \hat s(x_i) \ge \epsilon] \cdot \Pr_{\bar x}[\forall i, \hat s(x_i) \ge \epsilon]\\
&\le \epsilon \cdot N\delta + 1 \cdot (1 - \delta)^N.
\end{aligned}
$$
\end{proof}

Предположим теперь, что у получившегося алгоритма $R_f$ вероятность ошибки больше, чем $1/p(n)$, 
т.е. $R_f$ обращает $f$ с вероятностью успеха меньше $1-p(n)$. Положим $M = n / \epsilon$. 
Тогда второе слагаемое в лемме~\ref{lm:owf:rf} будет порядка $e^{-n}$, что при
при достаточно больших $n$ меньше, чем $\frac{1}{2p(n)}$.  Таким образом
$\delta > \frac{1}{2p(n)}$.

Теперь мы хотим определить $N$ и $\epsilon$ так, чтобы вероятность успеха $R_F$ оказалась
меньше, чем $1/q(n)$. Выберем $N = n\cdot p(n)$, тогда при $\delta > \frac{1}{2p(n)}$ мы получаем, 
что второе слагаемое в лемме~\ref{lm:owf:rfn} будет порядка $e^{-n/2}$:
$$(1 - \delta)^N < \Bigl (1 - \frac{1}{2p(n)}  \Bigr)^{n\cdot p(n)} 
= \Biggl[\Bigl(1 - \frac{1}{2p(n)}  \Bigr)^{2p(n)}\Biggr]^{n/2} \approx e^{-n/2}.$$
При достаточно больших $n$ это меньше, чем $\frac{1}{2q(n)}$.
Осталось определить $\epsilon$ так, чтобы и первое слагаемое лемме~\ref{lm:owf:rfn}
было меньше $\frac{1}{2q(n)}$. Например, это достигается при
$$\epsilon = \frac{1}{2N\cdot q(n)} = \frac{1}{2n\cdot p(n)\cdot q(n)}.$$
При таким $M$, $N$ и $\epsilon$ получается, что алгоритм $R_f$ вызовет
полиномиальный алгоритм $R_F$ не более $M\cdot N = 2n^3\cdot p^2(n)\cdot q(n)$ раз,
т.е. $R_f$ сам по себе будет полиномиальным.

\end{proof}


\subsection{Частичные односторонние функции}
Односторонние функции, которые мы определили выше, определены
для всех слов длины $k(n)$. Можно обобщить это определение на
случай частичных функций, которые определены на некотором 
$D_n\subset\bits^{k(n)}$.
Для формализации этого определения нам описать, как будет
устроено равномерное распределение на $D_n$.

\begin{definition}
Последовательность распределений вероятностей $\mu_n$ 
на множестве двоичных слов называется \emph{полиномиально 
моделируемой}, если существует полиномиальный вероятностный
алгоритм $K$, такой, что для всех $x\in\bitstr$
$$\Pr_r[K(1^n, r) = x] = \mu_n(x).$$
\end{definition}

\begin{definition}
\emph{Статистическим расстоянием} между распределениями
вероятностей $\mu$ и $\nu$ называется
$$\delta(\mu,\nu) = \max_{A\subset\bitstr}|\mu(A) - \nu(A)|.$$
Не сложно показать, что максимум достигается при $A$ равном 
$\{x \mid \mu(x) > \nu(x)\}$ и его дополнению.
Таким образом 
$$\delta(\mu,\nu) = \frac12\sum_{x} |\mu(x) - \nu(x)|.$$
\end{definition}

\begin{definition}
Последовательности распределений $\mu_n$ и $\nu_n$ называются
\emph{статистически неотличимыми}, если статистическое расстояние
между ними стремится к нулю быстрее любого обратного полинома от $n$
при $n\to\infty$. 
\end{definition}

\begin{definition}
Случайные величины $\alpha_n$ и $\beta_n$ называются \emph{статистически
неотличимыми}, если их распределения $\mu_n(x) = \Pr[\alpha_n = x]$
и $\nu_n(x) = \Pr[\beta_n = x]$ статистически неотличимы.
\end{definition}

\begin{definition}
Распределение $\mu_n$ называется \emph{доступным}, если оно статистически
неотличимо от некоторого полиномиально моделируемого распределения $\nu_n$.
\end{definition}

\begin{definition}
Семейство частичных функций $f_n$ с областями определения $D_n$ называется 
\emph{сильно односторонним}, если $f_n$ полиномиально вычислимо, равномерное
распределение на $D_n$ доступно, и существует такой полином $q$, что для любого
полиномиального вероятностного алгоритма $R$,
$$\Pr_{x\gets D_n,r}[f_n(x) = f_n(R(1^n, f_n(x), r))] < \frac{1}{q(n)}$$
при всех достаточно больших $n$. Сильно одностороннее семейство частичных функций
$f_n$ называется \emph{сильно односторонней перестановкой}, 
если для всех $n$ оно является перестановкой своей области определения $D_n$.
\end{definition}
Аналогичным образом определяются \emph{слабо односторонние} функции и
\emph{односторонние функции} для неравномерного противника.

\begin{example}[Предположительно сильно односторонние частичные функции]
\mbox{}
\begin{enumerate}
\item \emph{Функция Рабина.} Функция $f_n$ определена на словах вида $xy$
длины $4n$, где $|x| = |y| = 2n$. При этом $x$ и $y$ интерпретируются как 
$2n$-битовые числа, удовлетворяющих следующим требованиям:
\begin{enumerate}
\item $y = p\cdot q$, где $p$ и $q$ простые $n$-битовые числа вида $4k+3$;
\item $x = z^2 \bmod y$ для некоторого $z$, взаимно простого с $y$.
\end{enumerate}
Значение функции на $xy$ равно конкатенации слов $x^2 \bmod y$ и $y$.

\item \emph{Функция RSA.} Функция RSA является обобщением функции Рабина.
Она определена на словах вида $xyz$, где $x$, $y$ и $z$ имеют длину $2n$
и интерпретируются как двоичные записи чисел, удовлетворяющие следующим
требованиям:
\begin{enumerate}
\item $y = p\cdot q$, где $p$ и $q$ простые $n$-битовые числа;
\item $x \in [1, pq - 1]$ и взаимно просто с $y$;
\item $z$ взаимно просто $\phi(pq) = (p-1)\cdot(q-1)$.
\end{enumerate}
Значение функции на $xyz$ равно конкатенации слов ($x^z \bmod y$), $y$ и $z$.
\item \emph{Дискретная экспонента.} Функция определена на словах вида $xyz$, где $x$, $y$ и $z$ имеют длину $n$ и соответствующие числа удовлетворяют следующим требованиям:
\begin{enumerate}
\item $y$~--- $n$-битовое простое число,
\item $x\in [2,y-1]$, порождает всю мультипликативную группу вычетов
по модулю $y$ (т.е. любой ненулевой вычет является степенью $x$),
\item $z\in [1,y-1]$.
\end{enumerate}
Значение функции на $xyz$ равно конкатенации слов $x$, $y$ и $(x^z\bmod y)$.
Обращение этой функции~--- является дискретным логарифмированием.
\end{enumerate}
Более подробно об этих примерах см. \cite{veresch17}.
\end{example}

\begin{definition}
Частичная функция $f_n:\{0,1\}^{k(n)}\to \{0,1\}^{l(n)}$ называется
\emph{проверяемой}, если по $n$, любому слову $x$ длины $k(n)$
и любому слову $y$ из множества значений $f_n$ можно 
за полиномиальное время проверить, верно ли, что $f_n$
определена на $x$ и её значение на $x$ равно $y$.
\end{definition}
\begin{remark}
Неизвестно, является ли функция Рабина проверяемой, т.к. неясно, как за полиномиальное время проверить, является
ли данное число квадратичным вычетом по составному модулю.
\end{remark}

\begin{definition}[trapdoor permutation]
Пусть задан полиномиальный вероятностный алгоритм $K$,
который получив на вход $1^n$ генерирует пару слов 
$\langle e, d \rangle$ или выдаёт $\perp$ (символ неудачи),
причём последнее происходит с пренебрежимо малой вероятностью.
%Будем называть \emph{необратимой перестановкой с секретом} семейство 
%перестановок $f_n^e: D_n^e\to D_n^e$ такое,
%что функция $\langle e,x\rangle\to\langle e, f_n^e(x)\rangle$~--- 
%односторонняя.
Слова $e,d$ будут называться \emph{открытым и закрытым ключами}. Будем через $A_n$ обозначать первые компоненты
всех возможных пар $\langle e,d\rangle$, генерируемых
алгоритмом $K$ на входе $1^n$. Пусть для каждого $e\in A_n$
задана перестановка $f_n^e$ некоторого множества слов $D_n^e$
длины $\poly(n)$. Последовательность пар 
$\langle\langle e_n, d_n\rangle,\{f_n^e\} \rangle$
будем называть \emph{односторонней перестановкой с секретом},
если выполнены следующие условия.
\begin{enumerate}
\item (Полиномиальная вычислимость.) Функция 
$\langle 1^n, e,x \rangle\to f_n^e(x)$ вычислима
за полиномиальное от $n$ время.
\item (Необратимость.) Для любой последовательности
схем $C_n$ полиномиального размера вероятность того,
что $C_n$ по $\langle e,f_n^e(x) \rangle$ найдёт $x$,
стремится к нулю быстрее любого обратного полинома от $n$
($e$ выбирается случайно из $A_n$, 
$x$ выбирается независимо от $e$).
\item (Доступность равномерного распределения на области определения).
Существует вероятностный полиномиальный алгоритм $B$,
который по $1^n$ и любому $e\in A_n$ генерирует случайную
величину, статистически неотличимую от равномерного 
распределения случайной величина в $D_n^e$ при известном $e_n$.
(Т.е. пара, состоящая из $e$ и выхода алгоритма $B$
статистически неотличима от пары, состоящей из $e$ и 
случайной строки $D_n^e$.)

Из этого условия следует доступность случайной величины
$$\langle e_n, \text{случайный элемент $D_n^e$} \rangle.$$

\item (Возможность обращения при известном закрытом ключе.)
Существует полиномиальный вероятностный алгоритм, который
по тройке $\langle 1^n, d, f_n^e(x) \rangle$ с вероятностью
приблизительно равной $1$ вычисляет $x$. Здесь пара
$\langle e,d \rangle$ выбирается генератором случайный
величины $\langle e_n,d_n \rangle$, а $x$ выбирается
равномерно в $D_n^e$.
\end{enumerate}
\end{definition}
\begin{remark}
Предположение о существовании односторонних перестановок
с секретом сильнее, чем существование односторонних
функций. Если функция Рабина или RSA является односторонней,
то существуют односторонние перестановки с секретом.
\end{remark}

\section{Генераторы псевдослучайных чисел}
\subsection{Вычислительно неотличимые случайные величины}
\begin{definition}[Для неравномерного противника]
Случайные величины $\alpha_n$ и $\beta_n$, зависящие
от натурального параметра $n$, со значениями в множестве
слов некоторой длины $l(n)$ называются вычислительно
неотличимыми, если для любой последовательности схем
$C_0,C_1,\dotsc, C_n,\dotsc$ размера $\poly(n)$
(с $l(n)$ входами и одним выходом) вероятность событий
$C_n(\alpha_n) = 1$ и $C_n(\beta_n) = 1$ отличаются на 
пренебрежимо малую величину. Схема $C_n$ в этом контексте
называется \emph{тестом} и мы говорим, что случайная величина
$\alpha_n$ проходит тест $C_n$, если $C_n(\alpha_n)= 1$.
Таким образом, мы требуем, чтобы $\alpha_n$ и $\beta_n$
проходили любые тесты полиномиального размера с приблизительно
равной вероятностью.
\end{definition}

\begin{definition}[Для равномерного противника]
Случайные величины $\alpha_n$ и $\beta_n$, зависящие
от натурального параметра $n$, со значениями в множестве
слов некоторой длины $l(n)$ называются вычислительно
неотличимыми, если для любого вероятностного 
полиномиального алгоритма $T$ вероятность событий
$T(1^n, \alpha_n) = 1$ и $T(1^n, \beta_n) = 1$ отличаются на 
пренебрежимо малую величину. Алгоритм $T$ в этом контексте
называется \emph{тестом} и мы говорим, что случайная величина
$\alpha_n$ проходит тест $T$, если $T(1^n, \alpha_n)= 1$.
\end{definition}

\begin{remark}
Если $\alpha_n$ и $\beta_n$ статистически неотличимы,
то они и вычислительно неотличимы (например, для неравномерного
противника), поскольку разность вероятностей $\alpha_n$
и $\beta_n$ в множество $\{x\mid C_n(x)\}$, задаваемое
тестом $C_n$, не превосходит статистического расстояния
между $\alpha_n$ и $\beta_n$.
\end{remark}

\begin{lemma}[Свойства вычислительной неотличимости]
\mbox{}
\begin{enumerate}
\item Отношение вычислительной неотличимости рефлексивно, симметрично и транзитивно.

\item Для неравномерного противника: вычислительно неотличимые
последовательности случайных величин $\alpha_n$ и $\beta_n$
вычислительно неотличимы и вероятностными тестами 
полиномиального размера. Это означает, что для любой последовательности
$T_n$ вероятностных схем полиномиального от $n$ размера с $l(n)$
входами, вероятности событий $T_n(\alpha_n) = 1$ и $T_n(\beta_n) = 1$
приблизительно равны.

\item Если $\alpha_n$ и $\beta_n$ вычислительно неотличимы,
а $C_n$~--- последовательность вероятностных схем полиномиального размера с $l(n)$ входами, то и случайные
величины $C_n(\alpha_n)$ и $C_n(\beta_n)$ вычислительно
неотличимы. Аналогично для равномерного противника.

\item Пусть случайные величины $\alpha_n$, $\beta_n$
и $\gamma_n$ имеют совместное распределение. И пусть
для любой последовательности значений $c_n$ случайной
величины $\gamma_n$ случайные величины 
$(\alpha_n\mid\gamma_n = c_n)$ и 
$(\beta_n\mid\gamma_n = c_n)$ вычислительно неотличимы.
Тогда и $\alpha_n\gamma_n$ и $\beta_n\gamma_n$ вычислительно
неотличимы.

Для равномерного противника это свойство справедливо только
для независимых случайных величин $\alpha_n$, $\gamma_n$,
причём случайная величина должны быть полиномиально моделируемой.
\end{enumerate}
\end{lemma}
\begin{proof}\mbox{}
\begin{enumerate}
\item[1-2.] Очевидно.
\item[3.] Пусть дана последовательность тестов $T_n$
позволяет отличать $C_n(\alpha_n)$ и $C_n(\beta_n)$.
Тогда последовательность схем $D_n(x) = T_n(C_n(x))$
будет вероятностным тестом полиномального размера 
для случайных величин $\alpha_n$ и $\beta_n$.

\item[4.] Допустим, что существует последовательность 
схем-тестов $T_n$ полиномиального размера такая, что
вероятность $T_n(\alpha_n\gamma_n) = 1$
$T_n(\beta_n\gamma_n) = 1$ отличается $\epsilon = 1/\poly(n)$
для бесконечно многих $n$. Разность вероятностей
событий $T_n(\alpha_n\gamma_n) = 1$
$T_n(\beta_n\gamma_n) = 1$ равна среднему значению разности
вероятностей
$$
\Pr[T_n(\alpha_n c) \mid \gamma_n = c] - 
\Pr[T_n(\beta _n c) \mid \gamma_n = c]
$$
по случайно выбранному $c$ (в соответствии с распределением
случайной величины $\gamma_n$). Поэтому для бесконечно
многих $n$ найдётся $c=c_n$ в множестве значений $\gamma_n$,
для которой разность вероятности не меньше $\epsilon$.
Если ``зашить'' $c_n$ в схему $T_n$, то получится полиномиальный тест, различающий 
$(\alpha_n\mid\gamma_n = c_n)$ и 
$(\beta_n\mid\gamma_n = c_n)$.
\end{enumerate}
\end{proof}

\subsection{Генераторы псевдослучайных чисел}
\begin{definition}
Пусть даны многочлены $k(n)$ и $l(n)$ такие, что
$l(n) > k(n)$ для всех $n$. \emph{Генератором
псевдослучайных чисел типа $k(n)\to l(n)$} будем
называть семейство функций $G_n : \bits^{k(n)}\to \bits{l(n)}$, удовлетворяющее следующим условиям.
\begin{enumerate}
\item Семейство $G_n$ вычислимо за полиномиальное от $n$ время.
\item (Надежность генератора ПСЧ.) Случайная величина $G_n(s)$ для равномерного случайного $s$ вычислительно неотличима от случайной величины равномерно распределенной
на всех словах длины $l(n)$.
\end{enumerate}
\end{definition}

\begin{definition}
\emph{Генератор псевдослучайных чисел типа $k(n)\to\infty$} будем
называть семейство отображений $G_n: \bits^{k(n)}\to\bitstr$,
удовлетворяющее следующим требованиям.
\begin{enumerate}
\item Существует алгоритм, который по слову $s$ и натуральному числу $l$
вычисляет элемент последовательности $G_n(s)$ с номером $l$ за время, полиномиальное
от $|s| + l$.

\item Случайная величина $G_n(s)$ вычислительно неотличима от равномерно
распределённой бесконечной последовательности нулей и единиц.
(Это означает, что для любого полинома $p(n)$ первые $p(n)$ битов
$G_n(s)$ вычислительно неотличимы от случайной величины равномерно
распределённой на всех словах длины $p(n)$.)
\end{enumerate}
\end{definition}
 
\begin{remark}
По генератору ПСЧ типа $k(n)\to\infty$ можно построить генератор ПСЧ
типа $k(n)\to l(n)$ для любого полинома $l(n)$ (нужно взять первый $l(n)$ битов).
\end{remark}

\begin{theorem}
Если существует генератор ПСЧ $G_n$ типа $k(n)\to l(n)$,
то существуют и односторонние функции.
\end{theorem}
\begin{proof}
Действительно, можно рассмотреть сам генератор $G_n$ как слабо одностороннюю функцию.
Давайте покажем, что никакая последовательность схем полиномиального размера 
$C_n$ не обращает $G_n$ с вероятностью успеха более $3/4$ для бесконечно многих $n$.
Предположим, что такая последовательность существует. Тогда можно рассмотреть
следующий полиномиальный тест для последовательностей длины $l(n)$: для входа $y$ проверяем, что $G_n(C_n(y)) = y$. Если это верно (т.е. обращение произошло удачно), 
то выдаём $1$, а иначе $0$. Вероятность того, что $G_n$ пройдёт такой тест 
не менее $3/4$. При этом равномерно распределённая на $l(n)$ случайная 
величина пройдёт этот тест с вероятностью не более $1/2$ (т.к. размер 
образа $G_n$ не более $1/2$). 
\end{proof}
Обратное утверждение тоже верно. 
\begin{theorem}[\cite{hill}]
Если существует односторонняя функция, то существует
и генератор псевдослучайных чисел типа $n\to\infty$.
\end{theorem}
Мы же докажем более простое утверждение.
\begin{theorem}
Если существует односторонняя перестановка, то существует
и генератор псевдослучайных чисел типа $n\to\infty$.
\end{theorem}

В дальнейшем мы будем говорить про \emph{полиномиального противника}
подразумевая под этим две возможных формулировки: полиномиальный
вероятностный алгоритм и семейство схем полиномиального размера.

\subsection{Трудный бит}
\begin{definition}
Для пары совместно распределённых случайных величин $(\gamma_n,\beta_n)$, где $\beta_n$ распределена на
$\bits$ будем говорить, что $\beta_n$ является \emph{вычислительно трудной} относительно $\gamma_n$, 
если для любого полиномиального противника $B$
$$\left|\Pr[B(\gamma_n) = \beta_n] - \tfrac12\right| < \frac{1}{p(n)}$$
для любого полинома $p$ для достаточно больших $n$.
\end{definition}

\begin{theorem}\label{thm:hard-random-value}
Случайная величина $\beta_n$ вычислительно трудна относительно $\gamma_n$ тогда и только тогда,
когда случайная величина $\beta_n\gamma_n$ вычислительно неотличима от $r_n\gamma_n$, 
где $r_n$~--- это равномерно распределённая на $\bits$ случайная величина.
\end{theorem}
\begin{proof}\mbox{}
\begin{itemize}
\item[$\Leftarrow$] Пусть существует противник $B$, который для бесконечного числа $n$
предсказывает $\beta_n$ по $\gamma_n$ с хорошей вероятностью, т.е.
$$\Pr[B(\gamma_n) = \beta_n]\ge \tfrac12 + \epsilon_n,$$
где $\epsilon_n$~--- обратный полином.
Используя противника $B$ построим противника $A$, который различает $\beta_n\gamma_n$ и $r_n\gamma_n$.
$$A(x,y) = 
\begin{cases}
1, & B(y) = x,\\
0, & B(y) \neq x.
\end{cases}
$$
Тогда $\Pr[A(\beta_n\gamma_n) = 1]\ge\frac12 + \epsilon_n$, а $\Pr[A(r_n\gamma_n) = 1] = \frac12$.

\item[$\Rightarrow$] Пусть существует противник $A$, который для бесконечного числа $n$ 
различает $\beta_n\gamma_n$ и $r_n\gamma_n$ с хорошей вероятностью, т.е.
$$\Pr[A(\beta_n\gamma_n) = 1] - \Pr[A(r_n\gamma_n) = 1]\ge\epsilon_n,$$
где $\epsilon_n$~--- обратный полином.  Построим противника $B$, который предсказывает $\beta_n$ по $\gamma_n$.
$$B(x) = 
\begin{cases}
r, & A(0x) = 0,\ A(1x) = 0,\\
1, & A(0x) = 0,\ A(1x) = 1,\\
0, & A(0x) = 1,\ A(1x) = 0,\\
r, & A(0x) = 1,\ A(1x) = 1,\\
\end{cases}
$$
где $r$ означает случайный бит.

Покажем, что 
$$\Pr[B(\gamma_n) = \beta_n] = \frac12 + \Pr[A(\beta_n\gamma_n) = 1] - \Pr[A(r_n\gamma_n) = 1] \ge \frac12 + \epsilon_n.$$
Давайте докажем это равенство для фиксированного $\gamma_n = x$:
$$\Pr[B(\gamma_n) = \beta_n\mid \gamma_n = x] = 
  \frac12 + \Pr[A(\beta_n\gamma_n) = 1\mid \gamma_n = x] - \Pr[A(r_n\gamma_n) = 1\mid \gamma_n = x].$$
Отсюда по формуле полной вероятности получается требуемое равенство. Для того, чтобы убедиться,
что это равенство верно, нужно подставить все четыре возможные варианта из определения $B$
и проверить, что равенство выполняется.

\begin{remark}
В случае неравномерного противника данная конструкция даёт вероятностную схему, 
которую, как описано выше можно переделать в детерминированную. В случае равномерного
противника нам потребовалось бы также фиксировать внутренние биты вероятностного алгоритма.
\end{remark}
\end{itemize}
\end{proof}

\begin{definition}
Для односторонней перестановки $f_n: D_n\to D_n$, где $D_n\subset\bits^{k(n)}$,
будем называть \emph{трудным битом} такую полиномиально вычислимую функцию $h_n: D_n\to\bits$,
для которой случайная величина
$h_n(U(D_n))$ трудна для $f_n(U(D_n))$. 
\end{definition}

\begin{statement}
Пусть $f_n:D_n\to D_n$~--- односторонняя перестановка с трудным битом $h_n: D_n\to\bits$.
Тогда случайная величина $h_n(x)f_n(x)$ вычислительно неотличима от $r x$, где $x\gets U(D_n)$,
а $r\gets U_1$.
\end{statement}
\begin{proof}
Заметим, что $f_n(x)$ распределено так же, как $x$ (важно, что $f_n$~--- перестановка). Поэтому
$r f_n(x)$ распределено так же, как $r f_n(x)$. Осталось применить теорему~\ref{thm:hard-random-value}
для $r f_n(x)$ и $h_n(x)f_n(x)$.
\end{proof}

Это конструкцию можно итерировать. Например, $h_n(x) h_n(f_n(x)) f_n(f_n(x))$ позволяет получить 
два бита. Заметим, что если случайная величина $h_n(x) h_n(f_n(x)) f_n(f_n(x))$ отличима 
от $r h_n(f_n(x)) f_n(f_n(x))$, то отличимы $h_n(x) f_n(x)$ и $r f_n(x)$ (первые можно получить из вторых).
Продолжая рассуждение получаем, что $h_n(x) h_n(f_n(x)) f_n(f_n(x))$ неотличима от $rr'x$, где $r,r'\gets U_1$.

\begin{theorem}
Пусть $f_n:D_n\to D_n$~--- односторонняя перестановка с трудным битом $h_n: D_n\to\bits$.
Тогда случайная величина 
$$h_n(x)h_n(f_n(x))\dotsc h_n(f^{(p(n))})f_n^{(p(n) + 1)}(x)$$
вычислительно неотличима от случайной величины 
$$r_1r_2\dotsc r_{p(n)}x,$$
где $r_1,\dotsc,r_{p(n)}\gets U_1$, $x\gets U(D_n)$.
\end{theorem}
\begin{corollary}
$G_n(x) = h_n(x)h_n(f_n(x))\dotsb h_n(f^{(p(n))})f_n^{(p(n) + 1)}(x)$ является надёжным генератором псевдослучайных чисел.
\end{corollary}
\begin{proof}
Доказательство ,,гибридным`` методом.
$$
\begin{array}{llllll}
T_0 = & h_n(x)&h_n(f_n(x))&\dotsc  &h_n(f^{(p(n))})  &f_n^{(p(n) + 1)}(x)\\
T_1 = &r_1   &h_n(x)     &\dotsc  &h_n(f^{(p(n)-1)})&f_n^{(p(n))}(x)\\
T_2 = &r_1   &r_2        &\dotsc  &h_n(f^{(p(n)-2)})&f_n^{(p(n)-1)}(x)\\
\vdots   &\vdots&\vdots     &\dotsc  &\vdots			 &\vdots\\
T_{p(n)}= &r_1   &r_2        &\dotsc  &r_{p(n)}		 &x\\
\end{array}
$$
Пусть взломщик $B$ отличает $T_0$ от $T_{p(n)}$, т.е. $\Pr[B(T_0) = 1] - \Pr[B(T_0) = 1]\ge\epsilon_n$
для бесконечного числа $n$ и обратного полинома $\epsilon_n$. Тогда существует такое $i$, что
$$\Pr[B(T_i) = 1] - \Pr[B(T_{i+1}) = 1]\ge\epsilon_n/p(n).$$ Т.е. мы научились отличать
$$
\begin{array}{llllllll}
r_1   &\dotsc & r_i & h_n(x)  & h_n(f_n(x)) &\dotsc& h_n(f^{(p(n)-i)})    &f_n^{(p(n) - i + 1)}(x)\\
r_1   &\dotsc & r_i & r_{i+1} & h_n(x)      &\dotsc& h_n(f^{(p(n)-i - 1)})&f_n^{(p(n) - i)}(x)\\
\end{array}
$$
Можно воспользоваться тем, что $x$ распределён также как $f_n(x)$ и переписать $T_{i+1}$
$$
\begin{array}{llllllll}
r_1   &\dotsc & r_i & h_n(x)  & h_n(f_n(x)) &\dotsc& h_n(f^{(p(n)-i)}) &f_n^{(p(n) - i + 1)}(x)\\
r_1   &\dotsc & r_i & r_{i+1} & h_n(f_n(x)) &\dotsc& h_n(f^{(p(n)-i)}) &f_n^{(p(n) - i + 1)}(x)\\
\end{array}
$$
Используя противника, который отличает эти две случайные величины мы можем отличать $h_n(f)f_n(x)$ от $r f_n(x)$~---
по этим случайным величинам можно детерминированным алгоритмом построить $T_{i}$ и $T_{i+1}$.

\begin{remark}
В этом доказательстве мы воспользовались тем, что наш у нас неравномерный противник, т.е. для схема,
т.к. мы в эту схему зашили число $i$. В случае с алгоритмами можно взять случайное $i$ и доказать, 
что с хорошей вероятностью оно подойдёт.
\end{remark}
\end{proof}

\begin{theorem}[Голдрейх, Левин]
Пусть $f_n:D_n\to D_n$~--- односторонняя перестановка, $D_n\subseteq \bits^{k(n)}$.
Рассмотрим две функции: $g_n: D_n\times \bits^{k(n)}\to D_n\times \bits^{k(n)}$ и $h_n: D_n\times \bits^{k(n)}\to \bits$, такие что
$$g_n(xy)= f_n(x)y,\quad h_n(x,y) = x\odot y = \bigoplus_{i=1}^{k(n)} x_iy_i = \sum_{i=1}^{k(n)} x_iy_i\mod2.$$ 
Тогда $g_n$~--- односторонняя перестановка
с трудным битом $h_n$.
\end{theorem}

\begin{definition}
\emph{Код Уолша-Адамара}~--- это код исправляющий ошибки $WH: \bits^k\to\bits^{2^k}$,
определяющий следующим соотношением $WH(x)=(x\odot y)_{y\in\bits^{k}}$.
\end{definition}
Код Уолша-Адамара не очень удобен в практических применениях, 
т.к. он удлиняет строки в экспоненту раз.
Однако он обладает одним очень хорошим свойством.
\begin{statement}
Код Уолша-Адамара имеет расстояние $2^{k-1}$.
\end{statement}
\begin{proof}
Пусть $x_i\neq y_i$. Рассмотрим $r$ и $r^{\oplus i}$, где $r,r^{\oplus i}\in\bits^{k}$ и отличаются только в бите $i$.
Тогда либо $x\odot r$ отличается от $x\odot r^{\oplus i}$, либо $y\odot r$ отличается от $y\odot r^{\oplus i}$.
Т.е. все $\bits^k$ можно разбить на пары, различающиеся в одном бите, то все пары строк имеют коды, отличающиеся
ровно в половине всех битов.
\end{proof}

\begin{lemma}\label{lm:WH-list-decoding}
Пусть $s\in\bits^{2^m}$ и $\Pr_i[s_i \neq WH(x)] \le 1/2 - \epsilon$ (в терминах расстояния Хеммнига $\Delta(WH(x), s) \le (1/2 - \epsilon)2^m$). Существует вероятностный алгоритм $A^s$ со временем работы $\poly(m, \frac{1}{\epsilon})$, который выдаёт
список $L$ слов длины $m$ такой, что $x\in L$ с вероятностью не менее $1/2$ (алгоритм получает оракульный доступ к строке $s$).
\end{lemma}

\begin{proof}[Доказательство теоремы Голдрейха-Левина]
Функция $g_n$ является перестановкой. Легко показать, что если противник взламывает
$g_n$, то он взламывает и $f_n$, т.е. $g_n$ является односторонней перестановкой.

Теперь нужно показать, что $h_n$ является трудным битом $g_n$. 
Пусть существует неравномерный противник $B$ (в дальнейшем будем предполагать, 
что противник~--- это всегда семейство схем), который предсказывает $h_n$, т.е. 
$$\Pr_{\substack{x\gets U(D_n), y\gets U_{k(n)}}} [B(f(x)y) = x\odot y] \ge 1/2 + \epsilon_n$$
для бесконечного числа $n$ и обратного полинома $\epsilon_n$. Построим противника $C$,
который обращает $f_n$, т.е.
$$\Pr_{x\gets U(D_n)}[C(f_n(x)) = x]\ge \epsilon_n/4.$$
Противник $C$ будет использовать алгоритм декодирования списком кода Уолша-Адамара из леммы~\ref{lm:WH-list-decoding}
и при обращении к биту $y$ выдаём значение $B(f(x)y)$.
В списке $L$, который возвращает алгоритм $A$ ищем $z$ такое, что $f_n(z) = f_n(x)$. Если такое $z$ нашлось, то выдаём его, 
иначе выдаём любую строку.

Пусть $M\subseteq D_n$ и $x\in M\iff \Pr_{y\gets U_{k(n)}}[B(f_n(x)y) = x\odot y]\ge 1/2 + \epsilon_n/2.$
Давайте покажем, что $\Pr_{x\gets U(D_n)} [x\in M]\ge \epsilon_n/2$. Пусть это не так, тогда
$$
\begin{aligned}
\Pr_{x,y}[B(f_n(x)y) = x\odot y] &= 
    \Pr_{x,y}[B(f_n(x)y) = x\odot y \mid x    \in M] \cdot \Pr_x[x    \in M]\\ 
&+  \Pr_{x,y}[B(f_n(x)y) = x\odot y \mid x\not\in M] \cdot \Pr_x[x\not\in M]\\
&< 1 \cdot \epsilon_n/2 + (1/2 + \epsilon_n/2) \cdot 1 < 1/2 + \epsilon_n.
\end{aligned}
$$

Заметим, что $\Pr_{x}[C(f_n(x)) = x\mid x\in M]\ge 1/2,$ т.к. с вероятность не менее $1/2$ в списке будет искомый элемент.
Поэтому получаем
$$
\Pr_{x} [C(f_n(x)) = x]\ge \Pr_{x} [C(f_n(x)) = x\mid x\in M]\cdot \Pr_x[x    \in M]
\ge \frac12 \cdot \frac{\epsilon_2}{2} = \frac{\epsilon_n}{4}.
$$
\end{proof}
\begin{proof}[Доказательство леммы~\ref*{lm:WH-list-decoding}]
Будем рассматривать код Уолша-Адамара как таблицу истинности некоторой функции $f:\{0,1\}^m\to 1$.
Пусть $WH(x)$ соответствует $f$, а кодовое слово $s$~--- некоторой функции $\tilde{f}$. Таким 
образом для восстановления $x$ нам нужно вычислить $f$ на входах $100\dotsb0$, $010\dotsb0$, $001\dotsb0$,\ldots
Действительно, 
$$
\begin{aligned}
&x_1 = f(100\dotsb0)\\
&x_2 = f(100\dotsb0)\\
&\vdots\\
&x_n = f(000\dotsb n)
\end{aligned}
$$
Для того, чтобы вычислить $f(z)$ выберем случайный $r$ и вычислим
$f(z) = f(r) + f(z + r).$
Проблема в том, что у нас есть доступ только к $\tilde{f}$, т.е.
мы можем попробовать вычислять $f(z) = \tilde{f}(r) + \tilde{f}(z + r).$
Если бы ошибка в $\tilde{f}$ случалась с вероятностью менее $1/4-\epsilon$,
то суммарная ошибка при таком вычислении $f(z)$ была бы не более $1/2 - 2\epsilon$.
Тогда мы могли бы её амплифицировать и получить $f(z)$ с хорошей вероятностью.
Однако, ошибка в $f$ случается с большей вероятностью.

Если бы у нас был доступ к истинному значению, то тогда бы тоже всё сработало
$f(z) = f(r) + \tilde{f}(z + r)$, но доступа к $f$ у нас нет. Давайте попытаемся
вычислить верное $f(r)$: выберем случайные $r_1,r_2,\dotsc,r_N$ и вычислим $\maj_i\{f(r_i) + f(r + r_i)\}$.

\begin{remark}{Неравенство Чебышёва (закон больших чисел для 2-независимых случайных величин).}
Пусть $X_1,X_2,\dotsc,X_N$~--- одинаково распределённые попарно-независимые 
Бернулиевские случайные величины, $\forall i, \Pr[X_i = 1] = p$, тогда
$$\Pr\Biggl[ \biggl|\frac{\sum_i X_i}{N} - p\biggr| \ge \delta \Biggr]\le \frac{1}{\delta^2 N}.$$
\end{remark}

Давайте выберем $N=2^k - 1$. Выберем $t_1,t_2,\dotsc,t_k\gets U_m$~--- независимые случайные строки.
Из этих случайных строк можно сгенерировать $N$ попарно независимых следующим образом:
$$\forall J\subseteq \{1,\dotsc,k\},\ J\neq\emptyset,\ r_J = \bigoplus_{i\in J} t_i.$$

\begin{statement}
Если $J_1 \neq J_2$, то $r_{J_1}$ и $r_{J_2}$ будут независимыми.
\end{statement}
\begin{corollary}
$\{r_J\}_J$~--- 2-независимые случайные величины.
\end{corollary}

Теперь опишем алгоритм декодирования кода Уолша-Адамара. 
Выберем $N=2^k - 1$. Сгененируем независимые $t_1,t_2,\dotsc,t_k\gets U_m$.
Для всех $a_1, \dotsc, a_k\in \{0,1\}$ добавим в список строку $x_1,\dotsc,x_m$, где 
$$x_i = \maj_J\Bigl\{\bigoplus_{j\in J} a_j + \tilde{f}(0\dotsb\underset{i}{1}\dotsb 0 + r^J)\Bigr\},$$
где $r_J = \bigoplus_{i\in J} t_i$.
Для успеха $x_i$ должен быть верен с вероятностью не менее $1 - \frac{1}{10m}$.
Определим случайные величины $\{X_J\}$ такие, что 
$$X_J = 1\iff \tilde{f}(0\dotsb\underset{i}{1}\dotsb 0 + r^J) = f(0\dotsb\underset{i}{1}\dotsb 0 + r^J).$$
По закону больших чисел вероятность того, что при вычислении $\maj$ мы получим более половины неправильных
значений $\tilde{f}$ не более $\frac{1}{\epsilon^2 N}$. Т.е. требуется, что $\frac{1}{\epsilon^2 N} \le \frac{1}{10m}$.
$$\Pr[\text{$x_i$ вычислен не верно}] = \Pr\Bigl[\frac{1}{N}\sum X_J \le \frac{1}{2}\Bigr]\le \frac{1}{\epsilon^2 N}.$$
Таким образом $N> \frac{10m}{\epsilon^2}.$
\end{proof}

\section{Протоколы с секретным ключом}
\begin{definition}
Пусть дана доступная случайная величина $d_n$. Пусть даны два вероятностных полиномиальных по времени алгоритма
$E(d_n,x)$ и $D(d_n, m)$ такие, что $D(d_n, E(d_n, x)) = x$, будем называть \emph{одноразовым протоколом с секретным ключом}.
Будем говорить, что этот протокол \emph{надёжный}, если для любого полинома $k$, последовательности $x_n$ слов длины $k(n)$ и последовательности $y_n$ длины $k(n)$ случайные величины $E(d_n, x_n)$ и $E(d_n, y_n)$ вычислительно неотличимы.
\end{definition}

Такой протокол мы уже можем построить. Возьмём генератор псевдослучайных чисел $G: \bits^n\to\bits^{k(n)}$.
Возьмём $d_n = U_n$ и для $x\in\bits^{k(n)}$ определим 
$$
\begin{aligned}
E(d_n, x) &= G(d_n) \oplus x,\\ D(d_n, m) &= G(d_n) \oplus m.
\end{aligned}
$$
Если бы противник научился бы отличать случайные величины $E(d_n, x_n)$ и $E(d_n, y_n)$, то 
он также научился бы отличать одну из этих случайных величин от равномерного распределения
$U_{k(n)}$. Пусть он умеет отличать $E(d_n, x_n)$ от $U_{k(n)}$. Тогда мы можем зашить $x_n$ в схему 
и таким образом научиться отличать образ $G(d_n)$ от $U_{k(n)}$.

\begin{definition}
Пусть $S_n \subseteq\bits^{l(n)}$ и для любого $s\in S_n$ определена функция $f_s: \bits^n\to\bits^n$.
Множество функций $\{f_s\}_{s\in S_n}$ называется \emph{семейством псевдослучайных функций}, если 
выполняются следующие свойства.
\begin{enumerate}
\item Существует полиномиальный по времени алгоритм, который по $(s, x)$ вычисляет $f_s(x)$.
\item Распределение $U(S_n)$ доступно.
\item (\emph{слабая надёжность}) Для любого полинома $p$ и для любого набора различных 
$t_1,\dotsc, t_{p(n)}\in \bits^n$ случайная величина $f_s(t_1)f_s(t_2)\dotsb f_s(t_{p(n)})$ 
вычислительно неотличима от $U_{np(n)}$, где $s\gets U(S_n)$.
\item[$3'$.] (\emph{сильная надёжность}) Для любого полинома $p$, любого семейства схем полиномиального размера
$\{C_i\}_{i=1}^{p(n) - 1}$ и любого $t_1\in\{0,1\}^n$ определим случайные величины 
$\{y_i\}_{i=1}^{p(n)}$ следующим образом:
$$
\begin{aligned}
s   &\gets U(S_n),\\
y_1 &= f_s(t_1),\\
t_2 &= C_1(t_1, y_1),\\
y_2 &= f_s(t_2),\\
t_3 &= C_1(t_1, y_1, y_2),\\
y_3 &= f_s(t_3),\\
&\vdots
\end{aligned}
$$
Тогда случайная величина $y_1y_2\dotsb y_{p(n)}$ вычислительно неотличима от $U_{np(n)}$ (при условии, что все $t_i$ различны).
\end{enumerate}
\end{definition}

\begin{theorem}
Если существует генератор псевдослучайных чисел, то существует и семейство псевдослучайных функций.
\end{theorem}
\begin{proof}
Пусть $G_n:\bits^n\to\bits^{2n}$. Для $S_n = \bits^n$  определим $\{f_s\}_{s\in S_n}$ следующим образом.
Определим функции $G_n^{(0)},G_n^{(1)}: \bits^n\to\bits^n$ исходя из следующего соотношения:  
$G_n(r) = G_n^{(0)}(r)\; G_n^{(1)}(r)$. Теперь определим 
$$f_s(x) = G_n^{(x_n)}(\dotsb G_n^{(x_2)}(G_n^{(x_1)}(s))  \dotsb).$$
Можно представить вычисление $f_s$ на всевозможных $x$ в виде бинарного дерева: 
в корне записано число $s$, если в вершине записано число $z$, то в его наследниках будут записаны $G^{(0)}(z)$ 
и $G^{(1)}(z)$, в листьях дерева окажутся все возможные $f_s(x)$.

% Set the overall layout of the tree
\tikzstyle{level 1}=[level distance=0.5cm, sibling distance=5.5cm]
\tikzstyle{level 2}=[level distance=1cm, sibling distance=2.7cm]
\tikzstyle{level 3}=[level distance=1.5cm, sibling distance=1.3 cm]

% Define styles for bags and leafs
\tikzstyle{bag} = []
\tikzstyle{end} = [circle, minimum width=3pt,fill, inner sep=0pt]

% The sloped option gives rotated edge labels. Personally
% I find sloped labels a bit difficult to read. Remove the sloped options
% to get horizontal labels. 
\begin{center}
\begin{tikzpicture}[grow=down, sloped]
\node[bag] {$s$}
    child {
        node[end] {}        
            child {
                node[end] {}
	            child {
	                node[end, label={below:$f_s(000)$}] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end, label={below:$f_s(001)$}] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent
                node[above] {$G^{(0)}$}
            }
            child {
                node[end] {}
	            child {
	                node[end, label={below:$f_s(010)$}] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end, label={below:$f_s(011)$}] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent
                node[above] {$G^{(1)}$}
            }
            edge from parent 
            node[above] {$G^{(0)}$}
    }
    child {
        node[end] {}        
            child {
                node[end] {}
	            child {
	                node[end, label={below:$f_s(100)$}] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end, label={below:$f_s(101)$}] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent
                node[above] {$G^{(0)}$}
            }
            child {
                node[end] {}            
	            child {
	                node[end, label={below:$f_s(110)$}] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end, label={below:$f_s(111)$}] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent
                node[above] {$G^{(1)}$}
            }
        edge from parent 
        node[above] {$G^{(1)}$}
    };
\end{tikzpicture}
\end{center}
Будем доказывать гибридным методом. Для этого нам нужно построить последовательность распределений,
которые постепенно сходятся к равномерному. Изначальное распределение задаёт дерево $T$, в корне которого
выбирается $s$, а дальше вычисление происходит детерминировано.
Каждое $t_i$ задаёт некоторый путь от корня к листьям. Мы будем модифицировать исходное дерево следующим образом: для каждой вершины на пути соответствующему $t_1$ мы будем удалять эту вершину из дерева
и заменять её сыновей на случайные строки из $U(S_n)$.

\begin{center}
\begin{tikzpicture}[grow=down, sloped]
\node[bag] {$s$}
    child {
        node[end] {}        
            child {
                node[end] {}
	            child {
	                node[end, label={below:$f_s(000)$}] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end, label={below:$f_s(001)$}] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[thin]
                node[above] {$G^{(0)}$}
            }
            child {
                node[end] {}
	            child {
	                node[end, label={below:$f_s(\mathbf{010})$}] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end, label={below:$f_s(011)$}] {}
	                edge from parent[thin]
	                node[above] {$G^{(1)}$}
	            }
                edge from parent
                node[above] {$G^{(1)}$}
            }
            edge from parent[thick]
            node[above] {$G^{(0)}$}
    }
    child {
        node[end] {}        
            child {
                node[end] {}
	            child {
	                node[end, label={below:$f_s(100)$}] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end, label={below:$f_s(101)$}] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent
                node[above] {$G^{(0)}$}
            }
            child {
                node[end] {}            
	            child {
	                node[end, label={below:$f_s(110)$}] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end, label={below:$f_s(111)$}] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent
                node[above] {$G^{(1)}$}
            }
        edge from parent 
        node[above] {$G^{(1)}$}
    };
\end{tikzpicture}

Для примера $t_1=010$.
\end{center}

\begin{center}
\begin{tikzpicture}[grow=down, sloped]
\node[bag] {}
    child {
        node[bag] {$s_1$}
            child {
                node[end] {}
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[thin,solid]
                node[above] {$G^{(0)}$}
            }
            child {
                node[end] {}
	            child {
	                node[end] {}
	                edge from parent[thick]
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent[thin]
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[thick,solid]
                node[above] {$G^{(1)}$}
            }
            edge from parent[dashed]
    }
    child {
        node[bag] {$s_2$}        
            child {
                node[end] {}
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[solid]
                node[above] {$G^{(0)}$}
            }
            child {
                node[end] {}            
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[solid]
                node[above] {$G^{(1)}$}
            }
        edge from parent[dashed]
    };
\end{tikzpicture}

Удаляем корневую вершину и заменяем её сыновей на $s_1,s_2\gets U(S_n)$
\end{center}

\begin{center}
\begin{tikzpicture}[grow=down, sloped]
\node[bag] {}
    child {
        node {}
            child {
                node {$s_1$}
	            child {
	                node[end] {}
	                edge from parent[solid]
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent[solid]
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[dashed]
            }
            child {
                node {$s_2$}
	            child {
	                node[end] {}
	                edge from parent[solid,thick]
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent[solid,thin]
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[dashed]
            }
            edge from parent[dashed]
    }
    child {
        node {$s_3$}        
            child {
                node[end] {}
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[solid]
                node[above] {$G^{(0)}$}
            }
            child {
                node[end] {}            
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[solid]
                node[above] {$G^{(1)}$}
            }
        edge from parent[dashed]
    };
\end{tikzpicture}

Удаляем следующую вершину и заменяем сыновей на случайные элементы из $U(S_n)$.
\end{center}

\begin{center}
\begin{tikzpicture}[grow=down, sloped]
\node[bag] {}
    child {
        node[bag] {}
            child {
                node {$s_1$}
	            child {
	                node[end] {}
	                edge from parent[solid]
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent[solid]
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[dashed]
            }
            child {
                node {}
	            child {
	                node {$s_2$}
	                edge from parent
	            }
	            child {
	                node {$s_3$}
	                edge from parent
	            }
                edge from parent[dashed]
            }
            edge from parent[dashed]
    }
    child {
        node[bag] {$s_4$}        
            child {
                node[end] {}
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[solid]
                node[above] {$G^{(0)}$}
            }
            child {
                node[end] {}            
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(0)}$}
	            }
	            child {
	                node[end] {}
	                edge from parent
	                node[above] {$G^{(1)}$}
	            }
                edge from parent[solid]
                node[above] {$G^{(1)}$}
            }
        edge from parent[dashed]
    };
\end{tikzpicture}

Удаляем последнюю вершину и заменяем сыновей на случайные элементы из $U(S_n)$.
\end{center}
В конце этого процесса в вершине, которая раньше соответствовала $t_1$
будет некоторый $s_j\gets U(S_n)$.
Мы повторяем этот процесс для всех $t_i$. Таким образом получается последовательность $n\cdot p(n)$ деревьев, которые задают распределения
$\{T_i\}_{i=1}^{np(n)}$. В последнем распределении $T_{n p(n)}$
значение для каждого $f_n(t_i)$ выбирается из $U(S_n)$.
 
Если есть противник, который отличает первое распределение от последнего,
т.е. конкретные два последовательных распределения, которые этот
противник различает с вероятностью.
$$
\Pr_{z\gets T_1}[B(z) = 1] - \Pr_{z\gets T_{np(n)}}[B(z) = 1] \ge \epsilon_n \implies
\exists i: \Pr_{z\gets T_i}[B(z) = 1] - \Pr_{z\gets T_{i+1}}[B(z) = 1] \ge \frac{\epsilon_n}{np(n)}.
$$
Дерево распределения $T_{i+1}$ отличается от $T_i$ в трёх вершинах:
\begin{center}
\tikzstyle{level 1}=[level distance=1.5cm, sibling distance=1.5cm]
\begin{tikzpicture}[grow=down, sloped]
\node[bag] {$s_v$}
    child {
        node[end, label={below:$G^{(0)}(s_v)$}] {}
        edge from parent[solid]
    }
    child {
        node[end, label={below:$G^{(1)}(s_v)$}] {}        
        edge from parent[solid]
    };
    \node at (0,-3) {$T_i$};
\end{tikzpicture}\hspace{1cm}
\begin{tikzpicture}[grow=down, sloped]
\node[bag] {\vphantom{$s_v$}}
    child {
        node[end, label={below:$s_u$\vphantom{$G^{(1)}()$}}] {}
        edge from parent[dashed]
    }
    child {
        node[end, label={below:$s_w$\vphantom{$G^{(1)}()$}}] {}        
        edge from parent[dashed]
    };
    \node at (0,-3) {$T_{i+1}$};
\end{tikzpicture}
\end{center}
Таким образом противник может отличить образ генератора $G(s_v) = G^{(0)}(s_v)G^{(1)}(s_v)$ от полностью случайной строки $s_us_w$
с вероятностью больше $\epsilon_n/(n\cdot p(n))$.
\end{proof}
\begin{remark}
Это было доказательство надёжности в смысле п.3. 
То же самое доказательство работает и для п.$3'$. 
\end{remark}

\begin{definition}
Пусть $d_n$~--- доступная случайная величина $d_n\in\bits^{k(n)}$.
\emph{Многоразовый протокол с секретным ключом}~--- это пара
полиномиальный по времени вероятностных алгоритмов $E(d_n, x)$ и 
$D(d_n, m)$ таких, что $D(d_n, E(d_n, x)) = x$ и выполняются
следующее условие надёжности.
\begin{enumerate}[label=\alph*)]
\item (\emph{слабая надёжность}) Для любых полиномов $p$ и $q$ и для любых $x_1,\dotsc,x_{p(n)}\in\bits^{q(n)}$
случайные величины $E(d_n,x_1)\dotsb E(d_n,x_{p(n)})$ и
$E(d_n,0^{q(n)})\dotsb E(d_n,0^{q(n)})$ вычислительно неотличимы.
\item (\emph{сильная надёжность})
 Для любых полиномов $p$ и $q$, любого $x_1\in\bits^{q(n)}$
 и семейства схем $\{C_i\}_{i=1}^{p(n) - 1}$ полиномиального размера
 определим $\{x_i\}_{i=2}^{p(n)}$ следующим образом:
 $$
 \begin{aligned}
 x_2 &= C_1(x_1, E(d_n, x_1)),\\
 x_3 &= C_2(x_1, E(d_n, x_1),E(d_n, x_2)),\\
 x_4 &= C_3(x_1, E(d_n, x_1),E(d_n, x_2),E(d_n, x_3)),\\
 &\ \;\vdots\\ 
 x_{p(n)} &= C_{p(n)-1}(x_1, E(d_n, x_1),\dotsc,E(d_n, x_{p(n) - 1})).
 \end{aligned}
 $$
Случайные величины $E(d_n,x_1)\dotsb E(d_n,x_{p(n)})$ и
$E(d_n,0^{q(n)})\dotsb E(d_n,0^{q(n)})$ должны быть вычислительно неотличимы.
\end{enumerate}
\end{definition}

\begin{theorem}
Если существует семейство псевдослучайных функций, то существует многоразовый протокол с секретным ключом.
\end{theorem}
\begin{proof}
Докажем для сообщения из одного бита. Из этого будет следовать, что есть протокол для сообщения любой длины.
Пусть $f_s:\bits^n\to\bits$~--- семейство псевдослучайных функций, $s\in\bits^n$. Определим случайную величину $d_n$ следующим образом: $d_n=(s_n, z_n)$, где $s_n,z_n\gets U_n$. Алгоритм шифрования $E(d_n,m)$
для ключа $s_n$ и бита $m\in\bits$ выбирает $z\gets U_n$ и выдаёт $(m\oplus f_{s_n}(z),z)$. Алгоритм дешифровки $D(s_n, y)$, где $y\in\bits^{n+1}$, $y=bz$, выдаёт $b\oplus f_{s_n}(z)$. Корректность
протокола очевидна. Нужно доказать многоразовую надёжность.
\todo[inline]{Разобраться с обозначениями для $d_n$.}

Пусть есть сообщения $m_1,\dotsc,m_{p(n)}$. Их коды соответственно
$$f_{s_n}(z_1)\oplus m_1,\dotsc
f_{s_n}(z_{p(n)})\oplus m_{p(n)}$$.
Нужно показать, что такая случайная величина вычислительно неотличима
от строки из $U_{(n+1)\cdot p(n)}$. Если это так, то 
мы могли бы отличить псевдослучайные функции от равномерного распределения.
\end{proof}
\begin{remark}
У этой схемы есть существенный недостаток: длина шифра в $n+1$ раз
длиннее самого сообщения.
\end{remark}
\subsection{Эффективная схема шифрования с закрытым ключом}
Пусть $m\in\bits^{k(n)}$. Нам потребуется семейство псевдослучайных
функций $f_{s}: \bits^n\to\bits^{n}$. Тогда алгоритма шифрования
может работать так: выберем случайное $z\gets U_{n}$. 
Пусть $G:\bits^n\to\bits^{k(n)}$~--- ГПСЧ. 
Определим шифрование так $E(s_n, m) = (G(f_{s_n}(z))\oplus m, z)$. 
\begin{statement}
Описанная схема шифрования надёжна.
\end{statement}
\begin{proof}[Схема доказательства]
Доказываем гибридным методом в два этапа. 
Сначала заменяем функции $f_s$ на случайные строки длины $n$ (за один шаг), а потом заменяем применения генераторов на случайные строки длины $k(n)$ (за $p(n)$ шагов). 
\end{proof}

\section{Протоколы с открытым ключом}
\begin{definition}
Пусть $(d_n, e_n)$~--- доступные случайные величины. Пара вероятностных полиномиальных алгоритмов $(E,D)$ называется 
\emph{системой шифрования с отрытым ключом},
если 
Алгоритмы шифрования и дешифрования $E(e_n,m)$ и $D(e_n,d_n,c)$ связанны следующим соотношением (корректность):
$E(e_n, d_n, E(e_n, m)) = m$.
Надёжность протокола определяется следующим
образом: для любого полинома $p$
и любой последовательности сообщений
$x_n,y_n\in\bits^{p(n)}$ случайные величины
$e_nE(e_n, x_n)$ и $e_nE(e_n, н_n)$
вычислительно неотличимы.

\end{definition}
\begin{remark}
В такой системе шифрования значение $e_n$ сообщается всем (\emph{публичный ключ}), 
а $d_n$~--- никому (\emph{секретный ключ}). 
\end{remark}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\begin{thebibliography}{9}
    
    \bibitem{veresch17} Н.К. Верещагин. 
        \emph{Курс лекций ``Теоретико-сложностные проблемы криптографии''},
        МГУ, \url{http://lpcs.math.msu.su/~ver/teaching/cryptography/index.html}.
    
    \bibitem{dmitrits} Д.М. Ицыксон. \emph{Курс ``Теоретико-сложностные основы криптографии''}, 
        CS центр, \url{https://compsciclub.ru/courses/cryptography-foundations/2016-spring/}.

    \bibitem{gold} O. Goldreich. \emph{Foundations of cryptography}.

    \bibitem{hill} J. H\aa{}stad, R. Impagliazzo, L.A. Levin, M. Luby. 
        \emph{A Pseudorandom Generator from any One-way Function}.  
        SIAM J. Comput. 28, 4 (March 1999), 1364-1396.\\ 
        DOI: \url{https://doi.org/10.1137/S0097539793244708}
            
    \bibitem{katz} J. Katz, Y. Lindell. \emph{Introduction to Modern Cryptography}.

\end{thebibliography}

\listoftodos

\end{document}
% vim: set tw=120: